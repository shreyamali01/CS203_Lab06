{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.0\n",
      "  Downloading numpy-1.26.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (99 kB)\n",
      "Downloading numpy-1.26.0-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "Successfully installed numpy-1.26.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting numpy>=1.19.5 (from scikit-learn)\n",
      "  Using cached numpy-2.2.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached numpy-2.2.3-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "Downloading scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "Successfully installed joblib-1.4.2 numpy-2.2.3 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --force-reinstall scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (75.6.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-75.8.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Downloading setuptools-75.8.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.6.0\n",
      "    Uninstalling setuptools-75.6.0:\n",
      "      Successfully uninstalled setuptools-75.6.0\n",
      "Successfully installed setuptools-75.8.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-macosx_11_0_arm64.whl (254 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl (65 kB)\n",
      "Downloading pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pillow-11.1.0 pyparsing-3.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
      "Collecting pandas>=1.2 (from seaborn)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.11/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas, seaborn\n",
      "Successfully installed pandas-2.2.3 pytz-2025.1 seaborn-0.13.2 tzdata-2025.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Using cached wandb-0.19.7-py3-none-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from wandb) (4.3.6)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (7.0.0)\n",
      "Collecting pydantic<3,>=2.6 (from wandb)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pyyaml (from wandb)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting requests<3,>=2.0.0 (from wandb)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Using cached sentry_sdk-2.22.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from wandb) (75.8.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in ./.venv/lib/python3.11/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in ./.venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.6->wandb)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=2.6->wandb)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.0.0->wandb)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.0.0->wandb)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.0.0->wandb)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.0.0->wandb)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Using cached wandb-0.19.7-py3-none-macosx_11_0_arm64.whl (19.9 MB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sentry_sdk-2.22.0-py2.py3-none-any.whl (325 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "Downloading setproctitle-1.3.5-cp311-cp311-macosx_11_0_arm64.whl (11 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl (194 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: urllib3, smmap, setproctitle, pyyaml, pydantic-core, protobuf, idna, docker-pycreds, click, charset-normalizer, certifi, annotated-types, sentry-sdk, requests, pydantic, gitdb, gitpython, wandb\n",
      "Successfully installed annotated-types-0.7.0 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 docker-pycreds-0.4.0 gitdb-4.0.12 gitpython-3.1.44 idna-3.10 protobuf-5.29.3 pydantic-2.10.6 pydantic-core-2.27.2 pyyaml-6.0.2 requests-2.32.3 sentry-sdk-2.22.0 setproctitle-1.3.5 smmap-5.0.2 urllib3-2.3.0 wandb-0.19.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading IRIS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Labels: \n",
      " [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data   #extracting features\n",
    "y = iris.target  #extracting labels \n",
    "\n",
    "#printing raw labels\n",
    "print(f\"Raw Labels: \\n {y[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping labels for one-hot encoding\n",
    "y = y.reshape(-1, 1)\n",
    " \n",
    "#one-hot encoding the labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoded Labels: \n",
      " [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#printing one-hot encoded labels\n",
    "print(f\"One-Hot Encoded Labels: \\n {y_onehot[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing shapes of the original label and one-hot encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y shape: (150, 1)\n",
      "One-hot encoded y shape: (150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original y shape: {y.shape}\")\n",
    "print(f\"One-hot encoded y shape: {y_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in 70% Training Set, 20% Testing Set, and 10% Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first split is 70% training and 30% test+validation set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y_onehot, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "#second split is splitting 30% test+validation into 20% test and 10% validation set\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.333, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (150, 4) (150, 3)\n",
      "Training set shape: (105, 4) (105, 3)\n",
      "Validation set shape: (15, 4) (15, 3)\n",
      "Testing set shape: (30, 4) (30, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset shape:\", X.shape, y_onehot.shape)\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing feature values to [0, 1] using standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Defining and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.3347 - loss: 1.1743 - val_accuracy: 0.3333 - val_loss: 1.1133\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3586 - loss: 1.1421 - val_accuracy: 0.5333 - val_loss: 1.0904\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4006 - loss: 1.1113 - val_accuracy: 0.6000 - val_loss: 1.0688\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4360 - loss: 1.0905 - val_accuracy: 0.6000 - val_loss: 1.0490\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5127 - loss: 1.0571 - val_accuracy: 0.6000 - val_loss: 1.0311\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4599 - loss: 1.0515 - val_accuracy: 0.6000 - val_loss: 1.0137\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5140 - loss: 1.0145 - val_accuracy: 0.6000 - val_loss: 0.9965\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5796 - loss: 0.9959 - val_accuracy: 0.6000 - val_loss: 0.9797\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5990 - loss: 0.9703 - val_accuracy: 0.6000 - val_loss: 0.9633\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6192 - loss: 0.9580 - val_accuracy: 0.6000 - val_loss: 0.9475\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6126 - loss: 0.9491 - val_accuracy: 0.6000 - val_loss: 0.9320\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6018 - loss: 0.9344 - val_accuracy: 0.6000 - val_loss: 0.9165\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5699 - loss: 0.9233 - val_accuracy: 0.5333 - val_loss: 0.9012\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5900 - loss: 0.8868 - val_accuracy: 0.4667 - val_loss: 0.8859\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6285 - loss: 0.8692 - val_accuracy: 0.4667 - val_loss: 0.8709\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5643 - loss: 0.8542 - val_accuracy: 0.4667 - val_loss: 0.8559\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5754 - loss: 0.8342 - val_accuracy: 0.4667 - val_loss: 0.8409\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5921 - loss: 0.8335 - val_accuracy: 0.5333 - val_loss: 0.8262\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5775 - loss: 0.8136 - val_accuracy: 0.6000 - val_loss: 0.8118\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6264 - loss: 0.7908 - val_accuracy: 0.6000 - val_loss: 0.7977\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6674 - loss: 0.7791 - val_accuracy: 0.5333 - val_loss: 0.7836\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6972 - loss: 0.7677 - val_accuracy: 0.5333 - val_loss: 0.7696\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7402 - loss: 0.7445 - val_accuracy: 0.6000 - val_loss: 0.7558\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7235 - loss: 0.7275 - val_accuracy: 0.6667 - val_loss: 0.7421\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7804 - loss: 0.7239 - val_accuracy: 0.7333 - val_loss: 0.7286\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7794 - loss: 0.6890 - val_accuracy: 0.7333 - val_loss: 0.7150\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7641 - loss: 0.6972 - val_accuracy: 0.7333 - val_loss: 0.7017\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7846 - loss: 0.6794 - val_accuracy: 0.7333 - val_loss: 0.6885\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7884 - loss: 0.6863 - val_accuracy: 0.7333 - val_loss: 0.6753\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8370 - loss: 0.6412 - val_accuracy: 0.7333 - val_loss: 0.6624\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8110 - loss: 0.6561 - val_accuracy: 0.7333 - val_loss: 0.6501\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8241 - loss: 0.6153 - val_accuracy: 0.7333 - val_loss: 0.6383\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8033 - loss: 0.6258 - val_accuracy: 0.7333 - val_loss: 0.6269\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8342 - loss: 0.6033 - val_accuracy: 0.7333 - val_loss: 0.6156\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8745 - loss: 0.5745 - val_accuracy: 0.7333 - val_loss: 0.6048\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8751 - loss: 0.5684 - val_accuracy: 0.7333 - val_loss: 0.5945\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8585 - loss: 0.5689 - val_accuracy: 0.7333 - val_loss: 0.5846\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8439 - loss: 0.5674 - val_accuracy: 0.7333 - val_loss: 0.5747\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8554 - loss: 0.5385 - val_accuracy: 0.7333 - val_loss: 0.5651\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8574 - loss: 0.5171 - val_accuracy: 0.7333 - val_loss: 0.5557\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8512 - loss: 0.5306 - val_accuracy: 0.7333 - val_loss: 0.5467\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8741 - loss: 0.5191 - val_accuracy: 0.7333 - val_loss: 0.5383\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8588 - loss: 0.4955 - val_accuracy: 0.7333 - val_loss: 0.5304\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8390 - loss: 0.4853 - val_accuracy: 0.7333 - val_loss: 0.5229\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8620 - loss: 0.4795 - val_accuracy: 0.7333 - val_loss: 0.5154\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8345 - loss: 0.5009 - val_accuracy: 0.7333 - val_loss: 0.5082\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8262 - loss: 0.4786 - val_accuracy: 0.7333 - val_loss: 0.5014\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8567 - loss: 0.4679 - val_accuracy: 0.7333 - val_loss: 0.4948\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8484 - loss: 0.4749 - val_accuracy: 0.7333 - val_loss: 0.4887\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8817 - loss: 0.4570 - val_accuracy: 0.7333 - val_loss: 0.4826\n"
     ]
    }
   ],
   "source": [
    "#defining the MLP model\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(4,)),     #hidden layer\n",
    "    Dense(3, activation='softmax')                      #output layer\n",
    "])\n",
    "\n",
    "#compiling the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    batch_size=32, \n",
    "                    epochs=50, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 : Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the metrics\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Precision: 0.8253968253968256\n",
      "Recall: 0.8\n",
      "F1-score: 0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting train and validation loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAdiVJREFUeJzt3QdUU2cfBvCHvWSIKODeW3Erjqp1a9271j3qrKP9rHZo7bLDWlu17r1H3XvULe69t6iAOEGRTb7zf2MQFBEwkBCe3zlpuTc3yZubyH14p5lGo9GAiIiIyESYG7oARERERPrEcENEREQmheGGiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSWG4ISIiIpPCcEMZSrdu3ZA3b94UPfa7776DmZkZTNmtW7fUe5w7d26av7a8rpxjHSmD7JMyvYt8pvLZGst3hYgMi+GGjIJcxJJy2717t6GLmuF99tln6rO4du3aW4/5+uuv1TFnzpyBMfPz81OB6tSpUzC2gDlu3DikB/fv38cXX3yBokWLwt7eHg4ODihfvjx+/PFHPH361NDFowzK0tAFIBILFiyItz1//nxs3779jf3FihV7r9eZMWMGYmJiUvTYb775BiNGjEBG16lTJ0ycOBGLFy/GqFGjEjxmyZIlKFWqFEqXLp3i1+ncuTM6dOgAGxsbpGa4GTNmjKqhKVOmjN6+KxnF0aNH0bhxYzx//hyffPKJCjXi2LFj+OWXX7B3715s27bN0MWkDIjhhoyC/GKM69ChQyrcvL7/dS9evFB/LSaVlZVVistoaWmpbhld5cqVUbBgQRVgEgo3Pj4+uHnzprq4vQ8LCwt1M5T3+a5kBFIr07JlS/UZnTx5UtXcxPXTTz+pgKgPISEhqkaIKKnYLEXpRq1atVCyZEkcP34cH3zwgQo1X331lbpv7dq1aNKkCbJnz67+0i9QoAB++OEHREdHJ9qPIm4TwPTp09Xj5PEVK1ZUf5W+q8+NbA8cOBBr1qxRZZPHlihRAlu2bHmj/NKkVqFCBdja2qrXmTZtWpL78ezbtw9t27ZF7ty51WvkypULQ4cORWho6BvvL1OmTLh37x5atGihfs6aNatqNnj9XMjFSY53dnaGi4sLunbtmuRmBKm9uXTpEk6cOPHGfVKjI++pY8eOiIiIUAFI/qKX15ELVI0aNbBr1653vkZCfW40Go1q7siZM6f6/GvXro3z58+/8djHjx+r9yy1R3IOnJyc0KhRI5w+fTre5yGfs+jevXts06euv1FCfW7kIvv555+r8y+fQ5EiRdR3R8qV0u9FSgUGBqJnz55wd3dX3ykvLy/MmzfvjeOWLl2qzr+jo6M6D3JO/vrrr9j7IyMjVe1VoUKF1PNkyZIF1atXV39cJEa+v/I9Gz9+/BvBRki5pLbzbX2q3tZfSve579mzB/3790e2bNnU571y5crY/QmVRe47d+5c7D75frZp0waurq7qfcm/vXXr1sV7XErfOxk//hlK6cqjR4/URUqaK6RWR36B6n4hykVs2LBh6v///fefuqgGBwfj999/f+fzygX52bNn+PTTT9Uvyd9++w2tWrXCjRs33vkX/P79+7Fq1Sr1i1guIH///Tdat24NX19f9ctSyF+2DRs2hKenp/plKkHj+++/V8EjKVasWKFqqfr166ee88iRI6pp6O7du+q+uOS5GzRooGpY5MK7Y8cO/PHHHypQyeOFXIybN2+uyt63b1/V3Ld69WoVcJIabuR9yHkrV65cvNdevny5CjASxB4+fIiZM2eqoNO7d291jmfNmqXKJ+/h9aagd5HPVMKNNIXITcJV/fr1VYiKSz43CRYSCPPly6f6hcgFsGbNmrhw4YIKwfKe5TOQ5+zTp48qs6hatWqCry3nrFmzZiqYSaiQsm/duhX/+9//1EX+zz//TPb3IqUk1ErYl35PEqLkPcr3QEKCBNTBgwer4+QiLee+Tp06+PXXX9W+ixcv4sCBA7HHSOAYO3YsevXqhUqVKql/M9KsJOe2Xr16by2DBAU7OzsVIFKDnDf59yGfj4RK+eNF/m3L90s+x7iWLVumwqMESSGBt1q1asiRI4dqSpZQLY+TwP/vv/+qGqf3ee+UDmiIjNCAAQPkT+F4+2rWrKn2TZ069Y3jX7x48ca+Tz/9VGNvb68JCwuL3de1a1dNnjx5Yrdv3rypnjNLliyax48fx+5fu3at2r9+/frYfaNHj36jTLJtbW2tuXbtWuy+06dPq/0TJ06M3de0aVNVlnv37sXuu3r1qsbS0vKN50xIQu9v7NixGjMzM83t27fjvT95vu+//z7esWXLltWUL18+dnvNmjXquN9++y12X1RUlKZGjRpq/5w5c95ZpooVK2py5sypiY6Ojt23ZcsW9fhp06bFPmd4eHi8xz158kTj7u6u6dGjR7z98jg5xzpSBtknn5EIDAxU57pJkyaamJiY2OO++uordZy8dx35zOOWS8jz2NjYxDs3R48efev7ff27ojtnP/74Y7zj2rRpoz6HuN+BpH4vEqL7Tv7+++9vPWbChAnqmIULF8bui4iI0Hh7e2syZcqkCQ4OVvsGDx6scXJyUp/D23h5ealzmlyZM2dWj02q1z9fHTnHcT873edevXr1N8rdsWNHTbZs2eLt9/f315ibm8f7XOvUqaMpVapUvH/78p2pWrWqplChQu/93sn4sVmK0hWp3pcmhNfJX5A6UjsgNQbyl7jUdkj19Lu0b98emTNnjt3W/RUvNQDvUrduXVUroiOdaKX6X/dYqc2Q2hP5q1FqDHSk34rUQiVF3Pcnf8XK+5MaBrlmSK3Q66Q2Ji55P3Hfy6ZNm1T/IV1NjpC+E4MGDUJSSc2Z1BxJp1EdqcmxtrZWNSa655RtIZ1zpbkoKipKNREk1KSVGDmHUkMjZYzblDdkyJAEvyfm5uax519q/OSvfmlGSu7rxj1n8n5ktFhc0kwln8PmzZuT9b14H1IWDw8PVSujIzWMUjbp3KtrupHmRvm+JNbMIsdITcfVq1eTVQap5ZAaqdQiNX2v97mSf6fSHBd31KQ0V8l3S+4T8h2Tmtt27drF/i6Qm3wHpMZQ3qfUtL3Peyfjx3BD6YpUM+sulnHJLyipapZ+HXIBkepsXWfkoKCgdz6vNKHEpQs6T548SfZjdY/XPVZ+GUszgoSZ1yW0LyHSlCFNDtJ/QNePRlc1//r7k74Drzd3xS2PuH37tmoik+eKSy7+SSVNg3LxkUAjwsLCVNOWBLa4QVH6gciFXdenQcq2cePGJH0ucUmZhfSPiEueL+7rCbnYSTORHCtBx83NTR0nQ9OT+7pxX1/C6esXdN0IPl35kvq9eB/yWvLedAHubWWRpp3ChQurz0T6rfTo0eONfj/SNCdNWXKc9MeRZrakDOGXf2cSHlKLNLW9Tpp25d+4NEPpyM/SRCjlF9JUJ2Hz22+/VZ953Nvo0aNj/02+z3sn48dwQ+lK3BoMHfnlJBd66Swqv6zWr1+v/lLV9TFIynDet43Keb2jqL4fmxRS8yDt/xIIvvzyS9WXRN6fruPr6+8vrUYYSUdPKZf0YZCOmXLe5WIn/XF0Fi5cqEKZ1GBIXxu5sErZP/zww1QdZv3zzz+r/lfS8VzKIH1j5HWlX0ZaDe9O7e9FUj8jmcNH+sfo+gtJ0Inbt0rO0fXr1zF79mzVZ0X6SEk/Kvl/YqQT8ZUrV97o75Rcr3d0T+zfugRVqQGVEC01gFIDI/2HdLU2Qvf5Sody+cwTuun+qEjpeyfjxw7FlO5JFbVUOUvnTfllpSPDkY2BXGCk1iKhSe8SmwhP5+zZs+oiIjUgXbp0id3/PiM68uTJg507d6omjLi1N5cvX07W80iQkcAiTTJSgyN/zTdt2jRek0H+/PnVZxO3KUn3F3RyyyykCUGeU+fBgwdv1IbI68pIKglUrwdhqcXRSc6M0/L60jQmAS5u7Y2u2VNXvrQgryU1DHIhj1t7k1BZpKZTPhO5yfFSmyOdq6VmQ3eRlxpBae6Vm3wn5N+RdLaVjrZvI88nw/4l3MZtHnsbqbV6fTSeBCN/f/9kvXcJMvJvQb6/0jlawmLccKP7bkgznTQNvktK3jsZP9bcULqn+ws57l/E8kvzn3/+gbGUT37JSo2LTBoXN9i83k/jbY9//f3Jz3GH8yaXjDSSv3ynTJkS7y9oGYGVHPJXtAzJlnMt70VGmEmQS6zshw8fVhfF5JJzKBcsKWPc55swYcIbx8rrvl5DIqOJdH0tdHRzpyRlCLycMzlHkyZNirdfmr8kJCW1/5Q+SFkCAgLiNc/I5ynnRsKqrslSQn9cEoR0EyuGh4cneIw8XkKP7v63kX5d0rQpfY4kfL9Omn5kZJuO1N7F7Z8lZPqFt9XcJPY9kEAi711uMsopbhOW/DEhI8kkwCUUnCQM66T0vZPxY80NpXvSsVb+KpSqdt3SADKzcVpW/7+L/CUoM7XK8FTpxKu7SEpV+Lum/pfqf7kwSDW7XJyldkT+Wn6fvhvyV7eURYbJyjwyxYsXV7Urye2PIhcDCTi6fjdxm6TERx99pJ5X+kPJUF6pTZs6dap6PfkrOTl08/XI0F15XrnAS2dqCVVxa2N0rytNlPLXuHw/pPZr0aJF8Wp8hJxX6VQqZZLaGAk7MoQ+of4ecs6kNkiWlpBzJvPKyGcqcyxJp+a4nYf1QWompB/T6+R8y9B1uXhLk5/M+yRzxUhtlTTRSNjT1SxJ7YN0sJVmQOlzI31xJABJHxVd/xz5LCQMyFw4EhpkKLQ8lwwxT4z8m5PmIfkc5PnizlAsnbZlkkdvb+/Y46UsEohkOLw0Z0ozsjQXvv7ZvYsEXAnRMn+PdJZOaJmKyZMnq/lqpB+NdEyWz12mA5BQLZ3gdfMdpfS9Uzpg6OFaRMkZCl6iRIkEjz9w4ICmSpUqGjs7O0327Nk1w4cP12zdulU9x65du945FDyhYbevD11921BwKeu7hreKnTt3qiHZMkS4QIECmpkzZ2o+//xzja2t7TvPx4ULFzR169ZVw3zd3Nw0vXv3jh1aHHcYs7ymg4PDG49PqOyPHj3SdO7cWQ0VdnZ2Vj+fPHkyyUPBdTZu3Kge4+np+cbwaxl++/PPP6vzIcOw5f1v2LDhjc8hKUPBhTz/mDFj1GvJZ12rVi3NuXPn3jjfMgRYzq3uuGrVqml8fHzUd0huccmw/+LFi8cOy9e994TK+OzZM83QoUPVd8zKykoNK5bvTtyh6cn9XrxO9518223BggXquPv372u6d++uvg/ynZKhz69/bitXrtTUr19fDZ+WY3Lnzq2mSJDh0zoytL1SpUoaFxcXda6KFi2q+emnn9TQ8qTw8/NT56Rw4cLquyxTHsi0A/IcQUFB8T67L7/8UpVXjmnQoIEaKv+2oeAyTP9ttm/fro6RIfh37txJ8Jjr169runTpovHw8FCfVY4cOTQfffSROif6eu9kvMzkP4YOWEQZlfwVzqGoRET6xT43RGnk9aUSJNDIfCVSLU5ERPrDmhuiNCKdL6WPhLT/S98H6cwrHRel38jrc7cQEVHKsUMxURqRCcikk6WMcpH5OqSzpczHwmBDRKRfrLkhIiIik8I+N0RERGRSGG6IiIjIpGS4Pjcy/bjMEiuTXCVn6nUiIiIyHOlFI8ufyAK2ry8ai4webiTY5MqVy9DFICIiohS4c+eOmnE7MRku3OimJZeTI9PYExERkfELDg5WlRNxF659mwwXbnRNURJsGG6IiIjSl6R0KWGHYiIiIjIpDDdERERkUhhuiIiIyKRkuD43RET0/qKjoxEZGWnoYpCJsba2fucw76RguCEiomTNNSLroz19+tTQRSETZG5ujnz58qmQ8z4YboiIKMl0wSZbtmywt7fnZKik90l2/f39kTt37vf6bjHcEBFRkpuidMEmS5Yshi4OmaCsWbOqgBMVFQUrK6sUPw87FBMRUZLo+thIjQ1RatA1R0mQfh8MN0RElCxsiiJj/24x3BAREZFJYbghIiJKprx582LChAlJPn737t2qVoKjzNIGww0REZksCRSJ3b777rsUPe/Ro0fRp0+fJB9ftWpVNQrI2dkZqYkhSoujpfTIPygUj55HoGSO1P3yEhFR0kig0Fm2bBlGjRqFy5cvx+7LlClTvDl8pCOrpaVlkkb1JLejrIeHR7IeQynHmhs9OeH7BA3+3Iu+C4/jWRhn7SQiMgYSKHQ3qTWRWg3d9qVLl+Do6IjNmzejfPnysLGxwf79+3H9+nU0b94c7u7uKvxUrFgRO3bsSLRZSp535syZaNmypRpNVqhQIaxbt+6tNSpz586Fi4sLtm7dimLFiqnXadiwYbwwJsOhP/vsM3WcDL3/8ssv0bVrV7Ro0SLF5+PJkyfo0qULMmfOrMrZqFEjXL16Nfb+27dvo2nTpup+BwcHlChRAps2bYp9bKdOnVSws7OzU+9xzpw5MEYMN3pSKFsmONlZ4e6TUHy//oKhi0NElCaktuNFRFSa3+R19WXEiBH45ZdfcPHiRZQuXRrPnz9H48aNsXPnTpw8eVKFDrng+/r6Jvo8Y8aMQbt27XDmzBn1eAkCjx8/fuvxL168wLhx47BgwQLs3btXPf8XX3wRe/+vv/6KRYsWqQBx4MABBAcHY82aNe/1Xrt164Zjx46p4OXj46POo5RVN8x/wIABCA8PV+U5e/asKoOuduvbb7/FhQsXVBiUczVlyhS4ubnBGLFZSk8cba3wZ/syaDfNByuO30WdYtnQsKSnoYtFRJSqQiOjUXzU1jR/3QvfN4C9tX4uYd9//z3q1asXu+3q6govL6/Y7R9++AGrV69WgWDgwIGJBoeOHTuqn3/++Wf8/fffOHLkiApHCZFAMXXqVBQoUEBty3NLWXQmTpyIkSNHqtogMWnSpNhalJS4evWqeg8SlKQPkJDwlCtXLhWa2rZtqwJW69atUapUKXV//vz5Yx8v95UtWxYVKlSIrb0yVqy50aOKeV3Rt6b2Szpy1VkEPgszdJGIiOgddBdrHam5kRoUaS6SJiGpuZCainfV3Eitj4406Tg5OSEwMPCtx0uzkC7YCE9Pz9jjg4KCcP/+fVSqVCn2fgsLC9V8llIXL15U/YkqV64cu0+au4oUKaLuE9IM9uOPP6JatWoYPXq0qoXS6devH5YuXYoyZcpg+PDhOHjwIIwVa270bGjdwthz+QEu+Adj+MozmNOtIie8IiKTZWdloWpRDPG6+iJBJC4JNtu3b1dNRgULFlT9S9q0aYOIiIhEn+f15QLkd7+sl5Sc4/XZ3JYSvXr1QoMGDbBx40Zs27YNY8eOxR9//IFBgwap/jnSJ0dqj+T81KlTRzVjyXkyNqy50TNrS3NM6FBG/X/35QdYdDjxpE9ElJ7JBVmah9L6lpp/NEqzjTQxSXOQNM9I5+Nbt24hLUnnZ+nQLEPOdWQk14kTJ1L8nMWKFVOdlA8fPhy779GjR2r0WPHixWP3STNV3759sWrVKnz++eeYMWNG7H3SmVg6NS9cuFB1qJ4+fTqMEWtuUkFhd0d82bAofthwAT9tvIiqBbIgf9ZXww2JiMh4ySggubBLJ2IJUdKRNrEamNQitSVScyK1R0WLFlV9cGTEUlKC3dmzZ9VIMB15jPQjklFgvXv3xrRp09T90pk6R44car8YMmSIqqEpXLiweq1du3apUCRkGL00i8kIKul0vGHDhtj7jA3DTSrpXjUv/rt0HweuPcLQ5aexsq83rCxYUUZEZOzGjx+PHj16qE63MhpIhmDLSKW0Jq8bEBCghm5LfxuZNFCajOTnd/nggw/ibctjpNZGRl4NHjwYH330kWpmk+OkmUnXRCa1Q9LUdPfuXdVnSDpD//nnn7Fz9UgHZ6nFkqa6GjVqqD44xshMY+gGvjQmX1Cp7pPOWvLBpfakfjL3TXBYFIbULYQhdQun6usREaWmsLAw3Lx5E/ny5YOtra2hi5PhSO2R1JTIcHMZwZXRvmPBybh+syohFXk62+HHltrhdBP/u4aTvk8MXSQiIkonpPOu9He5cuWKamaS0Upy4f/4448NXTSjx3CTypp5ZVe36BgNhi0/rSafIiIiehdzc3M1k7HMkCxDsyXgyEzJxtrPxZiwz00a+KF5SRy99Rg3H4bg500X8WMLbW0OERHR28ioJRm5RcnHmps04GxvhXFttbNdLjzki12X3j6pExEREb0fhps0Uq2gG3pUy6d+/t/KM3j4PNzQRSIiIjJJDDdpaHjDIijsnkkFmy9WnEZMTIYaqEZERJQmGG7SkK2VBf7uWBY2L2cvnn3gpqGLREREZHIYbtJYUQ8njGqqneb61y2XcPrOU0MXiYiIyKQw3BjAx5Vyo1FJD0RGazBoyUk8C4s0dJGIiIhMBsONAcgaH7+0Ko0cLnbwffwCX60+Z/CVYImI6O1q1aql1l3SyZs3r1o48l2/69esWfPer62v58lIGG4MODxc+t9YmJth/Wk/rDh219BFIiIyObL4payPlJB9+/ap4HDmzJlkP6+s1i1rPenTd999hzJlyryx39/fXy1mmZrmzp0LFxcXmAqGGwMqnyczPq+vXW9q9LrzuBb4zNBFIiIyKT179sT27dvVQpCvk0UkK1SogNKlSyf7ebNmzQp7e3ukBQ8PD9jY2KTJa5kKhhsD6/tBAVQv6IbQyGgMXHwSYZHRhi4SEZHJkNWvJYhIzURcz58/x4oVK1T4efToETp27IgcOXKowFKqVCksWbIk0ed9vVnq6tWraoVtWeyxePHiKlAltMp34cKF1Wvkz58f3377LSIjtX0upXxjxozB6dOnVW2S3HRlfr1ZSpZh+PDDD9XK3FmyZFE1SPJ+dLp164YWLVpg3Lhx8PT0VMfISt+610oJX19fNG/eHJkyZVKLVsrinffv34+9X8pdu3ZtODo6qvvLly+PY8eOxa6RJTVomTNnhoODA0qUKKFWIk9NXH7BwMzNzTC+vRca/7UPlwKe4aeNF/FDi5KGLhYRUdJIf8HIF2n/ulb2ctV/52GWlpbo0qWLCgpff/21CgpCgk10dLQKNRIM5GIs4UMuzBs3bkTnzp1RoEABVKpUKUmrdbdq1Qru7u44fPiwWrU6bv8cHbnwSzmyZ8+uAkrv3r3VvuHDh6N9+/Y4d+4ctmzZotaPErIC9utCQkLQoEEDeHt7q6axwMBA9OrVCwMHDowX4Hbt2qWCjfz/2rVr6vmlyUteM7nk/emCzZ49exAVFaXCkjzn7t271TGdOnVC2bJlMWXKFFhYWODUqVOwsrJS98mxERER2Lt3rwo3Fy5cUM+Vmhhu9OlZABAdAbjkTtbDsjna4o92ZdB19hEsOHQb1QpmQcOSnqlWTCIivZFg83P2tH/dr/wAa4ckHdqjRw/8/vvv6sIsHYN1TVKtW7dWAUJuX3zxRezxgwYNwtatW7F8+fIkhRsJI5cuXVKPkeAifv755zf6yXzzzTfxan7kNZcuXarCjdTCyAVfwpg0Q73N4sWLERYWhvnz56ugICZNmqRqRn799VcVsITUksh+CRpFixZFkyZNsHPnzhSFG3mchDFZkVzWuxLy+lIDIwFLFvaUmp3//e9/6rVEoUKFYh8v98m5lhoxIbVWqY3NUvpy/wIw40NgUTsgLCjZD69ZOCs+/UD7gQ9feQZ3nxjgLyEiIhMkF9yqVati9uzZaltqMqQzsTRJCanB+eGHH9TF19XVVYUMCSpyUU6Kixcvqou+LtgIqVl53bJly9Tq3hJe5DUk7CT1NeK+lpeXV2ywEfKcUrty+fLl2H0lSpRQwUZHanGklicldO9PF2yENL1JB2S5TwwbNkzVINWtWxe//PILrl+/HnvsZ599hh9//FGVc/To0SnqwJ1crLnRFzsXQBMDPLgIrOgOfLwcsEje6f28fhEcuvlYTew3eOkpLOtTBZYWzJ9EZMSkeUhqUQzxuskgQUZqZCZPnqxqbaTJqWbNmuo+qdX566+/VB8aCTgSHKRZSZpS9MXHx0c13Ui/GmlWktoiqbX5448/kBqsXjYJ6UhznASg1CIjvT7++GPVpLd582YVYuT9tWzZUoUeec9y37Zt2zB27Fj1vuXzSC28cuqLU3ag41LtP7jrO4EtI5L9FNaW5pjYoSwcbSxx/PYTjN18KVWKSkSkN9KHRZqH0vqWhP42cUkHWHNzc9WsI00q0lSl639z4MAB1afkk08+UbUi0mxy5cqVJD93sWLFcOfOHTVkW+fQoUPxjjl48CDy5Mmj+v3ICC1ptpGOtnFZW1urWqR3vZZ03pW+NzpSfnlvRYoUQWoo9vL9yU1H+s08ffpU1eDoSGfpoUOHqgAjfZAkROpIrU/fvn2xatUqfP7555gxYwZSk0HDjXQuknZCqcpLyiRF8sWRZCgnUD7IhDpsGVT2MkCr6fKvHTg6AzgsPydP7iz2+K2NdljirP03seLYqy8TERGljDQDSQfYkSNHqmuJjCjSkaAho5skgEgzy6effhpvJNC7SFOMXJe6du2qgoc0eUmIiUteQ5qgpDZDmmz+/vtvrF69Ot4x0g9H+rVIZ9yHDx8iPDz8jdeS2h8ZkSWvJR2QpcOw1IBIB2hdf5uUkmAlrx33JudD3p/UaMlrnzhxAkeOHFGdtKXmS4JaaGio6tAsnYslsEnYkr44EoqEXKulmU/emzxeyqy7zyTDjSRPSclSTZgU8kHLkD5pp5THGaViTYG632l/3vIlcPXN4YDv0qiUJz6ro+2M9fXqc6oWh4iI3o80TT158kQ1kcTtHyPXlHLlyqn90uFY+sTIUOqkkj+2JajIRV46IEszzE8//RTvmGbNmqlaDQkBMmpJgpQMBY9LOt3KhIMypFqudQkNR5dh5BIUHj9+rDrytmnTBnXq1FGdh9/X8+fP1YinuDepgJDKh7Vr16pOyjLcXcKO1G5JHyIhfXtkOL0EHgl5UksmnamlCU4XmmTElAQaeX9yzD///IPUZKYxknn/5eTJlyOpXyj5AsoX5F3TX78uODhYtXXKUD0Z8pcq5JSuGwicXAhYOwI9twHur6rukiImRoN+i45j6/n7yOpog/UDq8PD2TZ1yktElAQySkf++s6XL5+qPSBKy+9Ycq7fJt/nRmp75ITEvaU6acdt8ieQtwYQ8QxY3B54Hpj8+W/alUERd0c8eBaOPguOcYI/IiKiJDD5cCO9snXzGMgt7lC2VGVpDbSbD7gWAIJ8gSUdgcjQZD2Fg40lZnatgMz2VjhzNwgj/j3DBTaJiIgyeriRzmNShaW7xe3tnersXYFOKwBbF+DeMWBNf22TVTLkcrXH5E7l1AKba075YfreG6lWXCIiIlNg8uFGFhuTtrm4tzSVpQDQfiFgbgWcXwXsHpvsp6hawA2jm2r77Pyy5RJ2XUrZRExEREQZgcmHG6OQrwbQ9GXH5z2/AmeWJ/spOlfJg46VcqmKn8+WnMS1wFeLpBERpSU2j5Oxf7cMGm5k2JluLL3Qje/XTUctTUoytCwu3fHy2AcPHqifZTIho1f2E6Day3l51g4Abu5L9miyMc1KomLezHgWHoU+848hKDTlK7wSEaV01tsXL7g8DKUO3azQcZeOSHdDwWXCHxnP/zqZnEhWN5VJlm7duhW76qjQzSgZl8z6KMcZzVDwt5Gpr1d0BS6uA2ycgO6bAY/krQD+8Hk4mk86gHtPQ9V6VLO7VVT9cYiI0oJMgCcz02bLlk3NuZLQ72SilJDlIfz8/FSIzp079xvfreRcv41mnpu0YtBwIyLDgAUtAd+DgKOndg6cZK4ift4vCK2nHERYZAx618iHr5skbw4dIqKUkktGQECACjhE+iYTIsocN7IUxesYbow53IjQJ8CcxkDgBSBLIW3AkZFVybDxjD8GLD6hfh7fzgutyuVMpcISEb1JZp2NjGTTOOmXhBoJOAlhuDH2cCOC7gGz6gPBd4GcFYEu6wDr5K1yO27rZUzadU0tuLn8U2+UyeWSasUlIiIyJM5QnB445wA++Vc7B87do8DK7kB0VLKeYli9wqhbzB0RUTH4dMExBAaHpVpxiYiI0guGG0PKVhT4eBlgaQtc2QJsGJysSf5kiYY/23uhULZMuB8sSzQc5xINRESU4THcGFruKkCbOYCZuXahzV3xV5J9F0dbK7VEg7OdFU7deapWEc9gLY1ERETxMNwYg6KNgY/+1P6893fgyIxkPTxPFgdM/li7RMO/J+5i1v6bqVNOIiKidIDhxliU7wbU+kr786b/ARfWJuvh1Qu54evGxdTPP2+6iL1XHqRGKYmIiIwew40xqTkcKN9dZpIA/u0F3Hg1eWFSdK+WF23L50SMBhi4+ARuPgxJtaISEREZK4YbYyKzMTb5Ayj6ERAdASzuANzan4yHm+HHliVRLrcLgsOi0Hv+MTwL4zwURESUsTDcGBtzC6DNbKBgPSAqFFjUDrjtk+SH21haYGrn8vBwslWLaw5ZegrRUpVDRESUQTDcGCNLG6D9QiB/bSAyBFjUBrhzJMkPz+Zoi+ldysPG0hw7LwXit62XUrW4RERExoThxlhZ2QIdlwD5PgAingMLWwN3jyf54aVzuuDX1qXVz9P23MDMfTdSsbBERETGg+HGmFnZAR2XAnmqAeHBwMKWgN/JJD+8Rdkc+F+DIurnHzdexPJjd1KxsERERMaB4cbYWTsAHy8HclUBwoKA+S0A/zNJfnj/WgXUyuFixL9nsPV8QCoWloiIyPAYbtIDm0zAJyu1C2yGPQXmNwfun0/yCKqvGheLHSI+aPFJHLz+MNWLTEREZCgMN+mFjaN2oc3s5YDQx8C8ZkDgpSQHnLGtSqF+cXdERMeg97xjOHP3aaoXmYiIyBAYbtITW2eg82rA0wt48RCY1xR4cDlJD7W0MMffHcuiaoEsCImIRrc5R9VQcSIiIlPDcJPe2LkAndcAHqWAkEBgdkPgXtJGUdlaWWB6lwoondMZj0Mi0HnWYdx7GprqRSYiIkpLDDfpkb0r0Hlt/CaqJC7VkMnGEnO6VUT+rA7wDwpTAefR8/BULzIREVFaYbhJrxyyAF3XAflqaufBWdQ2yYttZslkg4U9KyO7sy1uPAhB1zlHuEwDERGZDIab9N7JuNMKoFgz7VpUK7oBx+cm6aHZXeywoFdluDpY49y9YLUOVVhkdKoXmYiIKLUx3JjCUg1t5wLluwGaGGD9YGDfeEDz7vWkCmTNhHndK6mmqkM3HquVxCOjY9Kk2ERERKmF4cZUFtv8aAJQ43Pt9s4xwLZvgJh3B5VSOZ0xs2sFtQ7VjouB+GLFacRwoU0iIkrHGG5MhZkZUGcUUP8n7bbPJGDtACD63X1pquTPgn86lYOluRnWnvLD6HXnoUlCzQ8REZExYrgxNVUHAi2mAmYWwOnFwLLOQOS7h3vXKeaOP9p5qYy04NBtjNuWtPlziIiIjA3DjSkq0xHosAiwtAWubAYWtARCn7zzYc3L5MAPzUuqnyfvuo7pe6+nQWGJiIj0i+HGVBVppJ3N2MYZ8PXRTvb39N2rgn9SJQ+GN9SuJP7zpktYcsQ3DQpLRESkPww3pixPVaDHZsAxO/DgEjCrfpIW3OxfqyA+rZlf/fzV6rPYcMYvDQpLRESkHww3ps69BNBrO5C1KPDMT1uDc3PvOx82omFRdKyUW40oH7rsFHZdDkyT4hIREb0vhpuMwDkn0GMLkLsqEB4MLGwNnPv3nSuJ/9iiJJp6ZUdktAb9Fh7HkZuP06zIREREKcVwk1HYZdb2wdHNZryyB+AzOdGHWJibYXw7L9QukhVhkTHoOfcozt0LSrMiExERpQTDTUZiZaudzbhSH+321q+ArV8nOtmflYU5/ulUHpXyueJZeJRaaPPq/WdpV2YiIqJkYrjJiLMZN/oNqDvm1WR/q3oBUW9fGdzO2gKzulZA6ZzOePIiEp/MOgzfRy/SrsxERETJwHCTEclMfdWHAC2nAeaW2v430g8n7O1NTo62VmodqsLumXA/OBydZh1CQFBYmhabiIgoKRhuMjKvDtpVxa0zAbf2AbMbAUH33np4ZgdrLOxZGXmy2OPO41BVg/Po+dtrfIiIiAyB4SajK/Ah0H0TkMkdCDwPzKoH3L/w1sOzOdmqgOPpbItrgc/RZfYRBIW+e/0qIiKiDBFu9u7di6ZNmyJ79uxq6PGaNWve+Zjdu3ejXLlysLGxQcGCBTF37tw0KatJ8/QCem4H3AoDwffeORdOLld7LOxVGW6ZrHHeLxg95h7Fi4ioNC0yERGRUYabkJAQeHl5YfLkxIck69y8eRNNmjRB7dq1cerUKQwZMgS9evXC1q1bU72sJi9zHqDHViC3NxAepO2Dc3blWw8vkDUT5veoDCdbSxy//QR95h9HWGR0mhaZiIgoIWYajcxBa3hSc7N69Wq0aNHircd8+eWX2LhxI86dOxe7r0OHDnj69Cm2bNmSpNcJDg6Gs7MzgoKC4OTkpJeym5TIMGBVb+DiOu12vR+AqoO0nZATcML3CT6ZeRgvIqJRr7g7/ulUTg0fJyIi0qfkXL/T1VXIx8cHdevWjbevQYMGaj/peS6cyv2029u/BbaMAGISrpUplzszZnapAGtLc2y/cB//W3EaMTFGkZeJiCiDSlfhJiAgAO7u7vH2ybakudDQ0AQfEx4eru6Pe6OkzIXzC1D/J+324anAim5AZMLnuGpBN0zpVA6W5mZYc8oP/1t5BtEMOEREZCDpKtykxNixY1U1lu6WK1cuQxcp/ag6EGgzG7Cw1jZTzW8BvEh4fak6xdwxoUMZtWTDvyfuYtjyU4iKfvvMx0RERKklXYUbDw8P3L9/P94+2Za2Nzs7uwQfM3LkSNU+p7vduXMnjUprIkq21q5JZesM3DkEzKwLPL6R4KEflc6OSR3Lqhqctaf8MHjZKUQy4BARURpLV+HG29sbO3fujLdv+/btav/byJBxCT9xb5RMeasDPbYBzrmBx9e1AefOkQQPbVTK82WnYjNsPOOPgYtPICKKAYeIiDJIuHn+/Lka0i033VBv+dnX1ze21qVLly6xx/ft2xc3btzA8OHDcenSJfzzzz9Yvnw5hg4darD3kGFkKwr02gF4lgFePALmNQUurE3w0PolPDC9s7aT8dbz99F/0XGER3GYOBERZYBwc+zYMZQtW1bdxLBhw9TPo0aNUtv+/v6xQUfky5dPDQWX2hqZH+ePP/7AzJkz1YgpSgOO7trZjAs3AqLCgOVdgYMTgQRmE6hdNJsaRWVjaY4dFwM5Dw4REWW8eW7SCue50QMZFi7Dw49M125X7AU0/BWwsHzj0IPXHqLnvGMIjYxG9YJumNGlglplnIiIKDlMdp4bMqah4r8BDX6WfAwcnQks/RgIf57gMPG53SvC3toC+689RPe5RxASzqUaiIgo9TDcUMrIjMXeA4B28wFLW+DqVmBuY+BZwBuHVs6fBQt6VkImG0scuvEY3eYcwXMGHCIiSiUMN/R+ijcDum4A7N0A/9PakVT3z79xWPk8rirgONpa4uitJ+g2mwGHiIhSB8MNvb9cFYFe24EsBYGgO8CsBsCVbW8cVjZ3ZizuVUUttnns9hP0mMPVxImISP8Ybkg/XPMDPbcDeWsAEc+AJe2BQ1PfGElVKqczFvSsrGpwjtx6jB5zjyI0gqOoiIhIfxhuSH/sXYFPVgFlPwE0McCWL4GNnwPRkfEO88rlgvk9XvXB6TX/KIeJExGR3jDckH5ZWgPNJgH1ftCOpDo2C1jUFgh9+kYT1bweFeFgbYED1x6h9/xjDDhERKQXDDeUOiOpqn0GtF8IWNkDN3YBs+oDj2++0cl4bo9Kapj4vqsP0XchZzImIqL3x3BDqafYR0CPLYBjduDhZWDGh8Btn3iHVMzritndKsLWyhy7Lz9A/4Vci4qIiN4Pww2lLk8voPd/QPayQOhjYH4z4NSSeIdUyZ8Fs7tWVEs17LwUiAFcbJOIiN4Dww2lPidPoNsmoFgzIDoCWNMX2D5au4xDnJmMZ3bVLra5/cJ9fLbkJCKjGXCIiCj5GG4obVjbA23nATU+124fmAAs6QCEBcUeUqNQVkzvXB7WFubYcj5ABRzW4BARUXIx3FDaMTcH6owCWs96uWTDNm0/nAdXYg+pVSQbpr0MOJvPBaDPAo6iIiKi5GG4obRXqo22o7FTTuDRNWBmHeDK1ti7axfNppqodJ2Mu3KpBiIiSgaGGzIM6WDcZzeQ2xsIDwYWtwf2jY+d0fiDwlm1MxnbWOLwzcfoNPMwnr6IMHSpiYgoHWC4IcPJlBXosg4o3x2ABtg5BljZA4h4ETtMfHHvKshsb4XTd56iw/RDePAs3NClJiIiI8dwQ4af0bjpBKDJeMDcEji/CphdH3jqG7sW1bJPvZHV0QaXAp6h3TQf+D0NNXSpiYjIiDHckHGo2BPouh6wdwMCzgLTawG39qu7Crs7YsWn3sjhYoebD0PQdqoPbj0MMXSJiYjISDHckPHIU1XbD8ejNPDiETC/eezK4nndHLCirzfyuzng3tNQtJ3mg8sBzwxdYiIiMkIMN2RcXHIBPbYCpdoCMVHalcVX9wUiQ5HdxU41URX1cFR9b9pP98GZu/EX5CQiImK4IeOc8K/VDKDBz4CZBXBmqXbhzSe3Vd+bpX2qwCuXC56+iMTHMw7D5/ojQ5eYiIiMCMMNGe/K4t4DgC5rAPssQMAZbT+cG7vhYm+NRb0qo0p+VzX/Tdc5R7DtfIChS0xEREaC4YaMW74PgD57AM8y2oU3F7QEDvyNTNYWmNu9EuoVd1dLNPRbdAIrj981dGmJiMgIMNxQOumHswXw+hjQxADbv1Xz4dhqwjClUzm0KZ8T0TEafLHiNGbuu2Ho0hIRkYEx3FD6YGUHtPgHaDzu1Xw4M+vBMugWfmtdGr2q51OH/bjxIn7fegmalzMdExFRxsNwQ+mrH06l3tr5cByyAYHnVT8c8+s78XWTYvhfgyLqsMm7ruPrNedUbQ4REWU8DDeUPufD+XQPkKMCEBYELGoDs/3jMaBWAfzUsqTKQIsP+2Lw0pOqPw4REWUsDDeUPjllB7pvAsp1fbku1ffA8i7oVMYVEzuWhZWFGTac8UfPeUfxIoIrihMRZSQMN5R+WdoAzf4GPpoAmFsBF9cBM+vioxyhmNm1IuysLLDv6kOuKE5ElMEw3FD6V6G7thYnkwfw4BIwvTZq4gQW9a4MZzsrnPR9ivbTDiEwOMzQJSUiojTAcEOmIVclbT+cXJWB8CBgcXuUuzkDy/tURjZHG1y+/wxtpvrA99ELQ5eUiIhSGcMNmQ5HD6DrBqBCT20/nF0/ocjufvi3RynkdrWH7+MXaDP1IBfcJCIycQw3ZFosrYGPxgPNJgIW1sDljcj170dY3c4NRdwdEfgsHO2m+eCk7xNDl5SIiFIJww2ZpnJdgO5bAMfswMMryLK4EVbVfoSyuV0QFBqpOhkfuPbQ0KUkIqJUwHBDpitneW0/nDzVgIhncFjTDcsKbscHBTPjRUQ0us85ii3nuOAmEZGpYbgh05YpG9BlLVClv9q0Pvgn5lr/hjbF7BARHYP+i45jxbE7hi4lERHpEcMNmT4LK6DhWKDVTMDSDuY3duH3J4MxpMQLyAoN/1t5BrP23zR0KYmIyJTCzeTJk5E3b17Y2tqicuXKOHLkyFuPjYyMxPfff48CBQqo4728vLBly5Y0LS+lU6XbAr12AJnzwuypLwbfHoi/il1Sd/2w4QLGbr6IGK5HRUSU7hk83CxbtgzDhg3D6NGjceLECRVWGjRogMDAwASP/+abbzBt2jRMnDgRFy5cQN++fdGyZUucPHkyzctO6ZBHSaDPbqBgPZhFhaH5ze+xLv9aWCEK0/bcwMAlJxAWGW3oUhIR0Xsw02g0Bv1TVWpqKlasiEmTJqntmJgY5MqVC4MGDcKIESPeOD579uz4+uuvMWDAgNh9rVu3hp2dHRYuXPjO1wsODoazszOCgoLg5OSk53dD6UZMDLDnF2DPr2rzoWs5NLvfC37RLmpE1YwuFeCWycbQpSQiohRcvw1acxMREYHjx4+jbt26rwpkbq62fXx8EnxMeHi4ao6KS4LN/v3733q8nJC4NyKYmwO1vwI6LgVsnOD2+AR2O32HmrbX1XINLf85gGuBzw1dSiIiSgGDhpuHDx8iOjoa7u7u8fbLdkBAwkN0pclq/PjxuHr1qqrl2b59O1atWgV/f/8Ejx87dqxKerqb1AoRxSrSCOi9C8haDNahgZhrPgZDHP/Dnccv0HrKQRy68cjQJSQiovTW5ya5/vrrLxQqVAhFixaFtbU1Bg4ciO7du6san4SMHDlSVWHpbnfucNgvvcatoLajcYlWMIuJwpDImZjrPBPhoc/RedZhrDpx19AlJCKi9BJu3NzcYGFhgfv378fbL9seHh4JPiZr1qxYs2YNQkJCcPv2bVy6dAmZMmVC/vz5EzzexsZGtc3FvRG9wSYT0GY20OBnwMwCtcJ3YbvTj/CICcCw5afx5/YrMHD3NCIiSg/hRmpeypcvj507d8buk6Ym2fb29k70sdLvJkeOHIiKisK///6L5s2bp0GJyaSZmQHeA7ST/jlkRa6I69hmPwq1zE/ir51X8fny04iIijF0KYmIyNibpWQY+IwZMzBv3jxcvHgR/fr1U7Uy0tQkunTpopqWdA4fPqz62Ny4cQP79u1Dw4YNVSAaPny4Ad8FmZR8NYA+e4CcFWEX/QxzrMdhiOW/WH3yDrrNOYJnYZGGLiERESXCEgbWvn17PHjwAKNGjVKdiMuUKaMm5dN1Mvb19Y3XnyYsLEzNdSPhRpqjGjdujAULFsDFxcWA74JMjnMOoNtGYMtImB2bpcKNl8VNDL7eDx1nRGJOt0rI6sih4kRExsjg89ykNc5zQ8l2ajGwYSgQFYY7cMen4YMR4locC3pURu4s9oYuHRFRhhCcXua5IUoXynwM9NgKuORGLtzHapvvUPHpZrSachDn/YIMXToiInoNww1RUmQvo+2HU6g+bBCBcVbTMCxsEjpP24uD1x8aunRERBQHww1RUtm7Ah2XAbW/gQZm+NhyF+ZpvsE3szdi09mEJ5EkIqK0x3BDlBzSub3m/2D2yb/Q2LmilPktrLIciRVLZ2HhoduGLh0RETHcEKVQwTow+3QvNNnLw8UsBHOsfsejDaMxYdtFTvZHRGRgDDdEKeWSC2Y9NkNToafaHGy5GuX29caPK/YjKpqT/RERGQrDDdH7sLSB2UfjgZbTEGVuiw8szqLH+a74YdoCBHOyPyIig2C4IdIHrw6w/PQ/hGTKixxmj/D1/aGYN+Eb3HkUYuiSERFlOAw3RPriXgIOA/ciKG8jWJtFY1DYVJyd1B6nr98zdMmIiDIUhhsifbJ1hnPXJQiqMRrRMEdjzT7Yza+PPQcPGLpkREQZBsMNkb6ZmcG5zjCEd1qLpxauKGx2F+W2tsbW5dM4koqIKA0w3BClEvtCHyDTZwdxK1MZOJqFosGF4dg/qQ8iwsMNXTQiIpPGcEOUiiydPZF36E6czdtNbdd4tBw3/6iN4Pu+hi4aEZHJYrghSm0WlijV7S+cqT4ZzzR2KBJxHtFTqyPg9DZDl4yIyCQx3BClkdJ1P0FAh624apYHmTVByLq6He6s/QGI4YR/RET6xHBDlIYKFfOC88A92GFTDxbQINfJcfCf1gIIfWLoohERmQyGG6I0li1LZlT7fBkWZvsC4RoreN7fg6cTvBFz96Shi0ZEZBIYbogMwM7aAh/3/QbLvGbjdkw2uIT7I3pmPUQcngVwuDgR0XthuCEyEHNzM3Rp1QynG6/FjpjysEIkrDcPQ+jy3kAEl20gIkophhsiA2tWpTicui3HX2adEK0xg93FFQibUht4eNXQRSMiSpcYboiMQKX8bmgx8Hf8z/4HPNA4w/bJZURNrQmc+9fQRSMiSncYboiMRJ4sDhj9WV+MyTEVh2OKwjIqBFjZA5qNXwBRnNWYiCipGG6IjIiznRX+7NkQG8pMxT9RzdQ+s6MzoJlVH3h809DFIyJKFxhuiIyMlYU5vm9ZBtYNxqB75P/wRJMJZv6noJn2AXBxg6GLR0RkmuHmzp07uHv3buz2kSNHMGTIEEyfPl2fZSPKsMzMzNCrRn6079gLrWJ+wfGYQjALDwaWdQK2fAVERRi6iEREphVuPv74Y+zatUv9HBAQgHr16qmA8/XXX+P777/XdxmJMqyGJT0woU9TDLD+EdOjmmh3HpoMzGkEPL1j6OIREZlOuDl37hwqVaqkfl6+fDlKliyJgwcPYtGiRZg7d66+y0iUoXnlcsHKAR/g3yx90SdiKII19sC9Y8C0GsCVrYYuHhGRaYSbyMhI2NjYqJ937NiBZs20HR+LFi0Kf39//ZaQiJAzsz1W9PNGaIFGaBzxM07H5NeuR7W4HbDtWyA60tBFJCJK3+GmRIkSmDp1Kvbt24ft27ejYcOGar+fnx+yZMmi7zISEQAnWyvM7lYRH1SqgLYRozEnqoH2joN/A3Mas5mKiOh9ws2vv/6KadOmoVatWujYsSO8vLzU/nXr1sU2VxFR6oyk+qlFSXzRuBS+j+6KvhFDEGLmANw9AkytDlzaZOgiEhEZnJlGk7JV+qKjoxEcHIzMmTPH7rt16xbs7e2RLVs2GCsps7OzM4KCguDk5GTo4hCl2JZzARi2/BRcI/0x3XYSimuuae+o0h+oOwawtDZ0EYmIDHL9TlHNTWhoKMLDw2ODze3btzFhwgRcvnzZqIMNkamNpFrdvxosXPOieegozInRjab6B5jNSf+IKONKUbhp3rw55s+fr35++vQpKleujD/++AMtWrTAlClT9F1GInqLIh6OWDegOqoV8cSYiE7oGfE5Qi0cAb+TgEz6d2GtoYtIRJQ+ws2JEydQo0YN9fPKlSvh7u6uam8k8Pz999/6LiMRJcLZ3gqzulbEwNoFsTOmPOqE/ITLVsUBmfRveRdA1qaKDDN0MYmIjDvcvHjxAo6Ojurnbdu2oVWrVjA3N0eVKlVUyCGitGVhboYvGhTB1E/K4am1O5o8G4H5Fq21dx6dAcysCzy4bOhiEhEZb7gpWLAg1qxZo5Zh2Lp1K+rXr6/2BwYGspMukQE1LOmJNQOqIZebM0aFtEbP6JEIt3YF7p8FptUEjs8FUjaGgIjItMPNqFGj8MUXXyBv3rxq6Le3t3dsLU7ZsmWT/XyTJ09Wz2Vra6v678hSDomRzstFihSBnZ0dcuXKhaFDhyIsjNXuRKKwu6MKOLWLZMXOyFKoHvwjrjtWAqJCgfWDgRVdtRMAEhGZqBQPBZc1pWQ2YpnjRpqkhIQSqbmRmYqTatmyZejSpYuaFFCCjQSXFStWvHXk1eLFi9GjRw/Mnj0bVatWxZUrV9CtWzd06NAB48ePf+frcSg4ZRQxMRr8ueMKJv53DWaIwU/ue9Dx2VyYxUQCTjmB1jOBPNo/TIiIjF1yrt8pDjc6utXBc+bMmaLHS6CpWLEiJk2apLZjYmJUbcygQYMwYsSIN44fOHAgLl68iJ07d8bu+/zzz3H48GHs37//na/HcEMZzeaz/hi2/DRCI6NR38UPk2wmwTroFmBmDtT8EqjxBWBhaehiEhEZdp4bCSCy+re8SJ48edTNxcUFP/zwg7ovqSIiInD8+HHUrVv3VYHMzdW2j49Pgo+R2hp5jK7p6saNG9i0aRMaN26c4PEyH4+ckLg3ooykUSlPrOpfFTkz22Hb0+yo9uQ7+OVpAWhigN1jgXkfcekGIjIpKQo3X3/9tapp+eWXX3Dy5El1+/nnnzFx4kR8++23SX6ehw8fqpmOZSh5XLItzV4J+fjjj1Wwql69OqysrFCgQAG1DMRXX32V4PFjx45VIUx3k1ohooymmKcT1g2sjir5XfEgwhpVL7fDliI/QmPtCPj6AFOrAefXGLqYRESGCzfz5s3DzJkz0a9fP5QuXVrd+vfvjxkzZmDu3LlITbt371ZB6p9//lHz7axatQobN25UtUYJGTlypKrC0t1khBdRRuTqYI0FPSujq3cetd33dH6Myj4F0dnLAWFB2o7G0uE44oWhi0pE9F5S1ND++PHjBDsNyz65L6nc3NxgYWGB+/fvx9sv2x4eHgk+RmqGOnfujF69eqntUqVKISQkBH369FE1SrrOzTo2NjbqRkTahTfHNC+panK+XXsOCy6Z44T7t1hSfiecjk/WDhW/7QO0mQ14lDR0cYmI0q7mRkZI6ToAxyX7pBYnqaytrVG+fPl4nYOlz45s64aXJzSB4OsBRgKSeM++0UQZRodKubGkdxW4ZbLB+fuhqHmyJs7XnQ9k8gAeXgZmfAgcmcE5cYgo49Tc/Pbbb2jSpAl27NgRG0KkA7A0+Ujn3uQYNmwYunbtigoVKqg5c2QouNTEdO/eXd0vw8Rz5Mih+s6Ipk2bqiHfMp+OjLS6du2aqs2R/bqQQ0TvViGvK9YNrIZPFxzH2XtBaL7JEj83WIK2d3+B2dWtwKYvgOv/Ac0mAQ5ZDF1cIqLUrbmpWbOmml+mZcuWauFMuckSDOfPn8eCBQuS9Vzt27fHuHHj1MSAZcqUwalTp7Bly5bYTsa+vr5qPh2db775Rg39lv8XL14cPXv2RIMGDTBt2rSUvBWiDC27ix1W9PVG8zLZERWjwfDN/vjK9mtE1f8FsLAGLm/Sdja+udfQRSUiSrL3nucmrtOnT6NcuXJqBJSx4jw3RG+SXwPT997AL1suqZaoCnkyY3p9a7hu7gc8vCK/KoAanwO1RgAWVoYuLhFlQMGpPc8NEZkWMzMzfFqzAGZ3qwhHW0scu/0ETZYH4VyTdUC5LhJ/gH3jgDmNgSe3DF1cIqJEMdwQUazaRbKpdanyZ3WAf1AYWs86hbW5RwBt5gA2zsDdI8DUGsDZlYYuKhHRWzHcEFE8BbJmil14MzwqBoOXnsKvd4sj+tO9QK7KQHgw8G9PYHU/IPyZoYtLRPR+fW6k03BipGPxnj172OeGyAREx2gwbttlTNl9XW1L2PmrfSk4HZ4A7P1Nu3yDa37tApw5yhu6uERk4oJTa+FM3fDsd5kzZw6MFcMNUfKsPXUPw1eeUbU4+d0c8M8n5VA0/Bzwb28g+C5gbgl8+C1Q9TNZHM7QxSUiE5Wmq4KnNww3RMl39m4QPl1wDH5BYbC1MsePLUqhTXEHYP0Q4MLLNanyfQC0nA44eRq6uERkgjhaioj0qlROZ2z4rAY+KJwVYZEx+GLFaXy58Q7CWswCmk0ErOy1c+FMqQpcSt5EnkRE+sZwQ0RJXnhzbreKGFavMMzMgGXH7qDlFB/czN0akM7GHqWB0MfA0o7AhqFcgJOIDIbhhoiSzNzcDJ/VKYSFPSvDLZM1LvoHo+nE/djsnwnotQPwHqg98NhsYNoHgN9JQxeZiDIghhsiSrZqBd2w8bMaqJTXFc/Do9Bv0Ql8v/k6Iur8AHReAzh6Ao+uAjPrAvvGAzHGO4KSiEwPww0RpYi7ky0W966MT2vmV9uzD9xE++k+8MtSBeh3ECjWDIiJAnaOAeY1A57eMXSRiSiDYLghohSztDDHyEbFMKNLBTjZWuKk71M0+Xsf9tyNBtrNB5pPBqwzAbf3A1OqcWZjIkoTDDdE9N7qFXdXzVSlcjjjyYtIdJtzBBN2XkWMVyeg7z4gZ0UgPEg7s7HMjxMWZOgiE5EJY7ghIr3I5WqPlf280alybrWy+IQdV9Ft7lE8tskJdN8C1BwBmJkDZ5cDU6oDtw8aushEZKIYbohIb2wsLfBTy1IY385LTfa398oDfPT3Ppzyew7UHgn02ApkzgsE+QJzmwA7vweiIw1dbCIyMQw3RKR3rcrlVItv5nNzULMat516EAt8bkEjzVN99wNlPtGuTbXvD2BWfeCRdv0qIiJ9YLgholRR1MMJ6wZWQ8MSHoiM1uDbtecxZNkpvDCzA1pMBtrOBWxdAL8TwNTqwPF5UO1ZRETvieGGiFKNo60VpnxSDt80KQYLczOsPeWH5pMO4Frgc6BES+2Q8bw1gMgXwPrPgGWfAC8eG7rYRJTOMdwQUaoyMzNDrxr5saR3FWRztMHVwOdoPmk/1p/2A5xzAF3WAfW+B8ytgEsbgH+8gev/GbrYRJSOMdwQUZqolM8VGz6rjir5XRESEY1BS07i69VnERatAaoNBnrvBNwKA88DgAUtgS1fAZFhhi42EaVDDDdElGayOdqqdakG1i6oFt9cdNgXrf45iFsPQwBPL6DPHqBCT+3BhyYDM2oDAWcNXWwiSmcYbogozWc1/qJBEcztXkmtNH7BPxgfTdyPjWf8AWt74KPxQMelgL0bEHgBmF4b2P8n16cioiRjuCEig6hZOCs2xVl8c8DiExi19hzCo6KBIo2A/oeAIo2BmEhgx3faeXGe3DJ0sYkoHWC4ISKD8XDWLr7Zv1YBtT3f5zZaTzmI249CgExZgQ6LgWaTtOtT+fpo16c6uZBDxokoUQw3RGTwZqrhDYtiTveKyGxvhXP3gvHR3/ux+ay/DLUCynXWTvyX2xuIeA6sHQAs7QQ8f2DoohORkWK4ISKjULtINmwaXAMV8mTGs/Ao9Ft0At+tO4+IqBjANR/QbSNQ9zvtkPHLG4Ep3sDlzYYuNhEZIYYbIjIans52WNKnCvrW1DZTzT14C22n+eDukxeAuQVQfSjQ+z8gazEg5AGwpAOw7jMg/Lmhi05ERoThhoiMipWFOUY0KopZXSvA2c4Kp+88RZO/9+O/S/e1B3iWBvrsBrwHyhSBwIl52uUb7hwxdNGJyEgw3BCRUapTzB0bBlWHV05nBIVGosfcY/h1yyVERccAVrZAg5+ArusAp5zAk5vA7AbAfz9xlXEiYrghIuOVy9UeK/pWRbeqedX2lN3X8fHMw7gf/HLm4nwfAP0OAKXaaVcZ3/ubdpXxh1cNW3AiMiiGGyIyataW5viuWQlM/rgcMtlY4sjNx2jy9z4cuPZQe4CdC9B6BtBmNmDr/HKV8RrA0ZkcMk6UQTHcEFG60KS0J9YNrIaiHo54+DwCn8w6jL93XkVMzMsAU7I10M8HyFcTiAoFNn4OLGoLPHvZV4eIMgyGGyJKN/JnzYQ1A6qhfYVcqlJm/PYr6DL7CAJ1zVSyynjnNUCDsYCFDXBtO/BPFeDiekMXnYjSEMMNEaUrtlYW+LVNaYxr6wVbK3Psv/YQDf/ah12XArUHmJsD3v21I6rcSwGhj4FlnwCrPgVCnxq6+ESUBhhuiChdalM+pxpNVczTCY9DItB97lGMWX9euzaVcC8O9N4JVBsCmJkDZ5YCU6oC1/8zdNGJKJUx3BBRulUwmyNW9381mmrOgVtoMfkgrgU+0x5gaQPUGwN03wJkzgcE3wMWtAQ2fgFEhBi28ERk2uFm8uTJyJs3L2xtbVG5cmUcOfL2ybhq1aoFMzOzN25NmjRJ0zITkfE0U8loqtndKsDVwRoX/YPx0cT9WHLEFxrdaKnclbVDxiv20m4fncGJ/4hMmMHDzbJlyzBs2DCMHj0aJ06cgJeXFxo0aIDAwJft569ZtWoV/P39Y2/nzp2DhYUF2rZtm+ZlJyLj8WFRd2wZXAPVC7ohLDIGI1edxYDFJxD04uWkftYOQJM/gE9WAY7Zgcc3tBP/7RgDRIUbuvhEpEdmmtg/bQxDamoqVqyISZMmqe2YmBjkypULgwYNwogRI975+AkTJmDUqFEq6Dg4OLzz+ODgYDg7OyMoKAhOTk56eQ9EZDxkaPj0fTcwbutlRMVokMPFDhM6lEHFvK6vDgp9Amweoe2HI9xLAi2nAR4lDVZuItLf9dugNTcRERE4fvw46tat+6pA5uZq28fHJ0nPMWvWLHTo0CFJwYaITJ+5uZlaePPfflWRJ4s97j0NRYfph9TsxrFz4thlBlpNA9otAOyzAPfPAdNrAfv+AKKjDP0WiOg9GTTcPHz4ENHR0XB3d4+3X7YDAgLe+XjpmyPNUr16vWxHT0B4eLhKe3FvRGT6vHK5YONnNdCybA5Ex2jUulS95x/D0xcRrw4q3gzofwgo0gSIiQR2fq9tquLyDUTpmsH73LwPqbUpVaoUKlWq9NZjxo4dq6qxdDdp8iKijEGWaxjfzgtjW5VSyzjsvBSoVhg/dSfOfDeZsgEdFgEtpgI2zsC9Y9rlGw5NlTYuQxafiNJjuHFzc1Odge/fjz89umx7eHgk+tiQkBAsXboUPXv2TPS4kSNHqvY53e3OnTt6KTsRpQ8ymrJjpdxqyLiumart1IOYe+Dmq9FUZmZAmY5A/4NA/tra5Ru2fAnMbwY8uW3ot0BE6SncWFtbo3z58ti5c2fsPulQLNve3t6JPnbFihWqyemTTz5J9DgbGxvV8SjujYgynhLZnbF+UHU0KumByGgNvlt/AQMXn8SzsJejqYRzTqDzau2oKit74NY+YEo14MR8LsJJlI4YvFlKhoHPmDED8+bNw8WLF9GvXz9VK9O9e3d1f5cuXVTtS0JNUi1atECWLFkMUGoiSo+cbK3wT6dyGPVRcViam2HjWX80nbgfF/zi9MWTWhyZD6fvfiBXFSDiGbBuELC4HRDsb8jiE1F6CTft27fHuHHj1HDuMmXK4NSpU9iyZUtsJ2NfX181zDuuy5cvY//+/e9skiIiSqiZqkf1fFje1xvZnW1x69ELtPznAJbGnfRPZCkAdN8E1PsBsLAGrm7TLsJ5ZgVrcYiMnMHnuUlrnOeGiHSehERg6PJT2H35gdpu6pUdP7YoCWc7q/gHBl4EVn8K+J/WbhdrCjT5E8iU1QClJsqYgtPLPDdERIaU2cEas7tWxP8aFIGFuRnWn/ZD47/24fjtx/EPzFYM6LUTqPUVYG4JXFwP/FMZuLDWUEUnokSw5oaICMAJ3ycYvPQk7jwOVUFncJ1CGFC7oPo5Hqm9Wd0PCDyv3S7ZBmj8O2AfZwZkItI71twQESVTudyZ1aR/zctkV5P+jd9+BR1nHILf09D4B3p6AX12AzW+AMwsgHMrtX1xLm82VNGJ6DWsuSEies2qE3fx7ZpzCImIVv1vfm1dCg1Ler554L3j2lqch5e1214fAw3HAnYuaV5mIlMXzJobIqKUa1Uup6rF8crpjKDQSPRdeAIjV53Bi4jX1p3KUR74dC9QdZD8rQicXgz84w1c22GoohMRa25Yc0NEbxcRFYM/d1zB1D3X1ejvAlkd8HfHsmpCwDf4HgLW9AMe39Bul+0MNPgJsE3gWCJKNtbcEBHpgaxH9WXDoljYszKyOdrg+oMQtJh8ANP2xFlhXCd3FaDvAaByP20tzskF2lqcq6zFIUprrLkhIkqCxyERGPHvGWy7oF0Lzzt/FvzRzgvZXezePPj2QWBNf+DJTe122U+ABj+zFofoPbDmhohIz1wdrDGtc3n80qoU7Kws4HPjERpO2IsNZ/zePDhPVaDfwTi1OAtZi0OUhlhzQ0SUTDcfhmDI0pM4fTdIbbcqlwNjmpWAo+1rMxsL1uIQ6QVrboiIUlE+Nwes7FcVA2sXhMzxt+rEPTT+O4GZjROrxbmyzRBFJ8oQWHNDRPQejt56jCFLT+He01AVdCTwDKpTCFYW5u+uxSnZGmj4C5ApW5qXmyi9Yc0NEVEaqZjXFZuH1ECrsjkgA6j+/u8aWk85iKv3n729Fsd7IGBmDpz7F5hUATgxnyuNE+kRa26IiPREFt78evVZBIdFwdrCHMPqF0bvGvnfXJ9K+J0E1n0GBJzRbuepDjSdALgVSvNyE5na9ZvhhohIj+4Hh6kh47suP1Db5XK7YFxbL+TPmunNg6OjgMNTgV0/AZEvAAtr7ZpV1YcAljZpX3giI8ZwkwiGGyJKbfJrdcXxu/hh/QU8C4+CjaU5hjcsiu5V88I8oVqcJ7eBjZ8D17Zrt92KAE3/AvJ4p3nZiYwVw00iGG6IKK1IJ2Opxdl39aHarpTPFePaeCF3Fvs3D5ZfxedXAZu/BEK0tT4o3w2oMxqwd03jkhMZH4abRDDcEFFakl+xi4/44qeNF/EiIhr21hYY2agoOlXOk3AtzovHwI7R2k7Gwj4LUO8HwKsjYM4xIJRxBTPcvB3DDREZwp3HL/DFitM4fFM7F071gm74rU3phJdvELcOaJuqHlzUbuf2Bpr8AbiXSMNSExkPhptEMNwQkaHIYpvzfW7hly2XEBYZA0dbS3zfvARalMkBM7MEanGiI4FDU4DdvwCRIYCZBVClH1BrBGDjaIi3QGQwDDeJYLghIkO78eA5hi0/jVN3nqrtxqU88GOLUmr9qgQF3QW2jAQurtNuO3oCDccCxVsACYUiIhPEcJMIhhsiMgZR0TGYsvs6/tp5FVExGrhlssFvbUrhw6Lub3/Q1e3Apv+9muG4wIdA43FAlgJpVm4iQ2G4SQTDDREZk3P3gjB02SlcDXyutjtWyoWvmxRHJhvLhB8QGQbs/1N7iw7Xzo0jMx7X+BywSWAuHSITwXCTCIYbIjI2YZHRGLf1MmYduKlGhOdytcMfbcuooeNv9eg6sHk4cG2HdtsxO1D/B+16VWyqIhPEcJMIhhsiMlY+1x+pEVUyP47kE1m6YWjdwrCztkj4AfLr+/JmYOtI4MmtV6OqGv0GeJZO07ITpTaGm0Qw3BCRMXsWFonv119QMxyL3K72+KllSdQolPXtD5KmKp+JwL7x2mUcZFFOmQDww285ASCZDIabRDDcEFF6sOPCfXy79hz8g8LUtqw6/s1Hxd8+oko3qmr7KO1q48LWBfjwG6B8d8DiLX14iNIJhptEMNwQUXrxPDxK9cWZ53NLtUBltrfCN02Ko1W5t8yLE3cCQOmPc/+cdtu9JNDoVyBv9TQrO5G+MdwkguGGiNKbk75PMHLVWVwKeBY7u7E0VeXJ4vD2B8mK48fnAP/9CIRp59NR8+JIp2OX3GlUciL9YbhJBMMNEaVHkdExmLnvJibsuILwqBi10viQuoXRq0Y+WFkksuaUrFW16yfg2GxAEwNY2gLVBgPVhgDWCSzgSWSkGG4SwXBDROnZ7Uch+Hr1Oey/pl1pvKiHI35tXRpeuVwSf2DAOWDLCODWPu22Uw6g3vccOk7pBsNNIhhuiCi9k1/bq0/eww8bLuDJi0jI4uK93jVsXPtA7RIOW78BgnzjDB3/FfD0SrPyE6UEw00iGG6IyFQ8eh6O7zdcwNpTfmo7TxZ7jG1VClULuCX+wMhQ4ODLoeNRoXIpAMp10Q4dz5TIkHMiA2K4SQTDDRGZmp0X76umqoBg7bDxjpVyY2TjonCytUr8gWro+Gjg3ErttrUjUGMoUKU/YGWXBiUnSjqGm0Qw3BCRqU7+9+uWS1h4SNvc5O5ko1Yar1c8kYU4dW77aPvj+J/SbjvlBOqMAkq1BcwT6axMlIYYbhLBcENEpuzwjUcYseosbj4MUdsflfbEd81KqFXHExUTA5xdAez8HgjWzo4MzzJAg584Pw4ZBYabRDDcEFFGWIhzwo6rmLHvBqJjNHCxt8KXDYuiXYVcsJDex+/qj3PoH2Dfn0CEdl4dFGmsHVnlVihNyk/0vtdvo6hvnDx5MvLmzQtbW1tUrlwZR44cSfT4p0+fYsCAAfD09ISNjQ0KFy6MTZs2pVl5iYiMma2VBUY0Koq1A6qhuKcTnr6IVJMAtph8AMdvP0n8wdLXpsbnwGcngYq9ADML4PImYHJlYOMXQIh2CDqRMTN4zc2yZcvQpUsXTJ06VQWbCRMmYMWKFbh8+TKyZcv2xvERERGoVq2auu+rr75Cjhw5cPv2bbi4uMDL691DGVlzQ0QZbfK/BT638eeOK3gWFhW7TpWEn2xOtu9+ggeXtZ2Or2x+1em46kDAewBg45jKpSdKp81SEmgqVqyISZMmqe2YmBjkypULgwYNwogRI944XkLQ77//jkuXLsHK6h0jARLAcENEGdHD5+H4fctlLD9+R01342Btgc/qFEL3avlgbZmESvwbe4Dt3wL+p7Xb9lm0NTwVegJWSQhJRBkl3EgtjL29PVauXIkWLVrE7u/atatqelq7du0bj2ncuDFcXV3V4+T+rFmz4uOPP8aXX34JC4s3J68KDw9Xt7gnR8ITww0RZUSn7zzF6HXnceqOdr2p/G4OGNW0OGoVebOmPMFOxxfXaterenTt1ciqWl8CXh9z5XFKVemmz83Dhw8RHR0Nd/f4QxVlOyAgIMHH3LhxQ4UheZz0s/n222/xxx9/4Mcff0zw+LFjx6qTobtJsCEiyqhkmYZV/apiXFsvNYLqxsMQdJtzFL3mHVVLOyRKhoWXaAn0Pww0/Vu7hIOMrFo3CPinCnB+jXYWZCIDM2jNjZ+fn+ozc/DgQXh7e8fuHz58OPbs2YPDhw+/8RjpPBwWFoabN2/G1tSMHz9eNVX5+/u/cTxrboiIEhYcFomJO69izoFbiIrRwNrCHD2q58PADwsik00SamEiw4CjM4F9fwChj18NH5c5cgp8yDWrKGPW3Li5uamAcv/+/Xj7ZdvDwyPBx8gIKQk4cZugihUrpmp6pJnrdTKaSk5C3BsREUHNYPx1k+LYMuQDfFA4KyKiYzB1z3XUHrcbK4/fRUzMO/72lb420rl48Gmg5peAdSbtRIALWwFzGgE3Xy7SSZTGDBpurK2tUb58eezcuTN2n3Qolu24NTlxyUipa9euqeN0rly5okKPPB8RESVPwWyZMK97RczqWgF5s9jjwbNwfLHiNFpOOYiTvu8YOi5snYDaX2lDjizdYGED+PoA8z4C5jUFfA+lxdsgMp55boYNG4YZM2Zg3rx5uHjxIvr164eQkBB0795d3S/DxEeOHBl7vNz/+PFjDB48WIWajRs34ueff1bz3hARUcqYmZmhTjF3bB36gRomLqOppPNxy38OYtjyUwh8uW5VohzcgIZjgcGntHPkmFsBN/cCsxsAC1oBd4+nxVshMvxQcCHDwKXPjDQtlSlTBn///bcaIi5q1aqlJvibO3du7PE+Pj4YOnQoTp06pfrs9OzZ862jpV7HoeBERO8W+CwMv225rJqnhISdAR8WRM/q+WBj+e7ftcrTO8De34FTi4AY7Rw7KNxQW8vj+e55yYjS5VBwQ2C4ISJKOqm9+W79eZz01Q4dz+1qj68aF0ODEu6qtidJHt8E9vwGnFkKaF52KSjWFKg1EnAvkYqlJ1PCcJMIhhsiouSRjsVrT9/D2E2XEPhMO/q0Sn5XfPtRcZTI7pz0J3p4DdjzC3B2JYCXlx4ZWl5zBJCtaCqVnkwFw00iGG6IiFImJDxKjaaavvcGwqNi1EjvDhVzYVi9Isjq+I5Vx+MKvAjs/gW4sOblDjOgVBvtiCsuzklvwXCTCIYbIqL3c/fJC/yy+RI2nNHOLSZz4sjcON2r5U16fxwRcA7YPRa4tEG7bWYOlO4A1Pwf4Jo/lUpP6RXDTSIYboiI9OPorcf4fv0FnL0XlPL+OMLvlLYmR7c4p6xEXuZj4IP/AZnzpFLpKb1huEkEww0RkX7746w6eQ+/bYnfH0dCTumcLsl7MhkqLjU517Zrt80ttSFHFujMnDcVSk/pCcNNIhhuiIhSpz/OlN3XMX3fDUREaUdENfPKjv81KIJcrvbJe7I7R4BdPwE3dr+qyfHqCNQYBmQpkAqlp/SA4SYRDDdERKnbH+ePbVew+uQ9tS3rVXWtmgcDaheEi30yZ5GXmY33/Apc/+9Vn5xS7YAPvmDH4wwomOHm7RhuiIhS37l7QRi7+SIOXHuktp3trDCwdkF09s4DW6tkdDoWd44Ce38Drm57ucMMKNla2yeHQ8gzjGCGm7djuCEiShtyedlz5YEaWXUp4Jnal8PFDsMbFkHT0tlhbp7MVcPvndDOeHx508sdZkDx5tqQ41FS/2+AjArDTSIYboiI0lZ0jAb/nriLP7Zdxv1gbafjkjmc8GXDoqhRKGvyn9D/tDbkXFz/al+Rxtrmqhzl9VhyMiYMN4lguCEiMozQiGjMPnBTdTx+Hq5da6pqgSwY3rAoyuRK5sgqcf+8dlmHC2tfzXhcoI62JiePt55LT4bGcJMIhhsiIsN69Dwck3ddx8JDtxERrR1Z1bCEB75oUBgFszkm/wkfXAH2jwfOLAc00dp9eapra3Ly15Ilz/X8DsgQGG4SwXBDRGQ8I6sm7LiKVSfuIkYDSBecNuVzYkjdwsjuYpf8J5QFOg9MAE7KKuSR2n05Kmhrcgo3YMhJ5xhuEsFwQ0RkXK7cf4ZxWy9j24X7atva0hxdquRB/9oF4eqQzOHjIugecPBv4PhcICpMu8+9JFBtMFCiFWBhqed3QGmB4SYRDDdERMbphO8T/Lr5Eg7ffBy7ZlWvGvnQs3o+ONpaJf8JnwcCPpOBozOBiOfafc65gaoDgbKfANYOen4HlJoYbhLBcENEZLzkkrT36kO1nMN5v2C1L7O9FfrXSuEcOSL0iTbgHJoKvHio3WfnClTqo705ZNHzu6DUwHCTCIYbIqL0sWbVpnP+GL/tCm48DFH73J1sMOjDQmhfMResLMyT/6SRocCpRcDBicCTW9p9VvZA2c6A9wAu0mnkGG4SwXBDRJR+REXHYNWJe5iw4wr8gsJiVx8fWq8QmnnlgEVyJwIU0VHAxbXA/glAwJlX61eVaAlU6Q/k5Fw5xojhJhEMN0RE6U94VDSWHPbFpF3X8PB5hNpX2D0ThtUrggYl3GGWkpFQcvmTxTllhJVukU6RsxJQpS9QrBlgkYK+PpQqGG4SwXBDRJR+vYiIwpwDtzBtz3UEh0XFznY8uE5h1C2WLWUhR/idAg5NAc79+2oYuVMOoGIvoHw3wN5Vj++CUoLhJhEMN0RE6V9QaCRm7L2hZjx+EaGduK9Edgk5hVCveAprcsSz+8CxWcCx2UDIA+0+SzugdDugSj8gWzE9vgtKDoabRDDcEBGZ1mzHM/bdxHyfW7Ehp7inEz6rUwj1i7snf3FOnahwbS2O1Obo+uWIfDWBij21a1mxySpNMdwkguGGiMj0PA6JwMx9NzDv4C2EvAw5RT0cMaSuhByPlIccuUT6+mhDzqUNgEa7XAQyuWtHWZXvCrjk1uM7obdhuEkEww0Rkel6IiFnv4Sc27GLc0rIkZocWb8qxSFHPflt4MQ84MQCICTw5U4zoGBdoEIPoFB9zn6cihhuEsFwQ0Rk+p6+iMCs/TdV52NdyJHRVTJPTuNSnikbQq4TFQFc3qTtl3Nzz6v9jtmBcl20N+ccengXFBfDTSIYboiIMo6gF5GYdUBCzk08ezm6qkBWBxVyPirtCcuUTAYY16Pr2jWsZHLAF4+0+8zMgYL1gHKdgcIN2TdHTxhuEsFwQ0SUMUdXzT1wC7P234gdQp7PzQEDaxdE8zLZ3z/kSAfki+uBY3OA2/tf7XfICpRur63NyVrkPd9FxhbMcPN2DDdERBnXs7BIzPe5jRn7buDpi8jYGY8l5LQslyNlyzq87uFV4ORC4PQS4Ll2pfPYyQFlwc6SrQAbx/d/nQwmmOHm7RhuiIhI+uEseBlyZKSVyOFihx7V86m1q2RF8vcWHQlc3a4NOle2ABrtKC5YOWiXepBmq1yVgZTOyZPBBDPcvB3DDRERxZ3xeOGh25i+90bssg5OtpboVCUPulXNC3cnW/28kEwOKDU5JxcAj6692u9WWFub49URyJRNP69lohhuEsFwQ0RErwuLjMa/J+5i5r6buPlyFXIrCzM0L5MDvWvkRxEPPTUjySX3zmHtcPLzq4DIF9r95pbazscyd44MLeeQ8jcw3CSC4YaIiN4mJkaDHRfvq+aqo7eexO6vWTgr+nyQH1ULZEn50g6vC38GnFulrc25e/TVfkdPbU2O1OhkKaCf1zIBDDeJYLghIqKkOOH7RM16vOVcAGJeXillaQcJOU1Ke+qn87FO4EVtbc6Zpa+GlIs81bRBp0SLDN8JOZjh5u0YboiIKDluPwrB7P03sfzYXYRGajsFezrbonu1vOhQKTecbPU4j41ugkCpzbm2U9qxtPut7IFiTbVBJ98HgLkFMppghpu3Y7ghIqKULu2w6PBtzD14Gw+fh6t9MqqqQ8Vc6F49nxptpVdBd4Ezy4BTS4BHV1/td8qhnTunzMeAWyFkFMEMN2/HcENERO8jPCoaa0/6qX45VwOfq32ynEOTUp6q83GpnM76fUG5TN87DpxaDJxbCYQFvbovRwXAqwNQohXgkAWmLDi9hZvJkyfj999/R0BAALy8vDBx4kRUqlQpwWPnzp2L7t27x9tnY2ODsLCwJL0Www0REemDXD53X3mg+uUcuPaqn0yV/K7oUS0f6hRzf781rBISGQZc2aytzbm249XcOTLaqsCHQMk2QNHGJtk/JznXb4OPNVu2bBmGDRuGqVOnonLlypgwYQIaNGiAy5cvI1u2hMf8y5uS+3X01nOdiIgoieTaU7tINnU77xekhpGvP+2HQzceq1vOzHboXCWPmhTQxd5aPy9qZaudAFBuzwOBM8uBsysA/1PA1W3am6UdUKQRUKotULAOYGmjn9dORwxecyOBpmLFipg0aZLajomJQa5cuTBo0CCMGDEiwZqbIUOG4OnTpyl6PdbcEBFRavEPCsW8g7ex9Khv7PIOtlbmaFk2B7pWzYuiHql03Xl4TdtkJUHnUZxJAm2dgeLNtTU6eaun647I6aZZKiIiAvb29li5ciVatGgRu79r164qvKxduzbBcNOrVy/kyJFDBaFy5crh559/RokSJRJ8jfDwcHWLe3IkPDHcEBFRak4KuO6UH+YcvIWL/sHxmqxk5uO6xdzff7HOhMgl3f8UcHYlcO5f4Jn/q/scsgHFm2lrfXJ7p7ugk27CjZ+fnwopBw8ehLe3d+z+4cOHY8+ePTh8+PAbj/Hx8cHVq1dRunRp9QbHjRuHvXv34vz588iZM+cbx3/33XcYM2bMG/sZboiIKLXJJVYmA5x78Ca2nr+P6JcT5sjIqo8r50a7CrmQ1TGVmo1iooHbB7W1ORfXAaGvJiVEJndtjY50RJb1rcxTIWjpmUmHm9dFRkaiWLFi6NixI3744Yc37mfNDRERGQO/p6FqHaslR3zx5GWTlaW5GRqU8ECnyrnhrc/ZjxNaxPPmHuDcauDS+vgjrmRG5OIttBMFysrlRhp0TLpZKiFt27aFpaUllixZ8s5j2eeGiIgM3WQlHY8XH/HFSd9X/UfzuTng40q50bp8Trg66KkD8tsmCryxGzgvQWcjEB4n6GTy0I62KvoRkLcGYJmK5TDVcKPrUCzDvmX4t5B+NLlz58bAgQMT7FD8uujoaNXfpnHjxhg/fvw7j2e4ISIiY3HBLxiLj9zGmpN+eB4epfZZW5ijcSkPtTJ5hTyZU3dEcFQ4cH2XNujIzMjhr/oHwcYZKNJQG3Rk1JW1AwwpXYUbGQouNTXTpk1TIUeGgi9fvhyXLl2Cu7s7unTpopquxo4dq47//vvvUaVKFRQsWFDV7sj8OGvWrMHx48dRvHjxd74eww0RERmbkPAorDvtp2ZAPnfvVcAomC0T2lfIhZblcsAtUyoP6Y4KB27uBS6u1wadkAev7pPh5TKPTrGPtKuX27siraWreW7at2+PBw8eYNSoUWoSvzJlymDLli0q2AhfX1+Yx2n/e/LkCXr37q2OzZw5M8qXL6/67CQl2BARERkjBxtLdKyUW93O3H2KRYd8Vdi5FvgcP226iF+3XFIjrGTOnA8KZ9X/5IBC5sMpVE97i/kTuHMEuLRBG3ae3gYub9TezCyAPFWBok2AIo2BzHlgbAxec5PWWHNDRETpwbOwSKw/7Y9lx+7g9J1XfXM8nGzRunwONdIqT5Y0aCrSaID757Qh5+IGIPB8/PvdS74KOp5eMrthqhQjXTVLpTWGGyIiSm8uBQRj+dG7WH3ybuxIK928OR0q5kbDkh6wtUqjeWue3AIubdI2Xd0+AGhiXt3nlFM7O7KEHemQbKG/BiKGm0Qw3BARUXpetHPHhUBVm7Pv6gNVqSJc7K3QulxOdKyUCwWzpeG6Ui8eA1e2apurru0EIl9o91s5AMOvA1b6Wymd4SYRDDdERGQK7j0Nxcpjd7H82B31s06lfK5qSHma1uaIyFDgxp5X/XKaTtDr0zPcJILhhoiITInMerz3ygM1b85/lwJjZ0F+VZuTW426Su8YbhLBcENERKYqIChM1eQsPeILv6Cw2P2V8rqqTsiNSnnCydYK6RHDTSIYboiIKKPU5iw6LLU59/GyMgc2luaoW9wdrcrmUEPKrVJj8c5UwnCTCIYbIiLKaLU5q07exeoT93A18HnsflnioWlpT7QslxNeOZ1TdyZkPWC4SQTDDRERZUQajQbn/YKx6sQ9rDt9Dw+fR8Telz+rA1qWyYHmZXIgdxZ7GCOGm0Qw3BARUUYXFR2DfdceqtqcbRcCEBb5aq6aMrlc0LxMdjQp7YlsjrYwFgw3iWC4ISIiij8T8pZzAVhz6h58rj+K7Z8jKzx4F8iCZl7Z0bCEJ5ztDdsRmeEmEQw3RERECQt8FoaNZ/zVulYnfV8t+SArldcsklUFnTrFssHeOu2XpmS4SQTDDRER0bv5PnqB9Wf8sO6UHy7ffxa7387KQgWcj0p7olaRbGk2USDDTSIYboiIiJLncsAz1QlZanTuPH41G7KDtYUaWt6klKcaWp6aQYfhJhEMN0RERCkjkeHsvSDVdLXhjH+8ZR8y2ViiXnF3VaNTvZAbbCz1G3QYbhLBcENERPT+JD6cuvNUBZ2NZ/3hH2dGZGc7K+z/sjYc9TgbcnKu32nfI4iIiIjSPTMzM5TNnVndvmpcDCfvPFG1OZvO+iO3q71eg02yy8aaGyIiItKXmBgNHoVEIKujDQx1/U4/i0oQERGR0TM3N9N7sEl2GQz66kRERER6xnBDREREJoXhhoiIiEwKww0RERGZFIYbIiIiMikMN0RERGRSGG6IiIjIpDDcEBERkUlhuCEiIiKTwnBDREREJoXhhoiIiEwKww0RERGZFIYbIiIiMimWyGA0Gk3s0ulERESUPuiu27rreGIyXLh59uyZ+n+uXLkMXRQiIiJKwXXc2dk50WPMNEmJQCYkJiYGfn5+cHR0hJmZmd5TpYSmO3fuwMnJSa/PTW/i+U5bPN9pi+c7bfF8G//5lrgiwSZ79uwwN0+8V02Gq7mRE5IzZ85UfQ35oPiPI+3wfKctnu+0xfOdtni+jft8v6vGRocdiomIiMikMNwQERGRSWG40SMbGxuMHj1a/Z9SH8932uL5Tls832mL59u0zneG61BMREREpo01N0RERGRSGG6IiIjIpDDcEBERkUlhuCEiIiKTwnCjJ5MnT0bevHlha2uLypUr48iRI4YuksnYu3cvmjZtqmallFml16xZE+9+6RM/atQoeHp6ws7ODnXr1sXVq1cNVt70bOzYsahYsaKawTtbtmxo0aIFLl++HO+YsLAwDBgwAFmyZEGmTJnQunVr3L9/32BlTs+mTJmC0qVLx05k5u3tjc2bN8fez3Odun755Rf1O2XIkCGx+3jO9ee7775T5zfurWjRomlyrhlu9GDZsmUYNmyYGtZ24sQJeHl5oUGDBggMDDR00UxCSEiIOqcSIBPy22+/4e+//8bUqVNx+PBhODg4qPMv/3Aoefbs2aN+2Rw6dAjbt29HZGQk6tevrz4DnaFDh2L9+vVYsWKFOl6WM2nVqpVBy51eyWzpcoE9fvw4jh07hg8//BDNmzfH+fPn1f0816nn6NGjmDZtmgqXcfGc61eJEiXg7+8fe9u/f3/anGsZCk7vp1KlSpoBAwbEbkdHR2uyZ8+uGTt2rEHLZYrkK7t69erY7ZiYGI2Hh4fm999/j9339OlTjY2NjWbJkiUGKqXpCAwMVOd8z549sefWyspKs2LFithjLl68qI7x8fExYElNR+bMmTUzZ87kuU5Fz5490xQqVEizfft2Tc2aNTWDBw9W+3nO9Wv06NEaLy+vBO9L7XPNmpv3FBERof7qkqaQuOtXybaPj49By5YR3Lx5EwEBAfHOv6w9Ik2DPP/vLygoSP3f1dVV/V++61KbE/d8SzVz7ty5eb7fU3R0NJYuXapqyaR5iuc69UjtZJMmTeKdW8Fzrn/SRUC6FOTPnx+dOnWCr69vmpzrDLdwpr49fPhQ/VJyd3ePt1+2L126ZLByZRQSbERC5193H6VMTEyM6otQrVo1lCxZUu2Tc2ptbQ0XF5d4x/J8p9zZs2dVmJFmVOl3sHr1ahQvXhynTp3iuU4FEiCl+4A0S72O32/9kj8y586diyJFiqgmqTFjxqBGjRo4d+5cqp9rhhsieutft/JLKG4bOemf/OKXICO1ZCtXrkTXrl1V/wPSvzt37mDw4MGqP5kM/qDU1ahRo9ifpW+ThJ08efJg+fLlavBHamKz1Htyc3ODhYXFGz28ZdvDw8Ng5coodOeY51+/Bg4ciA0bNmDXrl2q06uOnFNpin369Gm843m+U07+ei1YsCDKly+vRqtJ5/m//vqL5zoVSFOIDPQoV64cLC0t1U2CpAxIkJ+l1oDnPPVILU3hwoVx7dq1VP9+M9zo4ReT/FLauXNnvOp82ZaqZkpd+fLlU/8Q4p7/4OBgNWqK5z/5pM+2BBtpGvnvv//U+Y1LvutWVlbxzrcMFZd2dJ5v/ZDfH+Hh4TzXqaBOnTqqGVBqynS3ChUqqL4gup95zlPP8+fPcf36dTVtR6p/v9+7SzJpli5dqkbnzJ07V3PhwgVNnz59NC4uLpqAgABDF81kRjacPHlS3eQrO378ePXz7du31f2//PKLOt9r167VnDlzRtO8eXNNvnz5NKGhoYYuerrTr18/jbOzs2b37t0af3//2NuLFy9ij+nbt68md+7cmv/++09z7Ngxjbe3t7pR8o0YMUKNRLt586b67sq2mZmZZtu2bep+nuvUF3e0lOA515/PP/9c/S6R7/eBAwc0devW1bi5ualRmKl9rhlu9GTixInqQ7K2tlZDww8dOmToIpmMXbt2qVDz+q1r166xw8G//fZbjbu7uwqZderU0Vy+fNnQxU6XEjrPcpszZ07sMRIa+/fvr4Ys29vba1q2bKkCECVfjx49NHny5FG/N7Jmzaq+u7pgI3iu0z7c8JzrT/v27TWenp7q+50jRw61fe3atTQ512byn/ev/yEiIiIyDuxzQ0RERCaF4YaIiIhMCsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghogzJzMwMa9asMXQxiCgVMNwQUZrr1q2bChev3xo2bGjoohGRCbA0dAGIKGOSIDNnzpx4+2xsbAxWHiIyHay5ISKDkCAjK7rHvWXOnFndJ7U4U6ZMQaNGjWBnZ4f8+fNj5cqV8R4vqzt/+OGH6v4sWbKgT58+atXhuGbPno0SJUqo15KViGXF87gePnyIli1bwt7eHoUKFcK6deti73vy5IlaLTpr1qzqNeT+18MYERknhhsiMkrffvstWrdujdOnT6uQ0aFDB1y8eFHdFxISggYNGqgwdPToUaxYsQI7duyIF14kHA0YMECFHglCElwKFiwY7zXGjBmDdu3a4cyZM2jcuLF6ncePH8e+/oULF7B582b1uvJ8bm5uaXwWiChF9LL8JhFRMsiK7hYWFhoHB4d4t59++kndL7+a+vbtG+8xlStX1vTr10/9PH36dLWS8PPnz2Pv37hxo8bc3FwTEBCgtrNnz675+uuv31oGeY1vvvkmdlueS/Zt3rxZbTdt2lTTvXt3Pb9zIkoL7HNDRAZRu3ZtVRsSl6ura+zP3t7e8e6T7VOnTqmfpSbFy8sLDg4OsfdXq1YNMTExuHz5smrW8vPzQ506dRItQ+nSpWN/ludycnJCYGCg2u7Xr5+qOTpx4gTq16+PFi1aoGrVqu/5rokoLTDcEJFBSJh4vZlIX6SPTFJYWVnF25ZQJAFJSH+f27dvY9OmTdi+fbsKStLMNW7cuFQpMxHpD/vcEJFROnTo0BvbxYoVUz/L/6UvjvS90Tlw4ADMzc1RpEgRODo6Im/evNi5c+d7lUE6E3ft2hULFy7EhAkTMH369Pd6PiJKG6y5ISKDCA8PR0BAQLx9lpaWsZ12pZNwhQoVUL16dSxatAhHjhzBrFmz1H3S8Xf06NEqeHz33Xd48OABBg0ahM6dO8Pd3V0dI/v79u2LbNmyqVqYZ8+eqQAkxyXFqFGjUL58eTXaSsq6YcOG2HBFRMaN4YaIDGLLli1qeHZcUuty6dKl2JFMS5cuRf/+/dVxS5YsQfHixdV9MnR769atGDx4MCpWrKi2pX/M+PHjY59Lgk9YWBj+/PNPfPHFFyo0tWnTJsnls7a2xsiRI3Hr1i3VzFWjRg1VHiIyfmbSq9jQhSAier3vy+rVq1UnXiKi5GKfGyIiIjIpDDdERERkUtjnhoiMDlvLieh9sOaGiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSWG4ISIiIpPCcENEREQmheGGiIiIYEr+D82UI7GfNFDNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 : Set Up Experiment Tracking with Weights & Biases (W&B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/shreya/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_api_key = \"c3095ada488aa1380a09d3c1f47ffb1689bf3ee6\"\n",
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/shreya/Documents/CS203_Lab06/wandb/run-20250226_181246-gbg1uv8v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6/runs/gbg1uv8v' target=\"_blank\">sage-gorge-115</a></strong> to <a href='https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6' target=\"_blank\">https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6/runs/gbg1uv8v' target=\"_blank\">https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6/runs/gbg1uv8v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr><tr><td>training_loss</td><td>██▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.8</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>f1_score</td><td>0.79167</td></tr><tr><td>precision</td><td>0.8254</td></tr><tr><td>recall</td><td>0.8</td></tr><tr><td>training_loss</td><td>0.45456</td></tr><tr><td>validation_loss</td><td>0.48264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-gorge-115</strong> at: <a href='https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6/runs/gbg1uv8v' target=\"_blank\">https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6/runs/gbg1uv8v</a><br> View project at: <a href='https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6' target=\"_blank\">https://wandb.ai/shreya-mali-indian-institute-of-technology-gandhinagar/cs203-lab6</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250226_181246-gbg1uv8v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initializing W&B\n",
    "wandb.init(project=\"cs203-lab6\", config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"architecture\": \"MLP\",\n",
    "    \"dataset\": \"Iris\"\n",
    "})\n",
    "\n",
    "#logging model architecture and hyperparameters\n",
    "wandb.config.update({\n",
    "    \"layers\": [4, 16, 3],\n",
    "    \"activations\": [\"relu\", \"softmax\"]\n",
    "})\n",
    "\n",
    "#logging metrics\n",
    "wandb.log({\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1\n",
    "})\n",
    "\n",
    "#logging confusion matrix\n",
    "wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "    y_true=y_test_classes,\n",
    "    preds=y_pred_classes,\n",
    "    class_names=iris.target_names\n",
    ")})\n",
    "\n",
    "#logging loss curves\n",
    "for epoch in range(len(history.history['loss'])):\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"training_loss\": history.history['loss'][epoch],\n",
    "        \"validation_loss\": history.history['val_loss'][epoch]\n",
    "    })\n",
    "\n",
    "#finish W&B run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 : Manual Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val, y_val = torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(batch_size, learning_rate, epochs, model, X_train, y_train, X_test, y_test):\n",
    "    # Create DataLoader for mini-batch training\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Define MLP Model\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MLP, self).__init__()\n",
    "            self.fc1 = nn.Linear(4, 16)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc2 = nn.Linear(16, 3)\n",
    "            self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.softmax(self.fc2(x))\n",
    "            return x\n",
    "\n",
    "    model = MLP()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test).numpy()\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        y_true_labels = np.argmax(y_test.numpy(), axis=1)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "    f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
    "\n",
    "    return accuracy, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2, LR: 0.001, Epochs: 1 -> Accuracy: 0.3667, F1: 0.2310\n",
      "Batch: 2, LR: 0.001, Epochs: 3 -> Accuracy: 0.7000, F1: 0.6238\n",
      "Batch: 2, LR: 0.001, Epochs: 5 -> Accuracy: 0.7000, F1: 0.6238\n",
      "Batch: 2, LR: 1e-05, Epochs: 1 -> Accuracy: 0.3333, F1: 0.1961\n",
      "Batch: 2, LR: 1e-05, Epochs: 3 -> Accuracy: 0.3667, F1: 0.2619\n",
      "Batch: 2, LR: 1e-05, Epochs: 5 -> Accuracy: 0.1333, F1: 0.1111\n",
      "Batch: 4, LR: 0.001, Epochs: 1 -> Accuracy: 0.4667, F1: 0.4329\n",
      "Batch: 4, LR: 0.001, Epochs: 3 -> Accuracy: 0.6667, F1: 0.6337\n",
      "Batch: 4, LR: 0.001, Epochs: 5 -> Accuracy: 0.5333, F1: 0.4316\n",
      "Batch: 4, LR: 1e-05, Epochs: 1 -> Accuracy: 0.3667, F1: 0.2315\n",
      "Batch: 4, LR: 1e-05, Epochs: 3 -> Accuracy: 0.3333, F1: 0.1709\n",
      "Batch: 4, LR: 1e-05, Epochs: 5 -> Accuracy: 0.4333, F1: 0.3340\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [2, 4]\n",
    "learning_rates = [1e-3, 1e-5]\n",
    "epochs_list = [1, 3, 5]\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epoch in epochs_list:\n",
    "            acc, f1, cm = train_model(batch, lr, epoch, model, X_train, y_train, X_test, y_test)\n",
    "            results.append((batch, lr, epoch, acc, f1, cm))\n",
    "            print(f\"Batch: {batch}, LR: {lr}, Epochs: {epoch} -> Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAGJCAYAAAD47Ca7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPFVJREFUeJzt3Qd8E+X/B/BvCnSwoeyNILtMQYWfIIIgIlsRBNlDKMgW+SvTgRuUqSiICOJAAQEZIiBatkxBhiAgMlpWGWUI9399nnIxSVOappcmffp5+zpJLmnuyd3lvvd9xp3NMAxDiIiINBPk7wIQERH5AgMcERFpiQGOiIi0xABHRERaYoAjIiItMcAREZGWGOCIiEhLDHBERKQlBjgiItJSmgtwBw8elEaNGkmOHDnEZrPJwoULLf38v/76S33up59+aunnpmUPP/ywmiheiRIl5IknnvB3MYg8snbtWnVM++abbyS98SrA/fnnn9K7d2+55557JDQ0VLJnzy516tSR999/X+Li4sSXOnfuLLt375bXXntN5syZI/fdd5/ookuXLmpHxPp0tx4R3PE6pnfeeSfZn//PP//ImDFjZMeOHZKWgon5nTFhf7v33ntl2LBhcu7cOa8+MyoqSq2HCxcuSKD4448/5IUXXpCqVatKtmzZpGDBgtK0aVPZunVrij4X66xfv353fQ9OXhzXcVhYmFSuXFkmTpwot2/f9nrZ+/fvl0GDBknt2rXVdsNn4wTSV7Bd//e//0nmzJmlQIEC8vzzz8vly5fdHuzdTRs3bvRquXf7TEzz58+X9GrlypXSvXt3qVSpkmTIkEH9nlNTxuT+wdKlS+Wpp56SkJAQ6dSpkyr4jRs35JdfflEHnd9//10++ugjnxQWB/0NGzbISy+9lOSP1lvFixdXy8mUKZP4Q8aMGeXq1avy/fffS9u2bZ1emzt3rjpQXLt2zavPRoAbO3as2slwIE3OTupPKOuQIUPUY3z3bdu2qYPvunXrZPPmzV4dCLEecEKRM2dOCQQff/yxfPLJJ9KmTRvp27evXLx4UT788EN54IEHZPny5dKwYUOfLr9IkSIyfvx49TgmJkbmzZunglN0dLQ6mfQGfqsffPCBVKhQQcqXL+/TEyt8doMGDdRy3nvvPfn777/VSSBOCn/44YcE70fwq1mzptO80qVLp6gM7j4THnzwQUmv5s2bJ19++aVUr15dChUqlPoFMJLh8OHDRtasWY1y5coZ//zzT4LXDx48aEycONHwlaNHj+LC0Mbbb79t6Khz585GlixZjEaNGhktW7ZM8Pq9995rtGnTxut1sGXLFvW3s2bN8uj9V65cMfytePHiRtOmTRPMHzp0qPouBw4cSPZnYt3hb48cOWJpmVJi69atxqVLl5zmxcTEGHnz5jXq1Knj9efie0ZGRt71PfXq1TMqVqzoNC8uLk59z2zZshn//vuvV8s+e/asERsba8k6T0qTJk2MggULGhcvXrTPmzFjhlrmihUr7PPWrFmj5n399deWLdsXn2mlNX4s34kTJ4wbN26ox/jNYJ9KTcmqonzrrbdUyo8zTVShuMIZ0IABA+zP//33X3nllVekVKlSKuND5vB///d/cv36dbdtGsgCa9WqpbIUVH9+9tln9vegSgnZFSBTROpvprs4E3eX+uJv8D5Hq1atUtUYOHPPmjWrlC1bVpUpqTa4n376SR566CHJkiWL+tsWLVrIvn373C7v0KFD9uwAbYVdu3ZVWZmnnnnmGXXW6ViFtmXLFnU2itdcoapu6NChEhERob4TqjibNGkiO3fudKpGMc8uUR6z+sT8nqimQjaO7Khu3bqqmsdcL65tcKgmxjZy/f6NGzeWXLlyqUzR11AFZWa8pl27dqn1blad4z3dunWTs2fPOm0j7D9QsmRJ+3pwrDr7/PPP1X6IdYDvg/XhLou92/7qWJ2PKSk1atRQ285ReHi42udc13NqwHfC/nLp0iU5c+aMfT72Y1SnIstLSu7cuVV1qydQFYqsvGLFimrZ+fPnV80g58+fT/JvY2Nj1e+6Y8eOat83oYYJ6/Srr75y+3f4bjhGpSazyhi1MTj24Lti2//8888J3rt9+3b1O8Z3wvdAhuquGhXHCWTbOAbiOItsHN89xmUbYR0jG8frWC4+D8cqRzjGoBYBvx28B+9t166dqlEw4XOxD3hyTEPW5q/aMEhWgEO1GX7IqFP3RI8ePWTUqFEqPZ0wYYLUq1dPVYNghbnCin7yySfl0UcflXfffVcdWHCwQpUntG7dWn0GtG/fXrW/4QeRHPgsBFIE2HHjxqnlNG/eXH799de7/t2PP/6oDt74oeMAOXjwYFXNhXZHd20KqFrEjwffFY8RRFAl5il8V/wQvv32W6dUv1y5cmpdujp8+LDqbIPvhuoZHMDRTon1bQYbVN3gO0OvXr3U+sOEg7cJgQA/KFQJYt3Wr1/fbfnQ1po3b14V6G7duqXmoToNQWDSpEmWV0XcvHlT/agwoeoJ+yG+J8qOIGXCQQ7rAgEc5cB+hvaPxx9/HDUV9nWL/QewP5nrAd8HsJ2effZZ9aPE+sLzokWLqhOc5OyvJhxEMHnr1KlTkidPHvEH82TPsRoXVcLYlyZPnmzpshDMsN+abfnYhggC+N1h+98N9nUEKtf2+ODgYLUvI1C4wucjcOAgjv08pW2dgN+8uZ86Tq53JEPV+sCBA1VAxj6G391jjz0me/bssb8H+xFObnCSirbZkSNHypEjR9SJ5qZNm+zvQ8KB92F/R+c7rLvnnntOBaC///7bablvvPGGfPfdd+pkeMSIESpYdujQwf46mpqwvjG/f//+MmXKFHWswG/K8WQb2x77gDfNA6nO01QPqT/e3qJFC4/ev2PHDvX+Hj16uK1a+umnn+zzkLZi3s8//2yfd+bMGSMkJMQYMmSIfR6qN9xVz6Fqz13qO3r0aPV+04QJE9Tz6OjoRMttLsOxGq9q1apGvnz5VJWLaefOnUZQUJDRqVOnBMvr1q2b02e2atXKCA8PT3SZrlWU8OSTTxoNGjRQj2/dumUUKFDAGDt2rNt1cO3aNfUe1++B9Tdu3DiPqihRTYXXpk+f7vY1TI5Q7YP3v/rqq/aqa3fVqill7huuE6rtUIXn6OrVqwn+/osvvkiwbyVWXYYqdmxTbC/X9Xn79u1k76/me72tlsHn22w2Y+TIkYavqyjR7IDfBaY//vjDGDZsmPpb16pYs7oL+3py3K2Kcv369eq1uXPnOs1fvny52/muUPXmuj1MTz31lPrtmH799VdVzf/JJ58YixYtMsaPH69+m6GhocZvv/1meMNcJ4lNJ0+etL/XnIcqacemFywf+50Jv6Xg4GDjzz//tM9DsxCqjOvWrWufN2rUKPV53377bYJy3b6zz5rlK1++vHH9+nX76++//76av3v3bvV8+/btHlVlmsc5fG5y+KOK0uNOJqgGAE+rHJYtW6b+RbbjCJ0F0PiLziqOGQIaonEmYsIZNVJ4nD1YxTwTXbRokTqDCwpKOoE9efKkasDGWRSqXEzoZYazd/N7OsIZlCN8L5w5YR06VqHcDaoi0ZkHZ/A4s8O/7qonAdUSJmRUONsyq19/++03j5Znfg7WiydwtoizbpyBovsxzoSRxfnC/fffL6+++qp6jOwbZ7Vvv/22yr6RXaPXH5j/mp1RcHaLThqA9eC4f7mDLBjVOKh1cN03XKu6Pd1fve01iNoCbG9kqNj3fA1n/GYWa8L6RXOEI2QQVt8j+euvv1ZV+fg9OVarmdW2a9asSXTfB7PHsePvwIT90rFHMmqfHGug8B2RieP3jKwGHXq8hf3G3T7meNwwO53gu5mKFSummjxQM2HWiKA2pGXLlqrGzIRmIayHGTNm2I8lCxYskCpVqkirVq0SLNfmss/it42s1mSWFfssmiewDWDFihWq1gNV9O6gFgtTWuBxgDMPzEjDPXH06FF1kHDtmYS6XQQavO4IG9kVqn08qYP31NNPP616q6Hq9MUXX1RVR6iywg6eWLAzy4mDlyuk6dgZrly5otrmEvsu+B6A7+JpgMMOhpMJ9EBCgEV7CNaluwMmDsqompg6daqqxjB/JGY7jqcKFy7s9ANICk5UcLKA8qEKNV++fEn+DXrlOZYPBzDXtidXqKJz7EWI7vPYHthu2J6oTjHbIlGliGpJx3YjcGxDSAzayrAfIHglxZf7K/YnVDfjt4Z2vqTWjxXQfoMDJ/YlrAe01WBbIUD4Gtp9sH0S23/MbYn3OAYr7KsIHuaJjWvbvnmi43ji4w5+VwgwaBLAvonu7N5AG7gnvV0xzMVVmTJlVJsW1jngcWLHHGyj48ePq/ZKbCu0mXmi2F2OS4CTKSQkqP5H9TACIE4AUJVqBr+0xuM2OByY0bbiWE/sCdeziMQktlN5craY2DIcD6SAHR2NuTjrRzsLOiUg6OHM0fW9KZGS72LC2SiC7+zZs1X2d7cz2Ndff13tmGiTQgcJBF20R+EHkJxxTEkdCFyhbcM8+KAdxBMI1DgTNSdvxvOB2a7l2DiP9k4cpJFB42CFs2DzjDwl47l8tY3dQTsItjv2TZw84Mw6NeAEDQdnZOZ9+vRRNRNoY3HsgOUr2DYIbthn3U1m2zE6sDnuO1hPYHZ4Q22LK8zzpE0Y7axY9zi50FUGD/ZZtCdj38N2x8kEhj7gOOLanpdWJGscHM4qMcYN41uSGtuBHo/YcXF2hrMO0+nTp1UVmtkj0go4E3E3aNc1SwScoZsN/zhTQXDAuDpUg7g7+zLLiUGr7qp1kF04Zm9WQlCbOXOmKrO7jjkmVBGiute1OgnrxLGDgqcnG57AgQBVHsh2UOWDHraoJnE3DsgRzgwdz8Idq2CSw+z9Zg7kxVno6tWrVQaHqiIT9j9Xia0H9PbFPrt3795kjRO0CpaN3m/4Huj5h05C/oIqO5y5o9oZnRLcZaxWwXrHSSc6mNztJAtVtSiTawaCkwD0pkVHEcexowhYqF1wHU/qDqrpkK2mRrbsbp88cOCAqhI0q4nxOLFjDo4HCMjmuktu0uFJJorp5Zdftnemmz59ur2ZIC1JVi9K7GA4mKOKD4HKFdJlVJWZVWzg2tMRQcWsZrIKNjKqL3Dm4XjmhszHkbsrX5gHMnfVG+bZId6DTMoxiGKnQoZgfk9fQNDCMAv0WjK7xSd2ZuaaOaBd48SJE07zzEBsxRU8hg8fLseOHVPrBdsUVVzoVZnYejThx4ITCXPyNsChvQLQ/uB4duq6Htz1tE1sPaDNAwcPZAyuGZ+3mZmnwwQAVa2okkZVs5md+BN+7+jBaP5mkztMwFMIQKhBwb7u7kTG3E44mXLcd8x2LFSf4TlqLxybUNA7FidAaMs2mVWAjtCmu3jxYpW9etIun1JIEBzbxlHdiGwdy8d+jAmPMc+xSQLHXDQFYJiT2dSB6kmU3/VY580+Gxsbm2DYBAId1onj7zo5wwTSVAaHQIIVjGo9ZGWOVzJBpMdBFV2lzQMPDnjI+LCD4mwUVR44IOJAklgXdG8gu8EBFxkEUmqs+GnTpql6bccdCQcuVGkhuCIzQ/UaDiYY64GdJjHo0IDu88hacdkZZCDolosfli8bW7Fj4SzKk8wa3w0ZFbIpVBciU3INHth+aP/E2Rja93CgRwcOx672nkCXeay30aNH24ctzJo1S3VAQHdmZHNWQqDGwQuwr+EHjcwC2anZ/oYfPKposWwclNGeiBMQtEm6Mg+MyNyx72BIQLNmzVRbDObhQIv2BwQZVBVjDCKqucwrfXhTlZpUZxMEYqxT7GM4eze/rwn7thmYMaYRvx+sf0/2P2Q27s6+sb3utt8joOAEDu2c2K5oz8Vv2NNl46QTvxMwh+LgZA37ICbzakQ4NqDDEtYvMi4c3LFNkOngmIKTZrS33g3aDLHv47PQtR1Vaqhuw2ehC74Jxy5kiXgvqkWRreMYhXWObvSO8P1QI4DaHU+uxbp+/Xq3VxlCNozJhGMmuuPjWIX9C9sdHIcSYXuZY3ZxZRtkqNjnEWgcf18YWoEaHARxjPnEvo0TeQTs6dOn208APf1dY5vgs3DsRLDDSQICrmM7H7ahp+sFSQfKYg6twT5h7osoG353PuVN10tcPaJnz55GiRIlVFdWdF1Ft+1JkyapLuummzdvqq7tJUuWNDJlymQULVrUGDFihNN77nZlCNfu6YkNE4CVK1calSpVUuUpW7as8fnnnycYJrB69Wo1zKFQoULqffi3ffv2TlfDcDdMAH788Uf1HcPCwozs2bMbzZo1M/bu3ev0HnN5rsMQ8FmeXMXBcZhAYhIbJoDu6biSA8qHcm7YsMFt9350ja5QoYKRMWNGp+/p7moWJsfPwZUpsL2qV6+utq+jQYMGqW72WLavhgng8zFkA9vt0KFDTu/9+++/VVfrnDlzGjly5FBdxNG12l239ldeecUoXLiw+jzXbTNz5kyjWrVqqtt/rly51HdftWpVsvdX872edI3Gtr9bV3PH8n3//feJDulwdbfPxDpIatuvXbvWaf0lZ5iAua+6m9ytk48++sioUaOG2odxTImIiDBeeOEFt1dNcgfDDWrXrq263OMKMBgeYV5JxbFrfK1atYzcuXOr3wB+Mx07dlRDRFzhN4VhGvv27UvRMAHHdWUO28DxCVcmwj6Gfc1dl3sMW2jcuLEagpM5c2ajfv36RlRUVIL3YfhSv3791P6M41qRIkXU/hRzZxhNYlcycT3WYbgPhjiVKlVKrUOsIywTxz5vhwmYxz53E8roazb8z7chlIisrjr84osv1Bmxu67xZA1cpQY1PcgirYL238jISMsHypNFF1smIv9C1RCqDBncfAftUagKR5MKpV0McERpDNoEybfQpptUhykKfGnuhqdERESeYIAjIkol6PLA9rd46NGOXpTooYy2SVwqz3VdYUwrhmqh5yuGgrgbQ3g3DHBERJTqcLEIDBXAXQvcwXAI3DAXwx1wBwUMk8HwiuTc8Jm9KImIyK+QwWGwOsZIA8ISMjtcnB9X0gGMocN9AnH7sbtd2ckRMzgiIkoxdMpB71PHyduOOrhAA+6g4nj5RFxYAxemwJVgPJWuelGGVYu/cgIFnvNb2C5B5I3QjIFxjBzeIk+CGzt7erUdVwhugIzNEZ6br3kiXQU4IiK6C5v3lXq4n57r/T/9PVaTAY6IiOKl4I4jCGZWBTTz4vK4wLR5OyTzeXLu9ME2OCIi+i+D83ayEC4AjyCHW0eZ0KaH3pRJ3arNETM4IiJKdbiVEa6n6tixBHeTwF3acf/BgQMHqjsP4A7oCHi4PB16Vpo9LT3BAEdERPEsvCmyJ7dxcrxtmtl+h9usYSgALiqOsXK4/RFuuYZbBy1fvlzdmNZT6WocHHtRBi72oiQKgF6UteLHnHkjbvM7EmiYwRERUapncKmBAY6IiOJZ3FnE3xjgiIhIywxOr3BNRER0BzM4IiKKxypKIiLSkk2vKkoGOCIiiscMjoiItGRjBkdERDqy6ZXB6fVtiIiI7mAGR0REWmZwDHBERBQviG1wRESkIxszOCIi0pGNGRwREenIplcGp9e3ISIiuoMZHBERxWMVJRERacmmV6UeAxwREcVjBkdERFqyMYMjIiId2fTK4PQK10RERHcwgyMionisoiQiIi3Z9KqiZIAjIqJ4zOCIiEhLNgY4IiLSkU2vKkq9wjUREdEdzOCIiCgeqyiJiEhLNr2qKBngiIgoHjM4IiLSko0ZHBERacimWYDTKx8lIiK6gxkcERFpmcExwBERUTy94hsDHBERxWMGR0REWrIxwBERkY5smgU49qIMYHWql5JvJvaWwytfk7jtk6XZw5UTvGdkn6bq9XMb3pOl0/tJqWJ5/VJWijd/3lxp8ugjUrNahHRo95Ts3rXL30WiO7ht0h8GuACWJSxEdh84IQPHf+n29SFdGkrf9vXk+dfnS91O78iVuBvy/ZRICQlmYu4Py39YJu+8NV56942U+V9/J2XLlpM+vbvL2bNn/V20dI/bxvMMztspEDHABbCVv+6VsVOXyOI17s80I5+pL2/OWCFL1u6WPQf/kR4jP5OCeXNI8/pVUr2sJDJn9ixp/WRbadmqjZQqXVpeHj1WQkNDZeG3C/xdtHSP28ZDthRMASggT/VjYmJk5syZsmHDBjl16pSaV6BAAaldu7Z06dJF8uZlNVyJwuEqmP206Q/7vNjL12TLnr/k/sol5OsV2/xavvTm5o0bsm/v79K9Z2/7vKCgIHnggdqya+d2v5YtveO28VygZmLaZHBbtmyRMmXKyAcffCA5cuSQunXrqgmPMa9cuXKydevWJD/n+vXrEhsb6zQZt2+JLgrkya7+PXPuktP8M2cvSf7w+Nco9Zy/cF5u3bol4eHhTvPxHCds5D/cNum3ijLgMrj+/fvLU089JdOnT0+w0gzDkOeee069B9nd3YwfP17Gjh3rNC9D/pqSqWAtn5SbiCitswVooNImg9u5c6cMGjTI7YrGPLy2Y8eOJD9nxIgRcvHiRacpY/4aootTMbHq33y5sznNzxeeTU6fjX+NUk+unLkkQ4YMCTot4HmePHn8Vi7itknPAi7Aoa1t8+bNib6O1/Lnz5/k54SEhEj27NmdJltQBtHFXyfOysnoi1L//rL2edmyhErNSiVk066//Fq29ChTcLCUr1BRNm38r2bh9u3bsmnTBqlcpZpfy5becdt4jlWUPjZ06FDp1auXbNu2TRo0aGAPZqdPn5bVq1fLjBkz5J133pH0IEtYsJQqmtepY0nlMoXlfOxVOX7qvEyZt0aG93hMDh2LVgFvdN+mKugtXrPTr+VOr57t3FVG/t9wqVixklSKqCyfz5ktcXFx0rJVa38XLd3jtvFQYMYpfQJcZGSkqjaYMGGCTJ06VTUOA6oYatSoIZ9++qm0bdtW0oPqFYrLyo8H2J+/NbSN+nfO4o3Sa/Tn8u6nP0rmsBCZ/HJ7yZktTKJ2/CnNI6fK9Rv/+rHU6ddjTR6X8+fOydTJH0hMTLSULVdepn74sYSzGszvuG08E6iZmLdsBnpuBKibN2/aezkh6GXKlClFnxdWrZ9FJSOrnd8y2d9FIEqTQi1MU/J2dX9RCU9Ez3paAk3AtcE5QkArWLCgmlIa3IiIKDDa4FAzN3LkSClZsqSEhYVJqVKl5JVXXlE95bWuoiQiIr29+eabMm3aNJk9e7ZUrFhRjW3u2rWrGu/8/PPPW7YcBjgiIoqXSk1wUVFR0qJFC2natKl6XqJECfniiy/u2oNeuypKIiJKG1WU7q4ehXnu4LKL6BV/4MAB+/jnX375RZo0aWLp92GAIyKiFAc4XD0KVYyOE+a58+KLL0q7du3UpRfRv6JatWoycOBA6dChg1iJVZRERJTiYQK4etTgwYMTXHDDna+++krmzp0r8+bNU21wuDoVAlyhQoWkc+fOYhUGOCIiSnGAQzBLLKC5GjZsmD2Lg4iICDl69KjK+KwMcKyiJCKiVHX16lV1yyJHuJgHLqFmJWZwRESUqr0omzVrJq+99poUK1ZMVVFu375d3nvvPenWrZuly2GAIyKiVL1U16RJk9RA7759+8qZM2dU21vv3r1l1KhRli6HAY6IiFI1wGXLlk0mTpyoJl9igCMiIi0vtsxOJkREpCVmcEREFE+vBI4BjoiI9KyiZIAjIiKFAY6IiLRkY4AjIiId2TQLcOxFSUREWmIGR0RE8fRK4BjgiIhIzypKBjgiIlIY4IiISEs2veIbAxwREemZwbEXJRERaYkZHBERKZolcAxwRESkZxUlAxwRESmaxTcGOCIiihcUpFeEY4AjIiItMzj2oiQiIi0xgyMiIoWdTIiISEs2veIbAxwREcVjBkdERFqyMcAREZGObHrFN/aiJCIiPTGDIyIihVWURESkJZte8Y0BjoiI4jGDIyIiLdn0im8McEREpGcGx16URESkJWZwRESkaJbAMcAREZGeVZQMcEREpGgW3xjgiIgoHjM4IiLSkk2v+MZelEREpCdmcEREpLCKkoiItGTTK74xwBERUTxmcEREpCUbAxwREenIpld8Yy9KIiLSEzM4IiJSWEVJRERasukV3xjgiIgoHjM4IiLSkk2v+MYAR0RE8YI0i3CW9KKcPXu2LF261P78hRdekJw5c0rt2rXl6NGjViyCiIgo9QPc66+/LmFhYerxhg0bZMqUKfLWW29Jnjx5ZNCgQVYsgoiIfMxm837SNsAdP35cSpcurR4vXLhQ2rRpI7169ZLx48fL+vXrrVgEERGlQicTm5dTcp04cUI6duwo4eHhKkGKiIiQrVu3Bl6Ay5o1q5w9e1Y9XrlypTz66KPqcWhoqMTFxVmxCCIi8rEgm/dTcpw/f17q1KkjmTJlkh9++EH27t0r7777ruTKlSvwOpkgoPXo0UOqVasmBw4ckMcff1zN//3336VEiRJWLIKIiDQZJvDmm29K0aJFZdasWfZ5JUuWtHw5lmRwaHN78MEHJTo6WhYsWKBSTti2bZu0b9/eikUQEVEAt8Fdv35dYmNjnSbMc2fx4sVy3333yVNPPSX58uVTydGMGTOs/z6GYRiSToRV6+fvIlAizm+Z7O8iEKVJoRYO9mr64Wav/7bmyWUyduxYp3mjR4+WMWPGJHgvmq9g8ODBKsht2bJFBgwYINOnT5fOnTuL3wPcrl27PH5v5cqVJRAwwAUuBjgi/we4Jz7c4vXfLuhSOUHGFhISoiZXwcHBKoOLioqyz3v++edVoENPfKt4vWqqVq2q6msTi4/ma/j31q1bKSkjERGlgqAUNMElFszcKViwoFSoUMFpXvny5VUTl5W8DnBHjhyxtCBERJQ+OpnUqVNH9u/f7zQPHRSLFy8eGAHO6oIQEZF/2VJpwDYuAIIrXeEiIW3btpXNmzfLRx99pKaAvOHpnDlzVFQuVKiQ/fJcEydOlEWLFlm1CCIi8vG1KIO8nJKjZs2a8t1338kXX3whlSpVkldeeUXFiw4dOlj7faz4kGnTpqneMBj/duHCBXubG65HiUITERE5euKJJ2T37t1y7do12bdvn/Ts2VOsZkmAmzRpkhrD8NJLL0mGDBns89FLBl+AiIgCn02za1Fa0sEUHU4wUM8VetRcuXLFikUQEZGP2QI1Uvkzg8MlVnbs2JFg/vLly1XXTyIiCnw2ZnAJof0tMjJS1aVi7Bt6xKDxEHcT+Pjjj61YBBER+VhQoEYqfwY4XGgZtzt4+eWX5erVq/LMM8+o3pTvv/++tGvXzopFEBGRj9lEL5Zd5AXdOzEhwF2+fFldQJOIiMhfLLyKmciZM2fso9PRWJk3b14rP56IiHzIplkVpSWdTC5duiTPPvusqpasV6+emvAYd2u9ePGiFYsgIiJNbniapgIc2uA2bdokS5cuVQO9MS1ZskTdfrx3795WLIKIiFIhg7N5OWlbRYlgtmLFCvnf//5nn9e4cWM1+Puxxx6zYhFERORjtsCMU/4NcLiDd44cORLMx7xcuXJZsQgiIvIxm2YRzpIqSgwPwFi4U6dO2efh8bBhw2TkyJFWLIKIiCh1Mjhcmssx2h88eFCKFSumJjh27Ji6VFd0dDTb4YiI0oAgvRI47wNcy5YtrS0JERH5lU2zKkqvA9zo0aOtLQkREfmVTfRi6UBvIiJKu4KYwSWEG5xOmDBBvvrqK9X2duPGDafXz507Z8ViiIiIUrcX5dixY+W9996Tp59+Wl25BD0qW7duLUFBQTJmzBgrFkFERD5m0+x2OZYEuLlz56pB3UOGDJGMGTNK+/bt1W1yRo0aJRs3brRiEelSneql5JuJveXwytckbvtkafZw5QTvGdmnqXr93Ib3ZOn0flKqGK//6U/z582VJo8+IjWrRUiHdk/J7l27/F0kuoPbJv1dycSSAIcxbxEREepx1qxZ7deffOKJJ9Tlu8g7WcJCZPeBEzJw/JduXx/SpaH0bV9Pnn99vtTt9I5cibsh30+JlJBgNq36w/Iflsk7b42X3n0jZf7X30nZsuWkT+/ucvbsWX8XLd3jtvEMMzg3ihQpIidPnlSPS5UqJStXrlSPt2zZosbCkXdW/rpXxk5dIovXuD/TjHymvrw5Y4UsWbtb9hz8R3qM/EwK5s0hzetXSfWyksic2bOk9ZNtpWWrNlKqdGl5efRYCQ0NlYXfLvB30dI9bhvPO5l4O2kb4Fq1aiWrV69Wj/v376+uXnLvvfdKp06dpFu3blYsglyUKByugtlPm/6wz4u9fE227PlL7q9cwq9lS49u3rgh+/b+Lg88WNs+D23QDzxQW3bt3O7XsqV33DbpN4OzpC7rjTfesD9GR5PixYtLVFSUCnLNmjWzYhHkokCe7OrfM+cuOc0/c/aS5A+Pf41Sz/kL51VvYlyX1RGeHzly2G/lIm6b9MySDM7VAw88oHpS3n///fL6669b+tnHjx/3KCu8fv26xMbGOk3G7VuWloWISCc2djLxHNrlrL7YMsbUzZ49O8n3jR8/Xt3NwHH69/Q20cWpmFj1b77c2Zzm5wvPJqfPxr9GqSdXzlySIUOGBJ0W8DxPnjx+Kxdx2yQ3IHg7BaKA6263ePHiu75++LBnVQojRoxQWaSjfA8NF138deKsnIy+KPXvLyu7DpxQ87JlCZWalUrIjK9/8Xfx0p1MwcFSvkJF2bRxgzzSoKGad/v2bdm0aYO0a9/R38VL17htPBeomZg2AQ4XccZKNgwjRRsBvTdde3DagjJIWpIlLFhKFc3r1LGkcpnCcj72qhw/dV6mzFsjw3s8JoeORauAN7pvUxX0Fq/Z6ddyp1fPdu4qI/9vuFSsWEkqRVSWz+fMlri4OGnZqrW/i5bucdt4hncT8LGCBQvK1KlTpUWLFm5f37Fjh9SoUUPSg+oVisvKjwfYn781tI36d87ijdJr9Ofy7qc/SuawEJn8cnvJmS1Monb8Kc0jp8r1G//6sdTp12NNHpfz587J1MkfSExMtJQtV16mfvixhLMazO+4bdJngLMZd0uVkuBaBegK94KbN2+e6sHkqebNm0vVqlVl3Lhxbl/fuXOnuhcdqhiSK6xav2T/DaWO81sm+7sIRGlSqIVpyuDF/w07Sq73mpeTQJOiVbN9e9JjSOrWrZusz8RdwK9cuZLo66VLl5Y1a9Yk6zOJiChpbINz4ItA89BDD9319SxZski9evUsXy4RUXoXpFd8C7w2OCIi8g8bAxwREekoSLMIxwBHRERKoA7Y9pZu34eIiEhhBkdERIpmNZTWZXDr16+Xjh07yoMPPignTsRfOmrOnDnyyy+8bBQRUVoQxPvBJbRgwQJp3LixhIWFqbFxuJI/4M7eVt9NgIiIfMOm2f3gLAlwr776qkyfPl1mzJghmTJlss+vU6eO/Pbbb1YsgoiIUmEcXJCXk7ZtcPv373d7xRLcoubChQtWLIKIiHwsKFBTMX9mcAUKFJBDhw4lmI/2t3vuuceKRRAREaV+gOvZs6cMGDBANm3apK5l9s8//8jcuXNl6NCh0qdPHysWQUREPmbTrA3OkirKF198UV3dv0GDBnL16lVVXYl7sSHA9e/f34pFEBGRjwUFaKDya4BD1vbSSy+pOwGgqvLy5ctSoUIFyZo1qxUfT0REqcAmekU4Swd6BwcHq8BGRERpT5Be8c2aAFe/fv273kfop59+smIxRETkQ0EMcAnhDtyObt68KTt27JA9e/ZI586drVgEERFR6ge4CRMmuJ0/ZswY1R5HRESBzxao3SED8W4CuDblzJkzfbkIIiKySBCvZOK5DRs2SGhoqC8XQUREFrEFaKDya4Br3bq103PDMOTkyZOydetWGTlypBWLICIiHwvSLMJZUkWJa046Trlz55aHH35Yli1bJqNHj7ZiEUREpGkV5RtvvKHa/wYOHCgBlcHdunVLunbtKhEREZIrVy5rSkVEROnCli1b5MMPP5TKlSsHXgaXIUMGadSoEe8aQESUxtlS+VqU6GXfoUMHdas1XyRIllRRVqpUSQ4fPmzFRxERkZ8Eic3rCTe6jo2NdZrMm18nJjIyUpo2bSoNGzb00fex6IanuLDykiVLVOcS1y9JRER6Z3Djx49P0B8D8xIzf/58dUPsu73Hr21w48aNkyFDhsjjjz+unjdv3txpoCB6U+I52umIiCiwBaWgs8iIESNk8ODBTvNwVxl3jh8/rm6xtmrVKp8OJbMZiEIpaH9DxrZv3767vq9evXoSCMKq9fN3ESgR57dM9ncRiNKkUAtHM3+08ajXf9vrgeIev3fhwoXSqlUrFUNMSISQEAUFBamqTcfXvJWiVWPGxkAJYEREFPgaNGggu3fvdpqH3vjlypWT4cOHWxLcIMWxX7drlxERpVe2VDqcZ8uWTXVOdJQlSxYJDw9PMN+vAa5MmTJJBrlz586ldDFERORjQZolLCkOcGPHjlW9ZYiIKG2z+TG+rV27NvACXLt27SRfvnzWlIaIiPS8vYwfpCjAsf2NiEgfNs2O6SkK2CkYYUBERBS4Gdzt27etKwkREfmVTfTi0xueEhFR2hGkWRUlAxwRESl6hTcGOCIiukOzBI4BjoiI4rEXJRERURrADI6IiLTMeBjgiIhIyypKBjgiIlL0Cm8McEREdAczuDTsnclD/V0ESkSbTzb7uwiUiAXda/m7CJRKgkQvun0fIiKi9JfBERFR4lhFSUREWrKJXhjgiIhI0SyBY4AjIqJ4QZrlcAxwRESkZQbHXpRERKQlZnBERKTYWEVJREQ6sukV3xjgiIgoHjuZEBGRlmx6xTcGOCIi0jPAsRclERFpiRkcEREp7EVJRERaCtIrvjHAERFRPGZwRESkJZte8Y2dTIiISE/M4IiISGEVJRERaSlIr/jGAEdERPGYwRERkZZsesU3BjgiIoqnWXxjL0oiItITMzgiIlKCNKujZIAjIiJFr/DGAEdERJpGOAY4IiJSOEyAiIi0ZNMrvrEXJRER6YkZHBERKZolcAxwRESkZ4RjgCMiIoWdTIiISEs2veIbAxwREcXTLL6xFyUREemJAY6IiP5L4bydkmH8+PFSs2ZNyZYtm+TLl09atmwp+/fvF6sxwBERkb2Tibf/Jce6deskMjJSNm7cKKtWrZKbN29Ko0aN5MqVK2IltsEREVGqdjJZvny50/NPP/1UZXLbtm2TunXrWrYcBjgiIlJSEt+uX7+uJkchISFqSsrFixfVv7lz5xYrsYqSiIhS3AaHdrUcOXI4TZiXlNu3b8vAgQOlTp06UqlSpSTfnxzM4IiIKMVGjBghgwcPdprnSfaGtrg9e/bIL7/8IlZjgCMiohRfycTT6khH/fr1kyVLlsjPP/8sRYoUEasxwBERUap2MjEMQ/r37y/fffedrF27VkqWLOmT5TDAERFRql7JBNWS8+bNk0WLFqmxcKdOnVLz0W4XFhZm2XLYySQN27r0S/mgW2P5ed40fxeFRCQ8cyYZ+sg98kXn6vJt9/tkypOVpHSeLP4uFt0xf95cafLoI1KzWoR0aPeU7N61y99FSrcDvadNm6Z6Tj788MNSsGBB+/Tll19a+nWYwaVRp4/slz3rlkqeIr5J7Sl5sgZnkLdbVpBd/8TK6GX75eK1m1IoR6hcvvGvv4tGGHf1wzJ5563x8vLosRIRUUXmzpktfXp3l0VLlkt4eLi/i5fu7iZgGEaqLIcZXBp041qcrPjoTXmk80AJyZLN38UhEXmyakGJvnxDJq49Igeir8jpSzdk+9+xcirWeVwQ+cec2bOk9ZNtpWWrNlKqdGkV6EJDQ2Xhtwv8XTTyIQa4NGjt55OlROVaUqxidX8Xhe64v0QuORR9RUY0LC1zO1WTD9pUlMbl8vq7WCQiN2/ckH17f5cHHqxtnxcUFCQPPFBbdu3c7teyBWInE5uXUyAKyAAXFxenxkTs3bs3wWvXrl2Tzz77LMnPwIj62NhYp+nmjbR/Nn1g01qJPnpIaj/Zzd9FIQcFsoXI4xXyyYnYazJy6X5ZtveM9K5TXBqUyePvoqV75y+cl1u3biWoisTzmJgYv5UrHTfBpd8Ad+DAASlfvry6HllERITUq1dPTp48aX8dDZNdu3ZN8nPcjapfOSdtd8a4dO6MrPtimjTuNVwyZgr2d3HIAc5g/4y5Ip9t/lsOn70qy/dFy4p9Z6RJhXz+LhpRuo1wARfghg8fri7XcubMGXX7BHQhxSVcjh07luxR9QiGjlOjZ/tIWnbmr0MSF3tBvhgbKZN6NFHTif27ZMfqRerx7du3/F3EdOv81Zty7Hyc07zjF65J3qw8EfG3XDlzSYYMGeTs2bNO8/E8Tx5m2P64m0BqCbhelFFRUfLjjz+qHQ/T999/L3379pWHHnpI1qxZI1myZPF6VH2m4HOSlhUtX1U6jPvQad6qme9KroJF5b4mbSUoKIPfypbe7T11WQrndB6/UzhHqERfSvvV4mldpuBgKV+homzauEEeadDQfv3DTZs2SLv2Hf1dvIBiC8w4pU8Gh/a3jBn/i7s2m02NmWjWrJmqrkQVZnoVHJZZwouUcJoyhYRKWJZs6jH5z8Ldp6RcvizStlpBKZg9ROqVDpfHyueVJb+f8XfRSESe7dxVvv3mK1m88Ds5/Oef8uq4MepY07JVa38XjdJTBleuXDnZunWraodzNHnyZPVv8+bN/VQyosQdjL4ir648JF1qFZH21QvL6UvX5aOoY7L2kHO1GPnHY00el/PnzsnUyR9ITEy0lC1XXqZ++LGEs4rSiWYJnNiM1Bpx5yF0Dlm/fr0sW7bM7euorpw+fbqqYkiuKb/+ZUEJyReW7WGmE6gWdK/l7yLQXYRamKYcOH3V678tkz+zBJqAC3C+xAAXuBjgAhcDXPoJcAdPO3eUSo5781t3DUltqyiJiMg/bJrVUTLAERGRoll8C7xelERERFZgBkdERFqmcAxwRESkBOoVSbzFAEdERAo7mRARkZZsohcGOCIi0jLCsRclERFpiRkcEREp7GRCRERasukV3xjgiIgonmbxjQGOiIjiMYMjIiJN2UQn7EVJRERaYgZHREQKqyiJiEhLNtELAxwRESnM4IiISEs2zXI4BjgiIoqnV3xjL0oiItITMzgiItIxgWOAIyKieOxkQkREWrJplsMxwBERUTy94hsDHBERaRnf2IuSiIj0xAyOiIgUdjIhIiIt2TSrpGSAIyIiLTM4tsEREZGWmMEREZHCDI6IiCgNYAZHREQKO5kQEZGWbHrFNwY4IiKKp1l8Y4AjIiI9Ixw7mRARkZaYwRERkcJOJkREpCV2MiEiIi3ZRC9sgyMiov8inLeTF6ZMmSIlSpSQ0NBQuf/++2Xz5s1iJQY4IiKyt8F5+19yffnllzJ48GAZPXq0/Pbbb1KlShVp3LixnDlzRqzCAEdERKnuvffek549e0rXrl2lQoUKMn36dMmcObPMnDnTsmUwwBERkb2TibfT9evXJTY21mnCPHdu3Lgh27Ztk4YNG9rnBQUFqecbNmwQyxiU5ly7ds0YPXq0+pcCD7dP4OK28R2sV4QUxwnz3Dlx4oR6PSoqymn+sGHDjFq1allWJhv+Z124pNSAM6McOXLIxYsXJXv27P4uDrng9glc3Da+g2zNNWMLCQlRk6t//vlHChcuLFFRUfLggw/a57/wwguybt062bRpkyVl4jABIiJKscSCmTt58uSRDBkyyOnTp53m43mBAgXEKmyDIyKiVBUcHCw1atSQ1atX2+fdvn1bPXfM6FKKGRwREaU6DBHo3Lmz3HfffVKrVi2ZOHGiXLlyRfWqtAoDXBqEagCMHfG0OoBSF7dP4OK2CRxPP/20REdHy6hRo+TUqVNStWpVWb58ueTPn9+yZbCTCRERaYltcEREpCUGOCIi0hIDHBERaYkBjoiItMQAlwb5+hYT5J2ff/5ZmjVrJoUKFRKbzSYLFy70d5HojvHjx0vNmjUlW7Zski9fPmnZsqXs37/f38UiH2OAS2NS4xYT5B2M4cH2wAkIBRZc/ikyMlI2btwoq1atkps3b0qjRo3UNiN9cZhAGoOMDWeikydPto/+L1q0qPTv319efPFFfxeP7kAG991336lMgQIPxl8hk0Pgq1u3rr+LQz7CDC4NSbVbTBBpDhdbhty5c/u7KORDDHBpSExMjNy6dSvBSH88x5UAiChpqPUYOHCg1KlTRypVquTv4pAP8VJdRJSuoC1uz5498ssvv/i7KORjDHBpSGrdYoJIV/369ZMlS5aoHq9FihTxd3HIx1hFmYak1i0miHSDvnQIbuj489NPP0nJkiX9XSRKBczg0pjUuMUEeefy5cty6NAh+/MjR47Ijh07VEeGYsWK+bVs6R2qJefNmyeLFi1SY+HMNmvc3TssLMzfxSMf4TCBNAhDBN5++237LSY++OADNXyA/Gvt2rVSv379BPNxQvLpp5/6pUz037ANd2bNmiVdunRJ9fJQ6mCAIyIiLbENjoiItMQAR0REWmKAIyIiLTHAERGRlhjgiIhISwxwRESkJQY4IiLSEgMcERFpiQGOtIarVDjedPThhx9Wt0rxx1VOcDWNCxcupNp3DdRyEqUWBjhKdTgQ4yCKCReQLl26tIwbN07+/fdfny/722+/lVdeeSUgD/YlSpRQ1xYlImvwYsvkF4899pi6DuD169dl2bJl6mK4mTJlkhEjRri9kzkCoRV4B2ei9IMZHPlFSEiIuodd8eLFpU+fPtKwYUNZvHixU1Xba6+9JoUKFZKyZcuq+cePH5e2bdtKzpw5VaBq0aKF/PXXX/bPxN3OcbcFvB4eHi4vvPCCuk2KI9cqSgTY4cOHS9GiRVWZkE1+8skn6nPNCyfnypVLZXLmRXlxi6Lx48erW67gSvRVqlSRb775xmk5CNplypRRr+NzHMvpDXy37t2725eJdfL++++7fe/YsWMlb968kj17dnnuuefUCYLJk7I7Onr0qDRr1kytgyxZskjFihXVdyNKC5jBUUDAwfbs2bP257jHHQ7Qq1atUs9v3rwpjRs3Vve9W79+vWTMmFFeffVVlQnu2rVLZXjvvvuuumr/zJkzpXz58uo57v/1yCOPJLrcTp06yYYNG9QdGXCwxy1uYmJiVMBbsGCBtGnTRvbv36/KYt5WBQHi888/l+nTp8u9996rbp7ZsWNHFVTq1aunAnHr1q1VVtqrVy/ZunWrDBkyJEXrB4EJN+j8+uuvVfCOiopSn12wYEEV9B3XW2hoqKpeRVDFbZTwfpwseFJ2V/gOCJB4HwLc3r17JWvWrCn6LkSpBncTIEpNnTt3Nlq0aKEe375921i1apUREhJiDB061P56/vz5jevXr9v/Zs6cOUbZsmXV+014PSwszFixYoV6XrBgQeOtt96yv37z5k2jSJEi9mVBvXr1jAEDBqjH+/fvR3qnlu/OmjVr1Ovnz5+3z7t27ZqROXNmIyoqyum93bt3N9q3b68ejxgxwqhQoYLT68OHD0/wWa6KFy9uTJgwwfBUZGSk0aZNG/tzrLfcuXMbV65csc+bNm2akTVrVuPWrVseld31O0dERBhjxozxuExEgYQZHPnFkiVLVCaAzAzZyTPPPCNjxoyxvx4REeHU7rZz5051M1HcrNLRtWvX5M8//5SLFy/KyZMnne6LhywPN4ZN7I5QuBlphgwZ3GYuiUEZrl69Ko8++qjTfGQ51apVU4/37duX4P58VtxxfcqUKSo7PXbsmMTFxall4n6AjpCFZs6c2Wm5uBErskr8m1TZXT3//POqCnnlypWqGhkZbeXKlVP8XYhSAwMc+QXapaZNm6aCGNrZEIwcoTrMEQ7ONWrUkLlz5yb4LFSvecObOzmjHLB06VIpXLiw02tow/OV+fPny9ChQ1W1K4IWAj1uertp0yaflr1Hjx6qahh/gyCHKk6UoX///in8RkS+xwBHfoEAhg4dnqpevbp8+eWXki9fPtUe5g7ao3DAr1u3rnqOYQfbtm1Tf+sOskRkj+vWrVPZiSszg0QHD1OFChVUMEAWlVjmh/Y/s8OMaePGjZISv/76q9SuXVv69u1rn4fM1RUyXWR3ZvDGcpEpo00RHXOSKrs7+Ft0VsGEXq4zZsxggKM0gb0oKU3o0KGD5MmTR/WcRCcTdAZBRwpUof3999/qPQMGDJA33nhDFi5cKH/88YcKBncbw4ZxZ507d5Zu3bqpvzE/86uvvlKvo4cnek+iOjU6OlplQMickEkNGjRIZs+erYLMb7/9JpMmTVLPAYHg4MGDMmzYMNVBZd68earziydOnDihqk4dp/Pnz6sOIeissmLFCjlw4ICMHDlStmzZkuDvUd2I3pboDILejqNHj5Z+/fpJUFCQR2V3hR6nWCbWDd67Zs0aFcCJ0gR/NwJS+u5kkpzXT548aXTq1MnIkyeP6pRyzz33GD179jQuXrxo71SCDiTZs2c3cubMaQwePFi9P7FOJhAXF2cMGjRIdVAJDg42SpcubcycOdP++rhx44wCBQoYNptNlQvQ0WXixImq00umTJmMvHnzGo0bNzbWrVtn/7vvv/9efRbK+dBDD6nP9KSTCd7jOqGDDTqIdOnSxciRI4f6bn369DFefPFFo0qVKgnW26hRo4zw8HDVuQTrB39rSqrsrp1M+vXrZ5QqVUp9D7z32WefNWJiYu66fYkChQ3/83eQJSIishqrKImISEsMcEREpCUGOCIi0hIDHBERaYkBjoiItMQAR0REWmKAIyIiLTHAERGRlhjgiIhISwxwRESkJQY4IiISHf0/ShMGJk8zDWsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch, lr, epoch, acc, f1, cm in results:\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(f\"Confusion Matrix - Batch: {batch}, LR: {lr}, Epochs: {epoch}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2 : Automated Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.5.2\n",
      "  Using cached scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.11/site-packages (from scikit-learn==1.5.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn==1.5.2) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn==1.5.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn==1.5.2) (3.5.0)\n",
      "Using cached scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "Successfully installed scikit-learn-1.5.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogluon\n",
      "  Downloading autogluon-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.2 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading autogluon.core-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.features==1.2 (from autogluon)\n",
      "  Downloading autogluon.features-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading autogluon.tabular-1.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting autogluon.multimodal==1.2 (from autogluon)\n",
      "  Downloading autogluon.multimodal-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.timeseries==1.2 (from autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading autogluon.timeseries-1.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy<2.1.4,>=1.25.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading numpy-2.1.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scipy<1.16,>=1.5.4 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting scikit-learn<1.5.3,>=1.4.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting networkx<4,>=3.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pandas<2.3.0,>=2.0.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting tqdm<5,>=4.38 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting requests (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting matplotlib<3.11,>=3.7.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading matplotlib-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting boto3<2,>=1.10 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading boto3-1.37.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting autogluon.common==1.2 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading autogluon.common-1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.40,>=2.10.0 (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading ray-2.39.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (17 kB)\n",
      "Collecting pyarrow>=15.0.0 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyarrow-19.0.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting Pillow<12,>=10.0.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting torch<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading torch-2.5.1-cp311-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting lightning<2.6,>=2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting transformers<5,>=4.38.0 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting accelerate<1.0,>=0.34.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torchvision<0.21.0,>=0.16.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting scikit-image<0.25.0,>=0.19.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading scikit_image-0.24.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting text-unidecode<1.4,>=1.3 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting defusedxml<0.7.2,>=0.7.1 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jinja2<3.2,>=3.0.3 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading catboost-1.2.7-cp311-cp311-macosx_11_0_universal2.whl.metadata (1.2 kB)\n",
      "Collecting numpy<2.1.4,>=1.25.0 (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting spacy<3.8 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting lightgbm<4.6,>=4.0 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading lightgbm-4.5.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Collecting einops<0.9,>=0.7 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting xgboost<2.2,>=1.6 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading xgboost-2.1.4-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastai-2.7.18-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting huggingface-hub[torch] (from autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting joblib<2,>=1.1 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pytorch-lightning (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading gluonts-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting statsforecast<1.8,>=1.7.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading statsforecast-1.7.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting mlforecast==0.13.4 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading mlforecast-0.13.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting utilsforecast<0.2.5,>=0.2.3 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading utilsforecast-0.2.4-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting coreforecast==0.0.12 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading coreforecast-0.0.12-py3-none-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading orjson-3.10.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting psutil<7.0.0,>=5.7.3 (from autogluon.common==1.2->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading psutil-6.1.1-cp36-abi3-macosx_11_0_arm64.whl.metadata (22 kB)\n",
      "Collecting cloudpickle (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting fsspec (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numba (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading numba-0.61.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting optuna (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting packaging (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting window-ops (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting pyyaml (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.1 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading botocore-1.37.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting graphviz (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting plotly (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting six (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pip (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastcore-1.7.29-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pydantic<3,>=1.7 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting toolz~=0.10 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting typing-extensions~=4.0 (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading py4j-0.10.9.9-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading rpds_py-0.23.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading fonttools-4.56.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting python-dateutil>=2.7 (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting click (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting rich (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting filelock (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting aiosignal (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting frozenlist (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting aiohttp>=3.7 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohttp-3.11.13-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading py_spy-0.4.0-py2.py3-none-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting prometheus-client>=0.7.1 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting smart-open (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading grpcio-1.70.0-cp311-cp311-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Collecting memray (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading memray-1.15.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting imageio>=2.33 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tifffile-2025.2.18-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting setuptools (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading setuptools-75.8.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting statsmodels>=0.13.2 (from statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading statsmodels-0.14.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5,>=4.38.0->transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading propcache-0.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting beautifulsoup4 (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting platformdirs<5,>=3.9.1 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting wrapt (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting textual>=0.41.0 (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading textual-2.1.1-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading SQLAlchemy-2.0.38-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading narwhals-1.28.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting filelock (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting mdit-py-plugins (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading autogluon-1.2-py3-none-any.whl (9.6 kB)\n",
      "Downloading autogluon.core-1.2-py3-none-any.whl (266 kB)\n",
      "Downloading autogluon.features-1.2-py3-none-any.whl (64 kB)\n",
      "Downloading autogluon.multimodal-1.2-py3-none-any.whl (429 kB)\n",
      "Downloading autogluon.tabular-1.2-py3-none-any.whl (352 kB)\n",
      "Downloading autogluon.timeseries-1.2-py3-none-any.whl (174 kB)\n",
      "Downloading autogluon.common-1.2-py3-none-any.whl (68 kB)\n",
      "Downloading coreforecast-0.0.12-py3-none-macosx_11_0_arm64.whl (110 kB)\n",
      "Downloading mlforecast-0.13.4-py3-none-any.whl (70 kB)\n",
      "Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Downloading boto3-1.37.1-py3-none-any.whl (139 kB)\n",
      "Downloading catboost-1.2.7-cp311-cp311-macosx_11_0_universal2.whl (27.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.1/27.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading fastai-2.7.18-py3-none-any.whl (234 kB)\n",
      "Downloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
      "Downloading gluonts-0.16.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "Downloading lightgbm-4.5.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "Downloading orjson-3.10.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pillow-11.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-macosx_12_0_arm64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
      "Downloading ray-2.39.0-cp311-cp311-macosx_11_0_arm64.whl (64.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scikit_image-0.24.0-cp311-cp311-macosx_12_0_arm64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-macosx_14_0_arm64.whl (22.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading statsforecast-1.7.8-cp311-cp311-macosx_11_0_arm64.whl (275 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp311-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading utilsforecast-0.2.4-py3-none-any.whl (40 kB)\n",
      "Downloading xgboost-2.1.4-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
      "Downloading aiohttp-3.11.13-cp311-cp311-macosx_11_0_arm64.whl (455 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading botocore-1.37.1-py3-none-any.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl (194 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading contourpy-1.3.1-cp311-cp311-macosx_11_0_arm64.whl (254 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fastcore-1.7.29-py3-none-any.whl (84 kB)\n",
      "Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Downloading fonttools-4.56.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading frozenlist-1.5.0-cp311-cp311-macosx_11_0_arm64.whl (52 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading grpcio-1.70.0-cp311-cp311-macosx_10_14_universal2.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-macosx_11_0_arm64.whl (65 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading msgpack-1.1.0-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading murmurhash-1.0.12-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading numba-0.61.0-cp311-cp311-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
      "Downloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Downloading psutil-6.1.1-cp36-abi3-macosx_11_0_arm64.whl (248 kB)\n",
      "Downloading py_spy-0.4.0-py2.py3-none-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading rpds_py-0.23.1-cp311-cp311-macosx_11_0_arm64.whl (356 kB)\n",
      "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-75.8.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (634 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.4/634.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.4-cp311-cp311-macosx_11_0_arm64.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Downloading thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tifffile-2025.2.18-py3-none-any.whl (226 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Downloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Downloading memray-1.15.0-cp311-cp311-macosx_11_0_arm64.whl (901 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.5/901.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading py4j-0.10.9.9-py2.py3-none-any.whl (203 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl (26.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading narwhals-1.28.0-py3-none-any.whl (308 kB)\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
      "Downloading propcache-0.3.0-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n",
      "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading textual-2.1.1-py3-none-any.whl (679 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.9/679.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp311-cp311-macosx_11_0_arm64.whl (92 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-macosx_10_9_universal2.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl (164 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Building wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19206 sha256=190ef767321a40ab0faeeed53e47b7c1d1ac4e31888042b2db273fe78f04c4d1\n",
      "  Stored in directory: /private/var/folders/20/90f_lm_94hq07z9ktfpfl3hh0000gn/T/pip-ephem-wheel-cache-ft3iynm3/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144590 sha256=a50b32d95389812de9ce5f78d32cd3833e1ed57f3ae0b80470d011c78ad41acd\n",
      "  Stored in directory: /private/var/folders/20/90f_lm_94hq07z9ktfpfl3hh0000gn/T/pip-ephem-wheel-cache-ft3iynm3/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16218 sha256=5922c98ba59a059ebfd9bde3c1eb0b08c47de571ea6eadcc664ca7cdad7ac12d\n",
      "  Stored in directory: /private/var/folders/20/90f_lm_94hq07z9ktfpfl3hh0000gn/T/pip-ephem-wheel-cache-ft3iynm3/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
      "Installing collected packages: text-unidecode, sentencepiece, pytz, py4j, py-spy, opencensus-context, nvidia-ml-py3, mpmath, distlib, cymem, colorful, appdirs, antlr4-python3-runtime, xxhash, wrapt, wasabi, urllib3, uc-micro-py, tzdata, typing-extensions, tqdm, toolz, threadpoolctl, tensorboard-data-server, tabulate, sympy, spacy-loggers, spacy-legacy, soupsieve, six, shellingham, setuptools, safetensors, rpds-py, regex, pyyaml, PySocks, pyparsing, pygments, pycryptodome, pyasn1, pyarrow, psutil, protobuf, propcache, prometheus-client, platformdirs, pip, Pillow, packaging, orjson, ordered-set, openxlab, numpy, networkx, narwhals, murmurhash, multidict, msgpack, mdurl, MarkupSafe, markdown, llvmlite, kiwisolver, joblib, jmespath, idna, grpcio, graphviz, future, fsspec, frozenlist, fonttools, filelock, fastprogress, einops, dill, defusedxml, cycler, colorlog, colorama, cloudpickle, cloudpathlib, click, charset-normalizer, certifi, catalogue, cachetools, attrs, annotated-types, aiohappyeyeballs, absl-py, yarl, werkzeug, virtualenv, tifffile, tensorboardX, srsly, sqlalchemy, smart-open, scipy, rsa, requests, referencing, python-dateutil, pytesseract, pydantic-core, pyasn1-modules, proto-plus, preshed, plotly, pdf2image, patsy, omegaconf, numba, nltk, multiprocess, model-index, markdown-it-py, marisa-trie, Mako, linkify-it-py, lightning-utilities, lazy-loader, jinja2, imageio, googleapis-common-protos, fs, fastcore, coreforecast, contourpy, blis, beautifulsoup4, aiosignal, xgboost, window-ops, torch, tensorboard, scikit-learn, scikit-image, rich, pydantic, pandas, mdit-py-plugins, matplotlib, lightgbm, language-data, jsonschema-specifications, hyperopt, huggingface-hub, google-auth, fastdownload, botocore, alembic, aiohttp, utilsforecast, typer, triad, torchvision, torchmetrics, tokenizers, statsmodels, seqeval, s3transfer, pytorch-metric-learning, optuna, opendatalab, langcodes, jsonschema, google-api-core, gluonts, gdown, confection, catboost, aiohttp-cors, accelerate, weasel, transformers, timm, thinc, textual, ray, pytorch-lightning, openmim, opencensus, nlpaug, mlforecast, datasets, boto3, adagio, spacy, memray, lightning, fugue, evaluate, autogluon.common, statsforecast, fastai, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
      "  Attempting uninstall: text-unidecode\n",
      "    Found existing installation: text-unidecode 1.3\n",
      "    Uninstalling text-unidecode-1.3:\n",
      "      Successfully uninstalled text-unidecode-1.3\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.2.0\n",
      "    Uninstalling sentencepiece-0.2.0:\n",
      "      Successfully uninstalled sentencepiece-0.2.0\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2025.1\n",
      "    Uninstalling pytz-2025.1:\n",
      "      Successfully uninstalled pytz-2025.1\n",
      "  Attempting uninstall: py4j\n",
      "    Found existing installation: py4j 0.10.9.9\n",
      "    Uninstalling py4j-0.10.9.9:\n",
      "      Successfully uninstalled py4j-0.10.9.9\n",
      "  Attempting uninstall: py-spy\n",
      "    Found existing installation: py-spy 0.4.0\n",
      "    Uninstalling py-spy-0.4.0:\n",
      "      Successfully uninstalled py-spy-0.4.0\n",
      "  Attempting uninstall: opencensus-context\n",
      "    Found existing installation: opencensus-context 0.1.3\n",
      "    Uninstalling opencensus-context-0.1.3:\n",
      "      Successfully uninstalled opencensus-context-0.1.3\n",
      "  Attempting uninstall: nvidia-ml-py3\n",
      "    Found existing installation: nvidia-ml-py3 7.352.0\n",
      "    Uninstalling nvidia-ml-py3-7.352.0:\n",
      "      Successfully uninstalled nvidia-ml-py3-7.352.0\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: distlib\n",
      "    Found existing installation: distlib 0.3.9\n",
      "    Uninstalling distlib-0.3.9:\n",
      "      Successfully uninstalled distlib-0.3.9\n",
      "  Attempting uninstall: cymem\n",
      "    Found existing installation: cymem 2.0.11\n",
      "    Uninstalling cymem-2.0.11:\n",
      "      Successfully uninstalled cymem-2.0.11\n",
      "  Attempting uninstall: colorful\n",
      "    Found existing installation: colorful 0.5.6\n",
      "    Uninstalling colorful-0.5.6:\n",
      "      Successfully uninstalled colorful-0.5.6\n",
      "  Attempting uninstall: appdirs\n",
      "    Found existing installation: appdirs 1.4.4\n",
      "    Uninstalling appdirs-1.4.4:\n",
      "      Successfully uninstalled appdirs-1.4.4\n",
      "  Attempting uninstall: antlr4-python3-runtime\n",
      "    Found existing installation: antlr4-python3-runtime 4.9.3\n",
      "    Uninstalling antlr4-python3-runtime-4.9.3:\n",
      "      Successfully uninstalled antlr4-python3-runtime-4.9.3\n",
      "  Attempting uninstall: xxhash\n",
      "    Found existing installation: xxhash 3.5.0\n",
      "    Uninstalling xxhash-3.5.0:\n",
      "      Successfully uninstalled xxhash-3.5.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.17.2\n",
      "    Uninstalling wrapt-1.17.2:\n",
      "      Successfully uninstalled wrapt-1.17.2\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 1.1.3\n",
      "    Uninstalling wasabi-1.1.3:\n",
      "      Successfully uninstalled wasabi-1.1.3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: uc-micro-py\n",
      "    Found existing installation: uc-micro-py 1.0.3\n",
      "    Uninstalling uc-micro-py-1.0.3:\n",
      "      Successfully uninstalled uc-micro-py-1.0.3\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2025.1\n",
      "    Uninstalling tzdata-2025.1:\n",
      "      Successfully uninstalled tzdata-2025.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: toolz\n",
      "    Found existing installation: toolz 0.12.1\n",
      "    Uninstalling toolz-0.12.1:\n",
      "      Successfully uninstalled toolz-0.12.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.5.0\n",
      "    Uninstalling threadpoolctl-3.5.0:\n",
      "      Successfully uninstalled threadpoolctl-3.5.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.2\n",
      "    Uninstalling tensorboard-data-server-0.7.2:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
      "  Attempting uninstall: tabulate\n",
      "    Found existing installation: tabulate 0.9.0\n",
      "    Uninstalling tabulate-0.9.0:\n",
      "      Successfully uninstalled tabulate-0.9.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: spacy-loggers\n",
      "    Found existing installation: spacy-loggers 1.0.5\n",
      "    Uninstalling spacy-loggers-1.0.5:\n",
      "      Successfully uninstalled spacy-loggers-1.0.5\n",
      "  Attempting uninstall: spacy-legacy\n",
      "    Found existing installation: spacy-legacy 3.0.12\n",
      "    Uninstalling spacy-legacy-3.0.12:\n",
      "      Successfully uninstalled spacy-legacy-3.0.12\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.6\n",
      "    Uninstalling soupsieve-2.6:\n",
      "      Successfully uninstalled soupsieve-2.6\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: shellingham\n",
      "    Found existing installation: shellingham 1.5.4\n",
      "    Uninstalling shellingham-1.5.4:\n",
      "      Successfully uninstalled shellingham-1.5.4\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.8.1\n",
      "    Uninstalling setuptools-75.8.1:\n",
      "      Successfully uninstalled setuptools-75.8.1\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.5.3\n",
      "    Uninstalling safetensors-0.5.3:\n",
      "      Successfully uninstalled safetensors-0.5.3\n",
      "  Attempting uninstall: rpds-py\n",
      "    Found existing installation: rpds-py 0.23.1\n",
      "    Uninstalling rpds-py-0.23.1:\n",
      "      Successfully uninstalled rpds-py-0.23.1\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: PySocks\n",
      "    Found existing installation: PySocks 1.7.1\n",
      "    Uninstalling PySocks-1.7.1:\n",
      "      Successfully uninstalled PySocks-1.7.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.1\n",
      "    Uninstalling pyparsing-3.2.1:\n",
      "      Successfully uninstalled pyparsing-3.2.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.19.1\n",
      "    Uninstalling Pygments-2.19.1:\n",
      "      Successfully uninstalled Pygments-2.19.1\n",
      "  Attempting uninstall: pycryptodome\n",
      "    Found existing installation: pycryptodome 3.21.0\n",
      "    Uninstalling pycryptodome-3.21.0:\n",
      "      Successfully uninstalled pycryptodome-3.21.0\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.6.1\n",
      "    Uninstalling pyasn1-0.6.1:\n",
      "      Successfully uninstalled pyasn1-0.6.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 6.1.1\n",
      "    Uninstalling psutil-6.1.1:\n",
      "      Successfully uninstalled psutil-6.1.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.3\n",
      "    Uninstalling protobuf-5.29.3:\n",
      "      Successfully uninstalled protobuf-5.29.3\n",
      "  Attempting uninstall: propcache\n",
      "    Found existing installation: propcache 0.3.0\n",
      "    Uninstalling propcache-0.3.0:\n",
      "      Successfully uninstalled propcache-0.3.0\n",
      "  Attempting uninstall: prometheus-client\n",
      "    Found existing installation: prometheus_client 0.21.1\n",
      "    Uninstalling prometheus_client-0.21.1:\n",
      "      Successfully uninstalled prometheus_client-0.21.1\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.3.6\n",
      "    Uninstalling platformdirs-4.3.6:\n",
      "      Successfully uninstalled platformdirs-4.3.6\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: orjson\n",
      "    Found existing installation: orjson 3.10.15\n",
      "    Uninstalling orjson-3.10.15:\n",
      "      Successfully uninstalled orjson-3.10.15\n",
      "  Attempting uninstall: ordered-set\n",
      "    Found existing installation: ordered-set 4.1.0\n",
      "    Uninstalling ordered-set-4.1.0:\n",
      "      Successfully uninstalled ordered-set-4.1.0\n",
      "  Attempting uninstall: openxlab\n",
      "    Found existing installation: openxlab 0.0.11\n",
      "    Uninstalling openxlab-0.0.11:\n",
      "      Successfully uninstalled openxlab-0.0.11\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.4.2\n",
      "    Uninstalling networkx-3.4.2:\n",
      "      Successfully uninstalled networkx-3.4.2\n",
      "  Attempting uninstall: narwhals\n",
      "    Found existing installation: narwhals 1.28.0\n",
      "    Uninstalling narwhals-1.28.0:\n",
      "      Successfully uninstalled narwhals-1.28.0\n",
      "  Attempting uninstall: murmurhash\n",
      "    Found existing installation: murmurhash 1.0.12\n",
      "    Uninstalling murmurhash-1.0.12:\n",
      "      Successfully uninstalled murmurhash-1.0.12\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.1.0\n",
      "    Uninstalling multidict-6.1.0:\n",
      "      Successfully uninstalled multidict-6.1.0\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.1.0\n",
      "    Uninstalling msgpack-1.1.0:\n",
      "      Successfully uninstalled msgpack-1.1.0\n",
      "  Attempting uninstall: mdurl\n",
      "    Found existing installation: mdurl 0.1.2\n",
      "    Uninstalling mdurl-0.1.2:\n",
      "      Successfully uninstalled mdurl-0.1.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.7\n",
      "    Uninstalling Markdown-3.7:\n",
      "      Successfully uninstalled Markdown-3.7\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.44.0\n",
      "    Uninstalling llvmlite-0.44.0:\n",
      "      Successfully uninstalled llvmlite-0.44.0\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.4.8\n",
      "    Uninstalling kiwisolver-1.4.8:\n",
      "      Successfully uninstalled kiwisolver-1.4.8\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.2\n",
      "    Uninstalling joblib-1.4.2:\n",
      "      Successfully uninstalled joblib-1.4.2\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.70.0\n",
      "    Uninstalling grpcio-1.70.0:\n",
      "      Successfully uninstalled grpcio-1.70.0\n",
      "  Attempting uninstall: graphviz\n",
      "    Found existing installation: graphviz 0.20.3\n",
      "    Uninstalling graphviz-0.20.3:\n",
      "      Successfully uninstalled graphviz-0.20.3\n",
      "  Attempting uninstall: future\n",
      "    Found existing installation: future 1.0.0\n",
      "    Uninstalling future-1.0.0:\n",
      "      Successfully uninstalled future-1.0.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.5.0\n",
      "    Uninstalling frozenlist-1.5.0:\n",
      "      Successfully uninstalled frozenlist-1.5.0\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.56.0\n",
      "    Uninstalling fonttools-4.56.0:\n",
      "      Successfully uninstalled fonttools-4.56.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.17.0\n",
      "    Uninstalling filelock-3.17.0:\n",
      "      Successfully uninstalled filelock-3.17.0\n",
      "  Attempting uninstall: fastprogress\n",
      "    Found existing installation: fastprogress 1.0.3\n",
      "    Uninstalling fastprogress-1.0.3:\n",
      "      Successfully uninstalled fastprogress-1.0.3\n",
      "  Attempting uninstall: einops\n",
      "    Found existing installation: einops 0.8.1\n",
      "    Uninstalling einops-0.8.1:\n",
      "      Successfully uninstalled einops-0.8.1\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: defusedxml\n",
      "    Found existing installation: defusedxml 0.7.1\n",
      "    Uninstalling defusedxml-0.7.1:\n",
      "      Successfully uninstalled defusedxml-0.7.1\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.12.1\n",
      "    Uninstalling cycler-0.12.1:\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "  Attempting uninstall: colorlog\n",
      "    Found existing installation: colorlog 6.9.0\n",
      "    Uninstalling colorlog-6.9.0:\n",
      "      Successfully uninstalled colorlog-6.9.0\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.1.1\n",
      "    Uninstalling cloudpickle-3.1.1:\n",
      "      Successfully uninstalled cloudpickle-3.1.1\n",
      "  Attempting uninstall: cloudpathlib\n",
      "    Found existing installation: cloudpathlib 0.20.0\n",
      "    Uninstalling cloudpathlib-0.20.0:\n",
      "      Successfully uninstalled cloudpathlib-0.20.0\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.8\n",
      "    Uninstalling click-8.1.8:\n",
      "      Successfully uninstalled click-8.1.8\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.1\n",
      "    Uninstalling charset-normalizer-3.4.1:\n",
      "      Successfully uninstalled charset-normalizer-3.4.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.1.31\n",
      "    Uninstalling certifi-2025.1.31:\n",
      "      Successfully uninstalled certifi-2025.1.31\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 2.0.10\n",
      "    Uninstalling catalogue-2.0.10:\n",
      "      Successfully uninstalled catalogue-2.0.10\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.5.2\n",
      "    Uninstalling cachetools-5.5.2:\n",
      "      Successfully uninstalled cachetools-5.5.2\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 25.1.0\n",
      "    Uninstalling attrs-25.1.0:\n",
      "      Successfully uninstalled attrs-25.1.0\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.7.0\n",
      "    Uninstalling annotated-types-0.7.0:\n",
      "      Successfully uninstalled annotated-types-0.7.0\n",
      "  Attempting uninstall: aiohappyeyeballs\n",
      "    Found existing installation: aiohappyeyeballs 2.4.6\n",
      "    Uninstalling aiohappyeyeballs-2.4.6:\n",
      "      Successfully uninstalled aiohappyeyeballs-2.4.6\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.18.3\n",
      "    Uninstalling yarl-1.18.3:\n",
      "      Successfully uninstalled yarl-1.18.3\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 3.1.3\n",
      "    Uninstalling Werkzeug-3.1.3:\n",
      "      Successfully uninstalled Werkzeug-3.1.3\n",
      "  Attempting uninstall: virtualenv\n",
      "    Found existing installation: virtualenv 20.29.2\n",
      "    Uninstalling virtualenv-20.29.2:\n",
      "      Successfully uninstalled virtualenv-20.29.2\n",
      "  Attempting uninstall: tifffile\n",
      "    Found existing installation: tifffile 2025.2.18\n",
      "    Uninstalling tifffile-2025.2.18:\n",
      "      Successfully uninstalled tifffile-2025.2.18\n",
      "  Attempting uninstall: tensorboardX\n",
      "    Found existing installation: tensorboardX 2.6.2.2\n",
      "    Uninstalling tensorboardX-2.6.2.2:\n",
      "      Successfully uninstalled tensorboardX-2.6.2.2\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.5.1\n",
      "    Uninstalling srsly-2.5.1:\n",
      "      Successfully uninstalled srsly-2.5.1\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.38\n",
      "    Uninstalling SQLAlchemy-2.0.38:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.38\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 7.1.0\n",
      "    Uninstalling smart-open-7.1.0:\n",
      "      Successfully uninstalled smart-open-7.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.2\n",
      "    Uninstalling scipy-1.15.2:\n",
      "      Successfully uninstalled scipy-1.15.2\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.9\n",
      "    Uninstalling rsa-4.9:\n",
      "      Successfully uninstalled rsa-4.9\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.36.2\n",
      "    Uninstalling referencing-0.36.2:\n",
      "      Successfully uninstalled referencing-0.36.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pytesseract\n",
      "    Found existing installation: pytesseract 0.3.10\n",
      "    Uninstalling pytesseract-0.3.10:\n",
      "      Successfully uninstalled pytesseract-0.3.10\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: pyasn1-modules\n",
      "    Found existing installation: pyasn1_modules 0.4.1\n",
      "    Uninstalling pyasn1_modules-0.4.1:\n",
      "      Successfully uninstalled pyasn1_modules-0.4.1\n",
      "  Attempting uninstall: proto-plus\n",
      "    Found existing installation: proto-plus 1.26.0\n",
      "    Uninstalling proto-plus-1.26.0:\n",
      "      Successfully uninstalled proto-plus-1.26.0\n",
      "  Attempting uninstall: preshed\n",
      "    Found existing installation: preshed 3.0.9\n",
      "    Uninstalling preshed-3.0.9:\n",
      "      Successfully uninstalled preshed-3.0.9\n",
      "  Attempting uninstall: plotly\n",
      "    Found existing installation: plotly 6.0.0\n",
      "    Uninstalling plotly-6.0.0:\n",
      "      Successfully uninstalled plotly-6.0.0\n",
      "  Attempting uninstall: pdf2image\n",
      "    Found existing installation: pdf2image 1.17.0\n",
      "    Uninstalling pdf2image-1.17.0:\n",
      "      Successfully uninstalled pdf2image-1.17.0\n",
      "  Attempting uninstall: patsy\n",
      "    Found existing installation: patsy 1.0.1\n",
      "    Uninstalling patsy-1.0.1:\n",
      "      Successfully uninstalled patsy-1.0.1\n",
      "  Attempting uninstall: omegaconf\n",
      "    Found existing installation: omegaconf 2.2.3\n",
      "    Uninstalling omegaconf-2.2.3:\n",
      "      Successfully uninstalled omegaconf-2.2.3\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.61.0\n",
      "    Uninstalling numba-0.61.0:\n",
      "      Successfully uninstalled numba-0.61.0\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: model-index\n",
      "    Found existing installation: model-index 0.1.11\n",
      "    Uninstalling model-index-0.1.11:\n",
      "      Successfully uninstalled model-index-0.1.11\n",
      "  Attempting uninstall: markdown-it-py\n",
      "    Found existing installation: markdown-it-py 3.0.0\n",
      "    Uninstalling markdown-it-py-3.0.0:\n",
      "      Successfully uninstalled markdown-it-py-3.0.0\n",
      "  Attempting uninstall: marisa-trie\n",
      "    Found existing installation: marisa-trie 1.2.1\n",
      "    Uninstalling marisa-trie-1.2.1:\n",
      "      Successfully uninstalled marisa-trie-1.2.1\n",
      "  Attempting uninstall: Mako\n",
      "    Found existing installation: Mako 1.3.9\n",
      "    Uninstalling Mako-1.3.9:\n",
      "      Successfully uninstalled Mako-1.3.9\n",
      "  Attempting uninstall: linkify-it-py\n",
      "    Found existing installation: linkify-it-py 2.0.3\n",
      "    Uninstalling linkify-it-py-2.0.3:\n",
      "      Successfully uninstalled linkify-it-py-2.0.3\n",
      "  Attempting uninstall: lightning-utilities\n",
      "    Found existing installation: lightning-utilities 0.12.0\n",
      "    Uninstalling lightning-utilities-0.12.0:\n",
      "      Successfully uninstalled lightning-utilities-0.12.0\n",
      "  Attempting uninstall: lazy-loader\n",
      "    Found existing installation: lazy_loader 0.4\n",
      "    Uninstalling lazy_loader-0.4:\n",
      "      Successfully uninstalled lazy_loader-0.4\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.5\n",
      "    Uninstalling Jinja2-3.1.5:\n",
      "      Successfully uninstalled Jinja2-3.1.5\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.37.0\n",
      "    Uninstalling imageio-2.37.0:\n",
      "      Successfully uninstalled imageio-2.37.0\n",
      "  Attempting uninstall: googleapis-common-protos\n",
      "    Found existing installation: googleapis-common-protos 1.68.0\n",
      "    Uninstalling googleapis-common-protos-1.68.0:\n",
      "      Successfully uninstalled googleapis-common-protos-1.68.0\n",
      "  Attempting uninstall: fs\n",
      "    Found existing installation: fs 2.4.16\n",
      "    Uninstalling fs-2.4.16:\n",
      "      Successfully uninstalled fs-2.4.16\n",
      "  Attempting uninstall: fastcore\n",
      "    Found existing installation: fastcore 1.7.29\n",
      "    Uninstalling fastcore-1.7.29:\n",
      "      Successfully uninstalled fastcore-1.7.29\n",
      "  Attempting uninstall: coreforecast\n",
      "    Found existing installation: coreforecast 0.0.12\n",
      "    Uninstalling coreforecast-0.0.12:\n",
      "      Successfully uninstalled coreforecast-0.0.12\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.3.1\n",
      "    Uninstalling contourpy-1.3.1:\n",
      "      Successfully uninstalled contourpy-1.3.1\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 0.7.11\n",
      "    Uninstalling blis-0.7.11:\n",
      "      Successfully uninstalled blis-0.7.11\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.13.3\n",
      "    Uninstalling beautifulsoup4-4.13.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.13.3\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.2\n",
      "    Uninstalling aiosignal-1.3.2:\n",
      "      Successfully uninstalled aiosignal-1.3.2\n",
      "  Attempting uninstall: xgboost\n",
      "    Found existing installation: xgboost 2.1.4\n",
      "    Uninstalling xgboost-2.1.4:\n",
      "      Successfully uninstalled xgboost-2.1.4\n",
      "  Attempting uninstall: window-ops\n",
      "    Found existing installation: window_ops 0.0.15\n",
      "    Uninstalling window_ops-0.0.15:\n",
      "      Successfully uninstalled window_ops-0.0.15\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.24.0\n",
      "    Uninstalling scikit-image-0.24.0:\n",
      "      Successfully uninstalled scikit-image-0.24.0\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.9.4\n",
      "    Uninstalling rich-13.9.4:\n",
      "      Successfully uninstalled rich-13.9.4\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.6\n",
      "    Uninstalling pydantic-2.10.6:\n",
      "      Successfully uninstalled pydantic-2.10.6\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "  Attempting uninstall: mdit-py-plugins\n",
      "    Found existing installation: mdit-py-plugins 0.4.2\n",
      "    Uninstalling mdit-py-plugins-0.4.2:\n",
      "      Successfully uninstalled mdit-py-plugins-0.4.2\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.10.0\n",
      "    Uninstalling matplotlib-3.10.0:\n",
      "      Successfully uninstalled matplotlib-3.10.0\n",
      "  Attempting uninstall: lightgbm\n",
      "    Found existing installation: lightgbm 4.5.0\n",
      "    Uninstalling lightgbm-4.5.0:\n",
      "      Successfully uninstalled lightgbm-4.5.0\n",
      "  Attempting uninstall: language-data\n",
      "    Found existing installation: language_data 1.3.0\n",
      "    Uninstalling language_data-1.3.0:\n",
      "      Successfully uninstalled language_data-1.3.0\n",
      "  Attempting uninstall: jsonschema-specifications\n",
      "    Found existing installation: jsonschema-specifications 2024.10.1\n",
      "    Uninstalling jsonschema-specifications-2024.10.1:\n",
      "      Successfully uninstalled jsonschema-specifications-2024.10.1\n",
      "  Attempting uninstall: hyperopt\n",
      "    Found existing installation: hyperopt 0.2.7\n",
      "    Uninstalling hyperopt-0.2.7:\n",
      "      Successfully uninstalled hyperopt-0.2.7\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.29.1\n",
      "    Uninstalling huggingface-hub-0.29.1:\n",
      "      Successfully uninstalled huggingface-hub-0.29.1\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.38.0\n",
      "    Uninstalling google-auth-2.38.0:\n",
      "      Successfully uninstalled google-auth-2.38.0\n",
      "  Attempting uninstall: fastdownload\n",
      "    Found existing installation: fastdownload 0.0.7\n",
      "    Uninstalling fastdownload-0.0.7:\n",
      "      Successfully uninstalled fastdownload-0.0.7\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.37.1\n",
      "    Uninstalling botocore-1.37.1:\n",
      "      Successfully uninstalled botocore-1.37.1\n",
      "  Attempting uninstall: alembic\n",
      "    Found existing installation: alembic 1.14.1\n",
      "    Uninstalling alembic-1.14.1:\n",
      "      Successfully uninstalled alembic-1.14.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.13\n",
      "    Uninstalling aiohttp-3.11.13:\n",
      "      Successfully uninstalled aiohttp-3.11.13\n",
      "  Attempting uninstall: utilsforecast\n",
      "    Found existing installation: utilsforecast 0.2.4\n",
      "    Uninstalling utilsforecast-0.2.4:\n",
      "      Successfully uninstalled utilsforecast-0.2.4\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.15.1\n",
      "    Uninstalling typer-0.15.1:\n",
      "      Successfully uninstalled typer-0.15.1\n",
      "  Attempting uninstall: triad\n",
      "    Found existing installation: triad 0.9.8\n",
      "    Uninstalling triad-0.9.8:\n",
      "      Successfully uninstalled triad-0.9.8\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1\n",
      "    Uninstalling torchvision-0.20.1:\n",
      "      Successfully uninstalled torchvision-0.20.1\n",
      "  Attempting uninstall: torchmetrics\n",
      "    Found existing installation: torchmetrics 1.2.1\n",
      "    Uninstalling torchmetrics-1.2.1:\n",
      "      Successfully uninstalled torchmetrics-1.2.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: statsmodels\n",
      "    Found existing installation: statsmodels 0.14.4\n",
      "    Uninstalling statsmodels-0.14.4:\n",
      "      Successfully uninstalled statsmodels-0.14.4\n",
      "  Attempting uninstall: seqeval\n",
      "    Found existing installation: seqeval 1.2.2\n",
      "    Uninstalling seqeval-1.2.2:\n",
      "      Successfully uninstalled seqeval-1.2.2\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.11.2\n",
      "    Uninstalling s3transfer-0.11.2:\n",
      "      Successfully uninstalled s3transfer-0.11.2\n",
      "  Attempting uninstall: pytorch-metric-learning\n",
      "    Found existing installation: pytorch-metric-learning 2.3.0\n",
      "    Uninstalling pytorch-metric-learning-2.3.0:\n",
      "      Successfully uninstalled pytorch-metric-learning-2.3.0\n",
      "  Attempting uninstall: optuna\n",
      "    Found existing installation: optuna 4.2.1\n",
      "    Uninstalling optuna-4.2.1:\n",
      "      Successfully uninstalled optuna-4.2.1\n",
      "  Attempting uninstall: opendatalab\n",
      "    Found existing installation: opendatalab 0.0.10\n",
      "    Uninstalling opendatalab-0.0.10:\n",
      "      Successfully uninstalled opendatalab-0.0.10\n",
      "  Attempting uninstall: langcodes\n",
      "    Found existing installation: langcodes 3.5.0\n",
      "    Uninstalling langcodes-3.5.0:\n",
      "      Successfully uninstalled langcodes-3.5.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.21.1\n",
      "    Uninstalling jsonschema-4.21.1:\n",
      "      Successfully uninstalled jsonschema-4.21.1\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 2.24.1\n",
      "    Uninstalling google-api-core-2.24.1:\n",
      "      Successfully uninstalled google-api-core-2.24.1\n",
      "  Attempting uninstall: gluonts\n",
      "    Found existing installation: gluonts 0.16.0\n",
      "    Uninstalling gluonts-0.16.0:\n",
      "      Successfully uninstalled gluonts-0.16.0\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 5.2.0\n",
      "    Uninstalling gdown-5.2.0:\n",
      "      Successfully uninstalled gdown-5.2.0\n",
      "  Attempting uninstall: confection\n",
      "    Found existing installation: confection 0.1.5\n",
      "    Uninstalling confection-0.1.5:\n",
      "      Successfully uninstalled confection-0.1.5\n",
      "  Attempting uninstall: catboost\n",
      "    Found existing installation: catboost 1.2.7\n",
      "    Uninstalling catboost-1.2.7:\n",
      "      Successfully uninstalled catboost-1.2.7\n",
      "  Attempting uninstall: aiohttp-cors\n",
      "    Found existing installation: aiohttp-cors 0.7.0\n",
      "    Uninstalling aiohttp-cors-0.7.0:\n",
      "      Successfully uninstalled aiohttp-cors-0.7.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.34.2\n",
      "    Uninstalling accelerate-0.34.2:\n",
      "      Successfully uninstalled accelerate-0.34.2\n",
      "  Attempting uninstall: weasel\n",
      "    Found existing installation: weasel 0.4.1\n",
      "    Uninstalling weasel-0.4.1:\n",
      "      Successfully uninstalled weasel-0.4.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.49.0\n",
      "    Uninstalling transformers-4.49.0:\n",
      "      Successfully uninstalled transformers-4.49.0\n",
      "  Attempting uninstall: timm\n",
      "    Found existing installation: timm 1.0.3\n",
      "    Uninstalling timm-1.0.3:\n",
      "      Successfully uninstalled timm-1.0.3\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.2.5\n",
      "    Uninstalling thinc-8.2.5:\n",
      "      Successfully uninstalled thinc-8.2.5\n",
      "  Attempting uninstall: textual\n",
      "    Found existing installation: textual 2.1.1\n",
      "    Uninstalling textual-2.1.1:\n",
      "      Successfully uninstalled textual-2.1.1\n",
      "  Attempting uninstall: ray\n",
      "    Found existing installation: ray 2.39.0\n",
      "    Uninstalling ray-2.39.0:\n",
      "      Successfully uninstalled ray-2.39.0\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 2.5.0.post0\n",
      "    Uninstalling pytorch-lightning-2.5.0.post0:\n",
      "      Successfully uninstalled pytorch-lightning-2.5.0.post0\n",
      "  Attempting uninstall: openmim\n",
      "    Found existing installation: openmim 0.3.9\n",
      "    Uninstalling openmim-0.3.9:\n",
      "      Successfully uninstalled openmim-0.3.9\n",
      "  Attempting uninstall: opencensus\n",
      "    Found existing installation: opencensus 0.11.4\n",
      "    Uninstalling opencensus-0.11.4:\n",
      "      Successfully uninstalled opencensus-0.11.4\n",
      "  Attempting uninstall: nlpaug\n",
      "    Found existing installation: nlpaug 1.1.11\n",
      "    Uninstalling nlpaug-1.1.11:\n",
      "      Successfully uninstalled nlpaug-1.1.11\n",
      "  Attempting uninstall: mlforecast\n",
      "    Found existing installation: mlforecast 0.13.4\n",
      "    Uninstalling mlforecast-0.13.4:\n",
      "      Successfully uninstalled mlforecast-0.13.4\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.3.2\n",
      "    Uninstalling datasets-3.3.2:\n",
      "      Successfully uninstalled datasets-3.3.2\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.37.1\n",
      "    Uninstalling boto3-1.37.1:\n",
      "      Successfully uninstalled boto3-1.37.1\n",
      "  Attempting uninstall: adagio\n",
      "    Found existing installation: adagio 0.2.6\n",
      "    Uninstalling adagio-0.2.6:\n",
      "      Successfully uninstalled adagio-0.2.6\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.7.5\n",
      "    Uninstalling spacy-3.7.5:\n",
      "      Successfully uninstalled spacy-3.7.5\n",
      "  Attempting uninstall: memray\n",
      "    Found existing installation: memray 1.15.0\n",
      "    Uninstalling memray-1.15.0:\n",
      "      Successfully uninstalled memray-1.15.0\n",
      "  Attempting uninstall: lightning\n",
      "    Found existing installation: lightning 2.5.0.post0\n",
      "    Uninstalling lightning-2.5.0.post0:\n",
      "      Successfully uninstalled lightning-2.5.0.post0\n",
      "  Attempting uninstall: fugue\n",
      "    Found existing installation: fugue 0.9.1\n",
      "    Uninstalling fugue-0.9.1:\n",
      "      Successfully uninstalled fugue-0.9.1\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.3\n",
      "    Uninstalling evaluate-0.4.3:\n",
      "      Successfully uninstalled evaluate-0.4.3\n",
      "  Attempting uninstall: autogluon.common\n",
      "    Found existing installation: autogluon.common 1.2\n",
      "    Uninstalling autogluon.common-1.2:\n",
      "      Successfully uninstalled autogluon.common-1.2\n",
      "  Attempting uninstall: statsforecast\n",
      "    Found existing installation: statsforecast 1.7.8\n",
      "    Uninstalling statsforecast-1.7.8:\n",
      "      Successfully uninstalled statsforecast-1.7.8\n",
      "  Attempting uninstall: fastai\n",
      "    Found existing installation: fastai 2.7.18\n",
      "    Uninstalling fastai-2.7.18:\n",
      "      Successfully uninstalled fastai-2.7.18\n",
      "  Attempting uninstall: autogluon.features\n",
      "    Found existing installation: autogluon.features 1.2\n",
      "    Uninstalling autogluon.features-1.2:\n",
      "      Successfully uninstalled autogluon.features-1.2\n",
      "  Attempting uninstall: autogluon.core\n",
      "    Found existing installation: autogluon.core 1.2\n",
      "    Uninstalling autogluon.core-1.2:\n",
      "      Successfully uninstalled autogluon.core-1.2\n",
      "  Attempting uninstall: autogluon.tabular\n",
      "    Found existing installation: autogluon.tabular 1.2\n",
      "    Uninstalling autogluon.tabular-1.2:\n",
      "      Successfully uninstalled autogluon.tabular-1.2\n",
      "  Attempting uninstall: autogluon.multimodal\n",
      "    Found existing installation: autogluon.multimodal 1.2\n",
      "    Uninstalling autogluon.multimodal-1.2:\n",
      "      Successfully uninstalled autogluon.multimodal-1.2\n",
      "  Attempting uninstall: autogluon.timeseries\n",
      "    Found existing installation: autogluon.timeseries 1.2\n",
      "    Uninstalling autogluon.timeseries-1.2:\n",
      "      Successfully uninstalled autogluon.timeseries-1.2\n",
      "  Attempting uninstall: autogluon\n",
      "    Found existing installation: autogluon 1.2\n",
      "    Uninstalling autogluon-1.2:\n",
      "      Successfully uninstalled autogluon-1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.9 MarkupSafe-3.0.2 Pillow-11.1.0 PySocks-1.7.1 absl-py-2.1.0 accelerate-0.34.2 adagio-0.2.6 aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiohttp-cors-0.7.0 aiosignal-1.3.2 alembic-1.14.1 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 appdirs-1.4.4 attrs-25.1.0 autogluon-1.2 autogluon.common-1.2 autogluon.core-1.2 autogluon.features-1.2 autogluon.multimodal-1.2 autogluon.tabular-1.2 autogluon.timeseries-1.2 beautifulsoup4-4.13.3 blis-0.7.11 boto3-1.37.1 botocore-1.37.1 cachetools-5.5.2 catalogue-2.0.10 catboost-1.2.7 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 cloudpathlib-0.20.0 cloudpickle-3.1.1 colorama-0.4.6 colorful-0.5.6 colorlog-6.9.0 confection-0.1.5 contourpy-1.3.1 coreforecast-0.0.12 cycler-0.12.1 cymem-2.0.11 datasets-3.3.2 defusedxml-0.7.1 dill-0.3.8 distlib-0.3.9 einops-0.8.1 evaluate-0.4.3 fastai-2.7.18 fastcore-1.7.29 fastdownload-0.0.7 fastprogress-1.0.3 filelock-3.17.0 fonttools-4.56.0 frozenlist-1.5.0 fs-2.4.16 fsspec-2024.12.0 fugue-0.9.1 future-1.0.0 gdown-5.2.0 gluonts-0.16.0 google-api-core-2.24.1 google-auth-2.38.0 googleapis-common-protos-1.68.0 graphviz-0.20.3 grpcio-1.70.0 huggingface-hub-0.29.1 hyperopt-0.2.7 idna-3.10 imageio-2.37.0 jinja2-3.1.5 jmespath-1.0.1 joblib-1.4.2 jsonschema-4.21.1 jsonschema-specifications-2024.10.1 kiwisolver-1.4.8 langcodes-3.5.0 language-data-1.3.0 lazy-loader-0.4 lightgbm-4.5.0 lightning-2.5.0.post0 lightning-utilities-0.12.0 linkify-it-py-2.0.3 llvmlite-0.44.0 marisa-trie-1.2.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.0 mdit-py-plugins-0.4.2 mdurl-0.1.2 memray-1.15.0 mlforecast-0.13.4 model-index-0.1.11 mpmath-1.3.0 msgpack-1.1.0 multidict-6.1.0 multiprocess-0.70.16 murmurhash-1.0.12 narwhals-1.28.0 networkx-3.4.2 nlpaug-1.1.11 nltk-3.8.1 numba-0.61.0 numpy-1.26.4 nvidia-ml-py3-7.352.0 omegaconf-2.2.3 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.2.1 ordered-set-4.1.0 orjson-3.10.15 packaging-24.2 pandas-2.2.3 patsy-1.0.1 pdf2image-1.17.0 pip-25.0.1 platformdirs-4.3.6 plotly-6.0.0 preshed-3.0.9 prometheus-client-0.21.1 propcache-0.3.0 proto-plus-1.26.0 protobuf-5.29.3 psutil-6.1.1 py-spy-0.4.0 py4j-0.10.9.9 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycryptodome-3.21.0 pydantic-2.10.6 pydantic-core-2.27.2 pygments-2.19.1 pyparsing-3.2.1 pytesseract-0.3.10 python-dateutil-2.9.0.post0 pytorch-lightning-2.5.0.post0 pytorch-metric-learning-2.3.0 pytz-2025.1 pyyaml-6.0.2 ray-2.39.0 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 rich-13.9.4 rpds-py-0.23.1 rsa-4.9 s3transfer-0.11.2 safetensors-0.5.3 scikit-image-0.24.0 scikit-learn-1.5.2 scipy-1.15.2 sentencepiece-0.2.0 seqeval-1.2.2 setuptools-75.8.1 shellingham-1.5.4 six-1.17.0 smart-open-7.1.0 soupsieve-2.6 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 sqlalchemy-2.0.38 srsly-2.5.1 statsforecast-1.7.8 statsmodels-0.14.4 sympy-1.13.1 tabulate-0.9.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 text-unidecode-1.3 textual-2.1.1 thinc-8.2.5 threadpoolctl-3.5.0 tifffile-2025.2.18 timm-1.0.3 tokenizers-0.21.0 toolz-0.12.1 torch-2.5.1 torchmetrics-1.2.1 torchvision-0.20.1 tqdm-4.67.1 transformers-4.49.0 triad-0.9.8 typer-0.15.1 typing-extensions-4.12.2 tzdata-2025.1 uc-micro-py-1.0.3 urllib3-2.3.0 utilsforecast-0.2.4 virtualenv-20.29.2 wasabi-1.1.3 weasel-0.4.1 werkzeug-3.1.3 window-ops-0.0.15 wrapt-1.17.2 xgboost-2.1.4 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --no-cache-dir --force-reinstall autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard==2.18.0\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (3.7)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (1.26.4)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (5.29.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (75.8.1)\n",
      "Requirement already satisfied: six>1.9 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.11/site-packages (from tensorboard==2.18.0) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard==2.18.0) (3.0.2)\n",
      "Using cached tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: tensorboard\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.19.0\n",
      "    Uninstalling tensorboard-2.19.0:\n",
      "      Successfully uninstalled tensorboard-2.19.0\n",
      "Successfully installed tensorboard-2.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard==2.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No broken requirements found.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.5.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "autogluon-core 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "autogluon-tabular 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.1 which is incompatible.\n",
      "autogluon-features 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import autogluon.core as ag\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting pytensor data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert tensors to NumPy arrays\n",
    "X_train_np, y_train_np = X_train.numpy(), y_train.numpy()\n",
    "X_val_np, y_val_np = X_val.numpy(), y_val.numpy()\n",
    "X_test_np, y_test_np = X_test.numpy(), y_test.numpy()\n",
    "\n",
    "# Convert one-hot encoded labels to class indices\n",
    "y_train_np = np.argmax(y_train_np, axis=1)\n",
    "y_val_np = np.argmax(y_val_np, axis=1)\n",
    "y_test_np = np.argmax(y_test_np, axis=1)\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_df = pd.DataFrame(X_train_np)\n",
    "train_df[\"target\"] = y_train_np  # Add labels\n",
    "\n",
    "val_df = pd.DataFrame(X_val_np)\n",
    "val_df[\"target\"] = y_val_np\n",
    "\n",
    "test_df = pd.DataFrame(X_test_np)\n",
    "test_df[\"target\"] = y_test_np\n",
    "\n",
    "# Save as CSV\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"val.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "val_data = pd.read_csv(\"val.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Define the label column\n",
    "label_column = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_143936\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.46 GB / 8.00 GB (18.2%)\n",
      "Disk Space Avail:   90.44 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_143936\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1469.10 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  # that has no feature names.\n",
      "/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  # that has no feature names.\n",
      "\t0.9048\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  # that has no feature names.\n",
      "/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  # that has no feature names.\n",
      "\t0.9048\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 9: early stopping\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t4.62s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9048\t = Validation score   (accuracy)\n",
      "\t2.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9048\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport catboost failed. Numpy version may be outdated, Please ensure numpy version >=1.17.0. If it is not, please try 'pip uninstall numpy -y; pip install numpy>=1.17.0' Detailed info: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9048\t = Validation score   (accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t1.0\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.02s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2141.5 rows/s (21 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_143936\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# Train the model\n",
    "predictor = TabularPredictor(label=label_column).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results: {'accuracy': 0.9333333333333333, 'balanced_accuracy': np.float64(0.9333333333333332), 'mcc': np.float64(0.9060606745389328)}\n",
      "Test Results: {'accuracy': 0.9, 'balanced_accuracy': np.float64(0.9), 'mcc': np.float64(0.8514202182000767)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_results = predictor.evaluate(val_data)\n",
    "print(\"Validation Results:\", val_results)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = predictor.evaluate(test_data)\n",
    "print(\"Test Results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144807\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.19 GB / 8.00 GB (14.9%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1222.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 1}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 1, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 1 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 0.8392, Val accuracy: 0.8571, Best Epoch: 1\n",
      "Best model found on Epoch 1 (Update 42). Val accuracy: 0.8571428571428571\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.8571\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t10824.7\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/WeightedEnsemble_L2/utils/model_template.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=2, lr=0.001, epochs=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.8571\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t9151.2\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.19s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 9151.2 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144807/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144808\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.19 GB / 8.00 GB (14.9%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1222.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 3}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 3, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 3 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 0.8392, Val accuracy: 0.8571, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 0.2817, Val accuracy: 0.9524, Best Epoch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=2, lr=0.001, epochs=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (Update 126).\tTrain loss: 0.1412, Val accuracy: 0.9524, Best Epoch: 3\n",
      "Best model found on Epoch 3 (Update 126). Val accuracy: 0.9523809523809523\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "\t3132.5\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t2972.1\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2972.1 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144808-001\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.19 GB / 8.00 GB (14.9%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1222.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 0.8392, Val accuracy: 0.8571, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 0.2817, Val accuracy: 0.9524, Best Epoch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=2, lr=0.001, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (Update 126).\tTrain loss: 0.1412, Val accuracy: 0.9524, Best Epoch: 3\n",
      "Epoch 4 (Update 168).\tTrain loss: 0.076, Val accuracy: 0.9524, Best Epoch: 4\n",
      "Epoch 5 (Update 210).\tTrain loss: 0.1704, Val accuracy: 0.9524, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 210). Val accuracy: 0.9523809523809523\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t15739.9\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t9830.4\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.32s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 9830.4 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-001/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144808-002\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.19 GB / 8.00 GB (14.9%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1222.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 1}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 1, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 1 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 1.1043, Val accuracy: 0.5238, Best Epoch: 1\n",
      "Best model found on Epoch 1 (Update 42). Val accuracy: 0.5238095238095238\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t14343.0\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11783.3\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11783.3 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-002/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144808-003\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.16 GB / 8.00 GB (14.6%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1191.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=2, lr=1e-05, epochs=1\n",
      "Training with batch_size=2, lr=1e-05, epochs=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 3}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 3, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 3 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 1.1043, Val accuracy: 0.5238, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 1.1019, Val accuracy: 0.5238, Best Epoch: 2\n",
      "Epoch 3 (Update 126).\tTrain loss: 1.1005, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Best model found on Epoch 3 (Update 126). Val accuracy: 0.5238095238095238\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t9762.8\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t8551.5\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.22s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 8551.5 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144808-003/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144809\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.16 GB / 8.00 GB (14.6%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1191.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 1.1043, Val accuracy: 0.5238, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 1.1019, Val accuracy: 0.5238, Best Epoch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=2, lr=1e-05, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (Update 126).\tTrain loss: 1.1005, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Epoch 4 (Update 168).\tTrain loss: 1.096, Val accuracy: 0.5238, Best Epoch: 4\n",
      "Epoch 5 (Update 210).\tTrain loss: 1.0934, Val accuracy: 0.5714, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 210). Val accuracy: 0.5714285714285714\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5714\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t13285.1\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5714\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11094.6\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.3s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11094.6 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144809-001\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.16 GB / 8.00 GB (14.6%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1191.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 0.001, 'num_epochs': 1}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 0.001, 'num_epochs': 1, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 1 epochs...\n",
      "Epoch 1 (Update 21).\tTrain loss: 0.9678, Val accuracy: 0.8095, Best Epoch: 1\n",
      "Best model found on Epoch 1 (Update 21). Val accuracy: 0.8095238095238095\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.8095\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t14012.2\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.8095\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11445.0\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11445.0 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-001/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144809-002\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.16 GB / 8.00 GB (14.6%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1191.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 0.001, 'num_epochs': 3}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 0.001, 'num_epochs': 3, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 3 epochs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=4, lr=0.001, epochs=1\n",
      "Training with batch_size=4, lr=0.001, epochs=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Update 21).\tTrain loss: 0.9678, Val accuracy: 0.8095, Best Epoch: 1\n",
      "Epoch 2 (Update 42).\tTrain loss: 0.4527, Val accuracy: 0.9524, Best Epoch: 2\n",
      "Epoch 3 (Update 63).\tTrain loss: 0.1885, Val accuracy: 0.9524, Best Epoch: 3\n",
      "Best model found on Epoch 3 (Update 63). Val accuracy: 0.9523809523809523\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11431.6\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t8627.7\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.22s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 8627.7 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-002/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144809-003\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.16 GB / 8.00 GB (14.6%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1193.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 0.001, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 0.001, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 21).\tTrain loss: 0.9678, Val accuracy: 0.8095, Best Epoch: 1\n",
      "Epoch 2 (Update 42).\tTrain loss: 0.4527, Val accuracy: 0.9524, Best Epoch: 2\n",
      "Epoch 3 (Update 63).\tTrain loss: 0.1885, Val accuracy: 0.9524, Best Epoch: 3\n",
      "Epoch 4 (Update 84).\tTrain loss: 0.0703, Val accuracy: 0.9048, Best Epoch: 3\n",
      "Epoch 5 (Update 105).\tTrain loss: 0.0382, Val accuracy: 0.9524, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 105). Val accuracy: 0.9523809523809523\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t9618.9\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/WeightedEnsemble_L2/utils/model_template.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=4, lr=0.001, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t8167.7\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.22s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 8167.7 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144809-003/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144810\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.18 GB / 8.00 GB (14.7%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1205.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 1}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 1, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 1 epochs...\n",
      "Epoch 1 (Update 21).\tTrain loss: 1.1061, Val accuracy: 0.4286, Best Epoch: 1\n",
      "Best model found on Epoch 1 (Update 21). Val accuracy: 0.42857142857142855\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.4286\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t14820.9\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.4286\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11758.2\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.11s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11758.2 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144810-001\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.18 GB / 8.00 GB (14.7%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1205.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/learner.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=4, lr=1e-05, epochs=1\n",
      "Training with batch_size=4, lr=1e-05, epochs=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 3}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 3, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 3 epochs...\n",
      "Epoch 1 (Update 21).\tTrain loss: 1.1061, Val accuracy: 0.4286, Best Epoch: 1\n",
      "Epoch 2 (Update 42).\tTrain loss: 1.1025, Val accuracy: 0.5238, Best Epoch: 2\n",
      "Epoch 3 (Update 63).\tTrain loss: 1.102, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Best model found on Epoch 3 (Update 63). Val accuracy: 0.5238095238095238\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t15444.6\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11933.4\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.21s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11933.4 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-001/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_144810-002\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.18 GB / 8.00 GB (14.7%)\n",
      "Disk Space Avail:   90.43 GB / 228.27 GB (39.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1205.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 21).\tTrain loss: 1.1061, Val accuracy: 0.4286, Best Epoch: 1\n",
      "Epoch 2 (Update 42).\tTrain loss: 1.1025, Val accuracy: 0.5238, Best Epoch: 2\n",
      "Epoch 3 (Update 63).\tTrain loss: 1.102, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Epoch 4 (Update 84).\tTrain loss: 1.0993, Val accuracy: 0.5238, Best Epoch: 4\n",
      "Epoch 5 (Update 105).\tTrain loss: 1.0971, Val accuracy: 0.5238, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 105). Val accuracy: 0.5238095238095238\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t15836.1\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/WeightedEnsemble_L2/utils/oof.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch_size=4, lr=1e-05, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11777.0\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.2s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11777.0 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_144810-002/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch Size  Learning Rate  Epochs  Accuracy        F1\n",
      "0            2        0.00100       1  0.800000  0.780220\n",
      "1            2        0.00100       3  0.933333  0.932660\n",
      "2            2        0.00100       5  0.933333  0.932660\n",
      "3            2        0.00001       1  0.400000  0.324786\n",
      "4            2        0.00001       3  0.400000  0.324786\n",
      "5            2        0.00001       5  0.533333  0.444444\n",
      "6            4        0.00100       1  0.666667  0.541126\n",
      "7            4        0.00100       3  1.000000  1.000000\n",
      "8            4        0.00100       5  1.000000  1.000000\n",
      "9            4        0.00001       1  0.400000  0.324786\n",
      "10           4        0.00001       3  0.400000  0.324786\n",
      "11           4        0.00001       5  0.400000  0.324786\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define hyperparameter grid\n",
    "batch_sizes = [2, 4]\n",
    "learning_rates = [1e-3, 1e-5]\n",
    "epochs = [1, 3, 5]\n",
    "\n",
    "# Generate all hyperparameter combinations\n",
    "hyperparameter_combinations = list(itertools.product(batch_sizes, learning_rates, epochs))\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Run Grid Search\n",
    "for batch_size, lr, epoch in hyperparameter_combinations:\n",
    "    print(f\"Training with batch_size={batch_size}, lr={lr}, epochs={epoch}\")\n",
    "    \n",
    "    predictor = TabularPredictor(label=label_column, verbosity=3).fit(\n",
    "        train_data,\n",
    "        hyperparameters={\n",
    "            \"NN_TORCH\": {  # Neural network model in AutoGluon\n",
    "                \"batch_size\": batch_size,\n",
    "                \"learning_rate\": lr,\n",
    "                \"num_epochs\": epoch\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_results = predictor.evaluate(val_data)\n",
    "    \n",
    "    # Get predictions and true labels\n",
    "    y_pred = predictor.predict(val_data)\n",
    "    y_true = val_data[label_column]\n",
    "    \n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Batch Size\": batch_size,\n",
    "        \"Learning Rate\": lr,\n",
    "        \"Epochs\": epoch,\n",
    "        \"Accuracy\": val_results[\"accuracy\"],\n",
    "        \"F1\": f1  # Use the computed F1 score\n",
    "    })\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv(\"grid_search_results.csv\", index=False)\n",
    "\n",
    "# Display results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the hyperparameter search space for Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163144\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.15 GB / 8.00 GB (14.4%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1174.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: batch_size=2, lr=0.001, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 0.8392, Val accuracy: 0.8571, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 0.2817, Val accuracy: 0.9524, Best Epoch: 2\n",
      "Epoch 3 (Update 126).\tTrain loss: 0.1412, Val accuracy: 0.9524, Best Epoch: 3\n",
      "Epoch 4 (Update 168).\tTrain loss: 0.076, Val accuracy: 0.9524, Best Epoch: 4\n",
      "Epoch 5 (Update 210).\tTrain loss: 0.1704, Val accuracy: 0.9524, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 210). Val accuracy: 0.9523809523809523\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t14247.9\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.9524\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t9036.7\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.58s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 9036.7 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163144/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163145\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.18 GB / 8.00 GB (14.7%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1204.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 1}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 1, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 1 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 1.1043, Val accuracy: 0.5238, Best Epoch: 1\n",
      "Best model found on Epoch 1 (Update 42). Val accuracy: 0.5238095238095238\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t12668.0\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t10156.9\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10156.9 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163145-001\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.18 GB / 8.00 GB (14.7%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1204.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: batch_size=2, lr=1e-05, epochs=1\n",
      "Trial 3: batch_size=2, lr=1e-05, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 1.1043, Val accuracy: 0.5238, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 1.1019, Val accuracy: 0.5238, Best Epoch: 2\n",
      "Epoch 3 (Update 126).\tTrain loss: 1.1005, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Epoch 4 (Update 168).\tTrain loss: 1.096, Val accuracy: 0.5238, Best Epoch: 4\n",
      "Epoch 5 (Update 210).\tTrain loss: 1.0934, Val accuracy: 0.5714, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 210). Val accuracy: 0.5714285714285714\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5714\t = Validation score   (accuracy)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t14179.1\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5714\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11545.5\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11545.5 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163145-001/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163146\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.23 GB / 8.00 GB (15.4%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1253.46 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 3}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 3, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 3 epochs...\n",
      "Epoch 1 (Update 21).\tTrain loss: 1.1061, Val accuracy: 0.4286, Best Epoch: 1\n",
      "Epoch 2 (Update 42).\tTrain loss: 1.1025, Val accuracy: 0.5238, Best Epoch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4: batch_size=4, lr=1e-05, epochs=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (Update 63).\tTrain loss: 1.102, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Best model found on Epoch 3 (Update 63). Val accuracy: 0.5238095238095238\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t12545.3\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t10677.7\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.24s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 10677.7 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163146-001\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.25 GB / 8.00 GB (15.6%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1276.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 1.1043, Val accuracy: 0.5238, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 1.1019, Val accuracy: 0.5238, Best Epoch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5: batch_size=2, lr=1e-05, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (Update 126).\tTrain loss: 1.1005, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Epoch 4 (Update 168).\tTrain loss: 1.096, Val accuracy: 0.5238, Best Epoch: 4\n",
      "Epoch 5 (Update 210).\tTrain loss: 1.0934, Val accuracy: 0.5714, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 210). Val accuracy: 0.5714285714285714\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5714\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t8653.1\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5714\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t7681.2\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.36s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 7681.2 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-001/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163146-002\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.25 GB / 8.00 GB (15.6%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1276.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 0.001, 'num_epochs': 1}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 0.001, 'num_epochs': 1, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 1 epochs...\n",
      "Epoch 1 (Update 21).\tTrain loss: 0.9678, Val accuracy: 0.8095, Best Epoch: 1\n",
      "Best model found on Epoch 1 (Update 21). Val accuracy: 0.8095238095238095\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.8095\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t13565.4\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.8095\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11133.9\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11133.9 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-002/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163146-003\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.25 GB / 8.00 GB (15.6%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6: batch_size=4, lr=0.001, epochs=1\n",
      "Trial 7: batch_size=2, lr=1e-05, epochs=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1276.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 3}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 3, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 3 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 1.1043, Val accuracy: 0.5238, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 1.1019, Val accuracy: 0.5238, Best Epoch: 2\n",
      "Epoch 3 (Update 126).\tTrain loss: 1.1005, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Best model found on Epoch 3 (Update 126). Val accuracy: 0.5238095238095238\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t14238.7\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11744.1\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.26s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11744.1 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163146-003/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163147\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.13 GB / 8.00 GB (14.2%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1160.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 4, 'learning_rate': 1e-05, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 21).\tTrain loss: 1.1061, Val accuracy: 0.4286, Best Epoch: 1\n",
      "Epoch 2 (Update 42).\tTrain loss: 1.1025, Val accuracy: 0.5238, Best Epoch: 2\n",
      "Epoch 3 (Update 63).\tTrain loss: 1.102, Val accuracy: 0.5238, Best Epoch: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8: batch_size=4, lr=1e-05, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (Update 84).\tTrain loss: 1.0993, Val accuracy: 0.5238, Best Epoch: 4\n",
      "Epoch 5 (Update 105).\tTrain loss: 1.0971, Val accuracy: 0.5238, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 105). Val accuracy: 0.5238095238095238\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t5353.1\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5238\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t4568.5\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.25s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4568.5 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163147-001\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.14 GB / 8.00 GB (14.2%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1164.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 1}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 0.001, 'num_epochs': 1, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 1 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 0.8392, Val accuracy: 0.8571, Best Epoch: 1\n",
      "Best model found on Epoch 1 (Update 42). Val accuracy: 0.8571428571428571\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.8571\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t13546.7\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.8571\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11369.6\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11369.6 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-001/models/WeightedEnsemble_L2/model.pkl\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_163147-002\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.14 GB / 8.00 GB (14.2%)\n",
      "Disk Space Avail:   89.36 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1164.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9: batch_size=2, lr=0.001, epochs=1\n",
      "Trial 10: batch_size=2, lr=1e-05, epochs=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 5}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': 2, 'learning_rate': 1e-05, 'num_epochs': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Tabular Neural Network treats features as the following types:\n",
      "{\n",
      "    \"continuous\": [\n",
      "        \"0\",\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\"\n",
      "    ],\n",
      "    \"skewed\": [],\n",
      "    \"onehot\": [],\n",
      "    \"embed\": [],\n",
      "    \"language\": [],\n",
      "    \"bool\": []\n",
      "}\n",
      "\n",
      "\n",
      "Training data for TabularNeuralNetTorchModel has: 84 examples, 4 features (4 vector, 0 embedding)\n",
      "Training on CPU\n",
      "Neural network architecture:\n",
      "EmbedNet(\n",
      "  (main_block): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Training tabular neural network for up to 5 epochs...\n",
      "Epoch 1 (Update 42).\tTrain loss: 1.1043, Val accuracy: 0.5238, Best Epoch: 1\n",
      "Epoch 2 (Update 84).\tTrain loss: 1.1019, Val accuracy: 0.5238, Best Epoch: 2\n",
      "Epoch 3 (Update 126).\tTrain loss: 1.1005, Val accuracy: 0.5238, Best Epoch: 3\n",
      "Epoch 4 (Update 168).\tTrain loss: 1.096, Val accuracy: 0.5238, Best Epoch: 4\n",
      "Epoch 5 (Update 210).\tTrain loss: 1.0934, Val accuracy: 0.5714, Best Epoch: 5\n",
      "Best model found on Epoch 5 (Update 210). Val accuracy: 0.5714285714285714\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/NeuralNetTorch/model.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "\t0.5714\t = Validation score   (accuracy)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t14179.1\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/trainer.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/utils/attr/NeuralNetTorch/y_pred_proba_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 1\n",
      "Ensemble weights: \n",
      "[1.]\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/WeightedEnsemble_L2/model.pkl\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5714\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "\t11764.4\t = Inference  throughput (rows/s | 21 batch size)\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.4s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 11764.4 rows/s (21 batch size)\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/trainer.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/predictor.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/version.txt with contents \"1.2\"\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002\")\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_163147-002/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch Size  Learning Rate  Epochs  Accuracy        F1\n",
      "0           2        0.00100       5  0.933333  0.932660\n",
      "1           2        0.00001       1  0.400000  0.324786\n",
      "2           2        0.00001       5  0.533333  0.444444\n",
      "3           4        0.00001       3  0.400000  0.324786\n",
      "4           2        0.00001       5  0.533333  0.444444\n",
      "5           4        0.00100       1  0.666667  0.541126\n",
      "6           2        0.00001       3  0.400000  0.324786\n",
      "7           4        0.00001       5  0.400000  0.324786\n",
      "8           2        0.00100       1  0.800000  0.780220\n",
      "9           2        0.00001       5  0.533333  0.444444\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "random.seed(None)\n",
    "\n",
    "# Define hyperparameter space\n",
    "batch_sizes = [2, 4]\n",
    "learning_rates = [1e-3, 1e-5]\n",
    "epochs = [1, 3, 5]\n",
    "\n",
    "label_column = \"target\"\n",
    "\n",
    "# Number of random trials\n",
    "num_trials = 10  # Increase for better diversity\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Run Random Search\n",
    "for i in range(num_trials):\n",
    "    random.seed(None)\n",
    "    batch_size = random.choice(batch_sizes)\n",
    "    lr = random.choice(learning_rates)\n",
    "    epoch = random.choice(epochs)\n",
    "    \n",
    "    print(f\"Trial {i+1}: batch_size={batch_size}, lr={lr}, epochs={epoch}\")\n",
    "    \n",
    "    predictor = TabularPredictor(label=label_column, verbosity=3).fit(\n",
    "        train_data,\n",
    "        hyperparameters={\n",
    "            \"NN_TORCH\": {\n",
    "                \"batch_size\": batch_size,\n",
    "                \"learning_rate\": lr,\n",
    "                \"num_epochs\": epoch\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_results = predictor.evaluate(val_data)\n",
    "    \n",
    "    # Get predictions and true labels\n",
    "    y_pred = predictor.predict(val_data)\n",
    "    y_true = val_data[label_column]\n",
    "    \n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Batch Size\": batch_size,\n",
    "        \"Learning Rate\": lr,\n",
    "        \"Epochs\": epoch,\n",
    "        \"Accuracy\": val_results[\"accuracy\"],\n",
    "        \"F1\": f1\n",
    "    })\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv(\"random_search_results.csv\", index=False)\n",
    "\n",
    "# Display results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperband + Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250226_164110\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:21 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.20 GB / 8.00 GB (15.0%)\n",
      "Disk Space Avail:   89.33 GB / 228.27 GB (39.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'hyperparameter_tune_kwargs': {'num_trials': 10,\n",
      "                                'scheduler': 'hyperband',\n",
      "                                'searcher': 'bayesopt'}}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': {'num_trials': 10,\n",
      "                                'scheduler': 'hyperband',\n",
      "                                'searcher': 'bayesopt'},\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/learner.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"/Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110\"\n",
      "Train Data Rows:    105\n",
      "Train Data Columns: 4\n",
      "Label Column:       target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [np.int64(1), np.int64(0), np.int64(2)]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1224.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 4 | ['0', '1', '2', '3']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['0', '1', '2', '3']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{'batch_size': [2, 4], 'learning_rate': [1e-05, 0.001], 'num_epochs': [1, 3, 5]}],\n",
      "}\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/utils/data/X.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/utils/data/y.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/utils/data/X_val.pkl\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tNeuralNetTorch: \t{'batch_size': [2, 4], 'learning_rate': [1e-05, 0.001], 'num_epochs': [1, 3, 5], 'ag_args': {'hyperparameter_tune_kwargs': {'scheduler': 'hyperband', 'searcher': 'bayesopt', 'num_trials': 10}, 'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 539.97s of the 599.97s of remaining time.\n",
      "\tFitting NeuralNetTorch with 'num_gpus': 0, 'num_cpus': 8\n",
      "Starting generic AbstractModel hyperparameter tuning for NeuralNetTorch model...\n",
      "\tHyperparameter search space for NeuralNetTorch: \n",
      "activation:   Categorical['relu', 'elu']\n",
      "embedding_size_factor:   Categorical[1.0, 0.5, 1.5, 0.7, 0.6, 0.8, 0.9, 1.1, 1.2, 1.3, 1.4]\n",
      "dropout_prob:   Categorical[0.1, 0.0, 0.5, 0.2, 0.3, 0.4]\n",
      "weight_decay:   Real: lower=1e-12, upper=0.1\n",
      "proc.embed_min_categories:   Categorical[4, 3, 10, 100, 1000]\n",
      "proc.impute_strategy:   Categorical['median', 'mean', 'most_frequent']\n",
      "proc.max_category_levels:   Categorical[100, 10, 20, 200, 300, 400, 500, 1000, 10000]\n",
      "proc.skew_threshold:   Categorical[0.99, 0.2, 0.3, 0.5, 0.8, 0.9, 0.999, 1.0, 10.0, 100.0]\n",
      "num_layers:   Categorical[2, 3, 4]\n",
      "hidden_size:   Categorical[128, 256, 512]\n",
      "use_batchnorm:   Categorical[False, True]\n",
      "Warning: Exception caused NeuralNetTorch to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2497, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1751, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1814, in _hyperparameter_tune\n",
      "    hpo_executor.execute(\n",
      "  File \"/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/core/hpo/executors.py\", line 421, in execute\n",
      "    analysis = run(\n",
      "               ^^^^\n",
      "  File \"/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/core/hpo/ray_hpo.py\", line 227, in run\n",
      "    searcher = _get_searcher(\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/shreya/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/core/hpo/ray_hpo.py\", line 367, in _get_searcher\n",
      "    assert searcher in SEARCHER_PRESETS, f\"{searcher} is not a valid option. Options are {SEARCHER_PRESETS.keys()}\"\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: bayesopt is not a valid option. Options are dict_keys(['random', 'bayes'])\n",
      "bayesopt is not a valid option. Options are dict_keys(['random', 'bayes'])\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/models/trainer.pkl\n",
      "No base models to train on, skipping auxiliary stack level 2...\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/models/trainer.pkl\n",
      "Warning: AutoGluon did not successfully train any models\n",
      "Saving /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 0.06s ... Best model: None\n",
      "Loading: /Users/shreya/Documents/CS203_Lab06/AutogluonModels/ag-20250226_164110/models/trainer.pkl\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 21\u001b[0m\n\u001b[1;32m     14\u001b[0m hyperparameter_tune_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperband\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Hyperband scheduling\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearcher\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbayesopt\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Bayesian Optimization\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_trials\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Number of hyperparameter trials\u001b[39;00m\n\u001b[1;32m     18\u001b[0m }\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mTabularPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_tune_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set a time limit (in seconds) for the search\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[1;32m     29\u001b[0m val_results \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mevaluate(val_data)\n",
      "File \u001b[0;32m~/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1299\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;66;03m# keep track of the fit strategy used for future calls\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_strategy \u001b[38;5;241m=\u001b[39m fit_strategy\n\u001b[0;32m-> 1299\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1307\u001b[0m, in \u001b[0;36mTabularPredictor._fit\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag_fit_kwargs)\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m-> 1307\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/Documents/CS203_Lab06/.venv/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:1630\u001b[0m, in \u001b[0;36mTabularPredictor._post_fit\u001b[0;34m(self, keep_only_best, refit_full, set_best_to_refit_full, save_space, calibrate, calibrate_decision_threshold, infer_limit, num_cpus, num_gpus, refit_full_kwargs, fit_strategy, raise_on_no_models_fitted)\u001b[0m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_names():\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_no_models_fitted:\n\u001b[0;32m-> 1630\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1631\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo models were trained successfully during fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1632\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Inspect the log output or increase verbosity to determine why no models were fit.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1633\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Alternatively, set `raise_on_no_models_fitted` to False during the fit call.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1634\u001b[0m         )\n\u001b[1;32m   1636\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: No models found, skipping post_fit logic...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No models were trained successfully during fit(). Inspect the log output or increase verbosity to determine why no models were fit. Alternatively, set `raise_on_no_models_fitted` to False during the fit call."
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define hyperparameter search space\n",
    "hyperparameter_space = {\n",
    "    \"NN_TORCH\": {\n",
    "        \"batch_size\": [2, 4],  # List of possible batch sizes\n",
    "        \"learning_rate\": [1e-5, 1e-3],  # Learning rates to try\n",
    "        \"num_epochs\": [1, 3, 5]  # Number of epochs\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use Hyperband + Bayesian Optimization\n",
    "hyperparameter_tune_kwargs = {\n",
    "    'scheduler': 'hyperband',  # Hyperband scheduling\n",
    "    'searcher': 'bayesopt',  # Bayesian Optimization\n",
    "    'num_trials': 10  # Number of hyperparameter trials\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "predictor = TabularPredictor(label=label_column, verbosity=3).fit(\n",
    "    train_data,\n",
    "    hyperparameters=hyperparameter_space,\n",
    "    hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "    time_limit=600  # Set a time limit (in seconds) for the search\n",
    ")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_results = predictor.evaluate(val_data)\n",
    "\n",
    "# Get predictions and true labels\n",
    "y_pred = predictor.predict(val_data)\n",
    "y_true = val_data[label_column]\n",
    "\n",
    "# Compute F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Print results\n",
    "print(\"Validation Accuracy:\", val_results[\"accuracy\"])\n",
    "print(\"Validation F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
